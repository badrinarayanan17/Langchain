{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Q&A on a Huge Book - Pinecone Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq # Inference\n",
    "from langchain.document_loaders import UnstructuredPDFLoader, PDFMinerLoader, PyPDFLoader # For Loading the book\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from langchain_pinecone import PineconeVectorStore # Vector DB\n",
    "from langchain.chains.summarize import load_summarize_chain # To Perform Summarization\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains.question_answering import load_qa_chain # To Perform Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv() # Detecting env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PINECONE_API_KEY\"] = os.getenv(\"PINECONE_API_KEY\") # Setting up pinecone API KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_data = PyPDFLoader(\"C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf\") # Loading the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 1221 0 (offset 0)\n",
      "Ignoring wrong pointing object 1309 0 (offset 0)\n",
      "Ignoring wrong pointing object 1388 0 (offset 0)\n",
      "Ignoring wrong pointing object 1412 0 (offset 0)\n",
      "Ignoring wrong pointing object 2082 0 (offset 0)\n",
      "Ignoring wrong pointing object 2429 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "loader = large_data.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 0}),\n",
       " Document(page_content='DATA SCIENCEtoTHE\\nFIEL D GUIDE\\n    \\n \\nSECOND  \\nEDITION\\n© COPYRIGHT 2015 BOOZ ALLEN HAMILTON INC. ALL RIGHTS RESERVED.', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 1}),\n",
       " Document(page_content='', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 2}),\n",
       " Document(page_content='FOREWORD\\nData Science touches every aspect of our lives on a \\ndaily basis. When we visit the doctor, drive our cars, \\nget on an airplane, or shop for services, Data Science \\nis changing the way we interact with and explore  \\nour world.  \\nOur world is now measured, \\nmapped, and recorded in digital \\nbits. Entire lives, from birth to \\ndeath, are now catalogued in \\nthe digital realm. These data, \\noriginating from such diverse \\nsources as connected vehicles, \\nunderwater microscopic cameras, \\nand photos we post to social \\nmedia, have propelled us into \\nthe greatest age of discovery \\nhumanity has ever known. It is \\nthrough Data Science that we \\nare unlocking the secrets hidden \\nwithin these data. We are making \\ndiscoveries that will forever \\nchange how we live and interact \\nwith the world around us. \\nThe impact of these changes \\nis having a profound effect on \\nhumanity. We have propelled \\nourselves into this age of \\ndiscovery through our incremental \\ntechnological improvements. \\nData Science has become the \\ncatalyzing force behind our next \\nevolutionary leap. Our own \\nevolution is now inextricably \\nlinked to that of computers. The \\nway we live our lives and the skills \\nthat are important to our very \\nexistence are directly dependent \\nupon the functions Data Science \\ncan achieve on our behalf.   As we move into this new \\nfuture, it is clearer than ever, that \\nbusinesses must adjust to these \\nchanges or risk being left behind. \\nFrom influencing retail markets, \\nto setting public health and safety \\npolicies, or to addressing social \\nunrest, organizations of all types \\nare generating value through  \\nData Science. Data is our new \\ncurrency and Data Science is  \\nthe mechanism by which we tap \\ninto it. \\nData Science is an auspicious and \\nprofound way of applying our \\ncuriosity and technical tradecraft \\nto solve humanity’s toughest \\nchallenges. The growing power, \\nimportance, and responsibility \\nof applying Data Science \\nmethodologies to these challenges \\nis unimaginable. Our own \\nbiases and assumptions can have \\nprofound outcomes on business, \\nnational security, and our daily \\nlives. A new class of practitioners \\nand leaders are needed to navigate \\nthis new future. Data Scientists \\nare our guides on this journey as \\nthey are creating radical new ways \\nof thinking about data and the \\nworld around us.  \\n \\nWe want to share our passion for  Data Science  and start a \\nconversation with you. This is a journey worth taking.  ››', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 3}),\n",
       " Document(page_content='Everyone you  \\nwill ever meet  \\nknows something  \\nyou don’t.  [1] \\n   ', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 4}),\n",
       " Document(page_content='THE STORY    \\n    of    THE FIELD  \\nGUIDE\\nSeveral years ago we created The Field Guide to Data Science because \\nwe wanted to help organizations of all types and sizes.  There were \\ncountless industry and academic publications describing what  Data \\nScience is and  why  we should care, but very little information was \\navailable to explain how to make use of data as a resource. We find \\nthat situation to be just as true today as we did two years ago, when \\nwe created the first edition of the field guide. \\nAt Booz Allen Hamilton, we built an industry-leading team of \\nData Scientists. Over the course of hundreds of analytic challenges \\nfor countless clients, we’ve unraveled the DNA of Data Science. \\nMany people have put forth their thoughts on single aspects of \\nData Science. We believe we can offer a broad perspective on the \\nconceptual models, tradecraft, processes and culture of Data Science \\n– the what , the why, the who and the how.  Companies with strong \\nData Science teams often focus on a single class of problems – graph \\nalgorithms for social network analysis, and recommender models for \\nonline shopping are two notable examples. Booz Allen is different. \\nIn our role as consultants, we support a diverse set of government \\nand commercial clients across a variety of domains. This allows us to \\nuniquely understand the DNA of Data Science. \\nOur goal in creating The Field Guide to Data Science was to  \\ncapture what we have learned and to share it broadly. The field  \\nof Data Science has continued to advance since we first released  \\nthe field guide. As a result, we decided to release this second edition, \\nincorporating a few new and important concepts. We also added \\ntechnical depth and richness that we believe practitioners will  \\nfind useful. \\nWe want this effort to continue driving forward the science and \\nart of Data Science.\\nThis field guide came from the passion our team feels for its \\nwork. It is not a textbook nor is it a superficial treatment. \\nSenior leaders will walk away with a deeper understanding of \\nthe concepts at the heart of Data Science. Practitioners will \\nadd to their toolbox. We hope everyone will enjoy the journey.››', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 5}),\n",
       " Document(page_content='', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 6}),\n",
       " Document(page_content='WE ARE ALL  \\nAUTHORS   of    THIS   \\nSTORY\\nWe recognize that Data Science is a team sport. The Field Guide \\nto Data Science  provides Booz Allen Hamilton’s perspective on the \\ncomplex and sometimes mysterious field of Data Science. We cannot \\ncapture all that is Data Science. Nor can we keep up - the pace at \\nwhich this field progresses outdates work as fast as it is produced.  \\nAs a result, we opened this field guide to the world as a living \\ndocument to bend and grow with technology, expertise, and  \\nevolving techniques. \\nThank you to all the people that have emailed us your ideas as \\nwell as the 100+ people who have watched, starred, or forked our \\nGitHub repository. We truly value the input of the community, as \\nwe work together to advance the science and art of Data Science. \\nThis is why we have included authors from outside Booz Allen \\nHamilton on this second edition of The Field Guide to Data Science . \\nIf you find the guide to be useful, neat, or even lacking, then \\nwe encourage you to add your expertise, including:\\n››Case studies from which you have learned \\n››Citations from journal articles or papers that inspire you \\n››Algorithms and techniques that you love \\n››Your thoughts and comments on other people’s additions \\n \\nEmail us your ideas and perspectives at data_science@bah.com  \\nor submit them via a pull request on the GitHub repository .   \\nJoin our conversation and take the journey with us. Tell us and \\nthe world what you know. Become an author of this story.››', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 7}),\n",
       " Document(page_content='', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 8}),\n",
       " Document(page_content='ACKNOWLEDGEMENTS\\nWe  w o u l d  l i k e  to  e x p r e s s  o u r  s i n c e r e s t  g ra t i t u d e  to  \\nall those who have made The Field Guide to Data \\nScience  such a success. \\nThank you to the nearly 15,000 \\npeople who have downloaded \\nthe digital copy from our website \\nand the 100+ people who have \\nconnected with The Field Guide \\non our GitHub page . We have \\nbeen overwhelmed by the \\npopularity of the work within the \\nData Science community. \\nThank you to all of the \\npractitioners who are using The \\nField Guide as a resource. We are \\nexcited to know that the work has \\nhad such a strong influence, from \\nshaping technical approaches to \\nserving as the foundation for the \\nvery definition and role of Data \\nScience within major government \\nand commercial organizations. Thank you to the educators and \\nacademics who have incorporated \\nThe Field Guide into your course \\nwork. We appreciate your trusting \\nthis guide as a way to introduce \\nyour students to Data Science.   \\nIt is an honor to know that we are \\nshaping the next generation of \\nData Scientists.\\nThank you to the organizational \\nleaders who have shared your \\nfeedback, encouragement, and \\nsuccess stories. We are thrilled  \\nto know that The Field Guide  \\nhas helped so many organizations, \\nfrom energy, to life sciences,  \\nto retail, to begin their Data \\nScience journeys.  \\nWe hope you will all continue to find value from The Field \\nGuide to Data Science and to share in our excitement around the \\nrelease of this second edition. Please continue to be part of the \\nconversation and take this journey with us. ››', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 9}),\n",
       " Document(page_content='', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 10}),\n",
       " Document(page_content='THE OUTLINE    \\n                                of   OUR STORY\\n12    ›› Meet Your Guides\\n17    ›› The Short Version – The Core Concepts of Data Science\\n18    ›› Start Here for the Basics –  An Introduction to Data Science\\nWhat Do We Mean by Data Science?\\nHow Does Data Science Actually Work?\\nWhat Does It Take to Create a Data Science Capability?\\n46    ›› Take off the Training W heels –  The Practitioner’s Guide to Data Science\\nGuiding Principles\\nThe Importance of Reason\\nComponent Parts of Data Science\\nFractal Analytic Model\\nThe Analytic Selection Process\\nGuide to Analytic Selection  \\nDetailed Table of Analytics\\n84    ›› Life in the Trenches – Navigating Neck Deep in Data\\nGoing Deep into Machine Learning\\nFeature Engineering\\nFeature Selection\\nEnsemble Models\\nData Veracity\\nApplication of Domain Knowledge\\nThe Curse of Dimensionality \\nModel Validation\\n102    ›› Putting it all T ogether –  Our Case Studies\\nStreamlining Medication Review\\nReducing Flight Delays\\nMaking Vaccines Safer\\nForecasting the Relative Risk for the Onset of\\n Mass Killings to Help Pr event Future Atrocities \\nPredicting Customer Response\\n114   ›› Closing Time  \\nThe Future of Data Science\\nParting Thoughts\\nReferences\\nAbout Booz Allen Hamilton››', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 11}),\n",
       " Document(page_content='MEET  your GUIDES\\nFred Blackburn\\n(@boozallen)\\nData Science is a field that is  \\nevolving at a very rapid pace…be  \\npart of the journey.  \\nAngela Zutavern\\n(@angelazutavern)\\nData Science is about asking bigger \\nquestions, seeing future possibilities, \\nand creating outcomes you desire.  Josh Sullivan \\n(@joshdsullivan)\\nLeading our Data Science team \\nshows me every day the incredible \\npower of discovery and human \\ncuriosity. Don’t be afraid to blend \\nart and science to advance your \\nown view of data analytics – it \\ncan be a powerful mixture.\\nSteve Escaravage\\n(@sescarav)\\nInvest your time and energy \\nin data that is difficult to \\nassemble.  If it doesn’t exist, \\nfind a way to make it exist.Peter Guerra \\n(@petrguerra)\\nData Science is the most fascinating \\nblend of art and math and code \\nand sweat and tears. It can take \\nyou to the highest heights and the \\nlowest depths in an instant, but it \\nis the only way we will be able to \\nunderstand and describe the why.\\nEzmeralda Khalil\\n(@ezmeraldakhalil)\\nThe power of data science \\nlies in the execution.››\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 12}),\n",
       " Document(page_content='Steven Mills \\n(@stevndmills)\\nData Science truly can \\nchange the world.\\nStephanie Beben\\n(@boozallen)\\nBegin every new data challenge \\nwith deep curiosity along with \\na healthy dose of skepticism.Alex Cosmas \\n(@boozallen)\\nData scientists should be truth-\\nseekers, not fact-seekers.\\nKirk Borne\\n(@KirkDBorne)\\nFocus on value, not volume.Brian Keller \\n(@boozallen)\\nGrit will get you farther than talent.\\nDrew Farris \\n(@drewfarris)\\nDon’t forget to play. Play with \\ntools, play with data, and play with \\nalgorithms. You just might discover \\nsomething that will help you solve \\nthat next nagging problem. \\n13 Meet Your Guides', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 13}),\n",
       " Document(page_content=\"Paul Yacci\\n(@paulyacci)\\nIn the jungle of data, don't \\nmiss the forest for the trees, \\nor the trees for the forest.\\n \\nStephanie Rivera \\n(@boozallen)\\nI treat Data Science like I do rock \\nclimbing: awesome dedication \\nleads to incremental improvement. \\nPersistence leads to the top.Charles Glover\\n(@MindAfterMath)\\nThe beauty of data science lies \\nin satisfying curiosities about \\nimportant problems by playing \\nwith data and algorithms.\\nAaron Sander \\n(@ajsander) \\nData science is changing corporate \\nculture to be more like the open \\nsource environment. More open, \\nmore collaborative, and faster paced.Michael Kim \\n(@boozallen)\\nData science is both an art  \\nand science. \\nWe would like to thank the following people for their \\ncontributions and edits: \\nTim Andrews, Mike Delurey, Greg Dupier, Jason Escaravage, \\nChristine Fantaskey, Juergen Klenk, Dan Liebermann, Mark \\nRockley and Katie Wilks.\\nTHE FIELD  GUIDE to  DATA  SCIENCE\", metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 14}),\n",
       " Document(page_content=' COMMUNITY  CONTRIBUTORS\\nWill Cukierski, kaggle\\n(@kaggle)\\n \\nI took the one in the direction  \\nof the negative gradient,   \\nAnd that has made all the difference.\\nArmen Kherlopian \\n(@akherlopian)\\nA Data Scientist must \\ncontinuously seek truth in spite \\nof\\xa0ambiguity; therein rests the \\nbasis of rigor and insight.Mark Herman\\n(@cloudEBITDA)\\nEnd every analysis with…  \\n‘and therefore.’Ed Kohlwey \\n(@ekohlwey)\\nData Science is about formally \\nanalyzing everything around you \\nand becoming data driven.››\\nTwo roads diverged in a wood, and I—\\n15 Meet Your Guides', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 15}),\n",
       " Document(page_content='', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 16}),\n",
       " Document(page_content='TheSHORT                  \\n  VERSION\\n››Data Science is the art of turning data into actions.  \\nIt’s all about the tradecraft. Tradecraft is the process, tools and \\ntechnologies for humans and computers to work together to \\ntransform data into insights.\\n››Data Science tradecraft creates data products .  \\nData products provide actionable information without exposing \\ndecision makers to the underlying data or analytics (e.g., buy/sell \\nstrategies for financial instruments, a set of actions to improve \\nproduct yield, or steps to improve product marketing).\\n››Data Science supports and encourages shifting between \\ndeductive (hypothesis-based) and inductive (pattern-\\nbased) reasoning.  \\nThis is a fundamental change from traditional analysis approaches. \\nInductive reasoning and exploratory data analysis provide a means \\nto form or refine hypotheses and discover new analytic paths. \\nModels of reality no longer need to be static. They are constantly \\ntested, updated and improved until better models are found. \\n››Data Science is necessary for companies to stay with the \\npack and compete in the future.   \\nOrganizations are constantly making decisions based on gut \\ninstinct, loudest voice and best argument – sometimes they are \\neven informed by real information. The winners and the losers in \\nthe emerging data economy are going to be determined by their \\nData Science teams. \\n››Data Science capabilities can be built over time.  \\nOrganizations mature through a series of stages – Collect, \\nDescribe, Discover, Predict, Advise – as they move from data \\ndeluge to full Data Science maturity. At each stage, they can \\ntackle increasingly complex analytic goals with a wider breadth \\nof analytic capabilities. However, organizations need not reach \\nmaximum Data Science maturity to achieve success. Significant \\ngains can be found in every stage.\\n››Data Science is a different kind of team sport.   \\nData Science teams need a broad view of the organization. Leaders \\nmust be key advocates who meet with stakeholders to ferret out \\nthe hardest challenges, locate the data, connect disparate parts of \\nthe business, and gain widespread buy-in.››\\n17 The Short Version 17', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 17}),\n",
       " Document(page_content='', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 18}),\n",
       " Document(page_content='AN INTRODUCTION TO DATA SCIENCE\\nIf you haven’t heard of Data Science, you’re behind the \\ntimes. Just renaming your Business Intelligence group \\nthe Data Science group is not the solution. START HERE    for   THE BASICS\\n', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 19}),\n",
       " Document(page_content='What do We Mean by  \\nData Science?\\nDescribing Data Science is like trying to describe a sunset – it \\nshould be easy, but somehow capturing the words is impossible.\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 20}),\n",
       " Document(page_content='21 Start Here for the Basics 21 Start Here for the BasicsData Science Defined\\nData Science is the art of turning data into actions. This is \\naccomplished through the creation of data products, which provide \\nactionable information without exposing decision makers to the \\nunderlying data or analytics (e.g., buy/sell strategies for financial \\ninstruments, a set of actions to improve product yield, or steps to \\nimprove product marketing).\\nPerforming Data Science requires the extraction of timely, actionable \\ninformation from diverse data sources to drive data products. \\nExamples of data products include answers to questions such as: \\n“Which of my products should I advertise more heavily to increase \\nprofit? How can I improve my compliance program, while reducing \\ncosts? What manufacturing process change will allow me to build a \\nbetter product?” The key to answering these questions is: understand \\nthe data you have and what the data inductively tells you. » Data Product\\nA data product provides actionable \\ninformation without exposing \\ndecision makers to the underlying \\ndata or analytics. Examples include:\\n• Movie Reco mmendations      \\n• Weather F orecasts\\n• Stock Market Predictions\\n• Production Process \\nImprovements\\n• Health Diagnosis\\n• Flu T rend Predictions\\n• Targeted AdvertisingRead this for additional background:\\nThe term Data Science appeared \\nin the computer science literature \\nthroughout the 1960s-1980s. \\nIt was not until the late 1990s \\nhowever, that the field as we \\ndescribe it here, began to  \\nemerge from the statistics and \\ndata mining communities  \\n(e.g., [2] and [3]). Data Science \\nwas first introduced as an \\nindependent discipline in 2001.[4] \\nSince that time, there have been \\ncountless articles advancing the \\ndiscipline, culminating with \\nData Scientist being declared the \\nsexiest job of the 21st century.[5] \\nWe established our first Data \\nScience team at Booz Allen \\nin 2010. It began as a natural \\nextension of our Business \\nIntelligence and cloud infrastructure development  \\nwork. We saw the need for a  \\nnew approach to distill value \\nfrom our clients’ data. We \\napproached the problem \\nwith a multidisciplinary \\nteam of computer scientists, \\nmathematicians and domain \\nexperts. They immediately \\nproduced new insights and \\nanalysis paths, solidifying the \\nvalidity of the approach. Since \\nthat time, our Data Science  \\nteam has grown to 250 staff \\nsupporting dozens of clients \\nacross a variety of domains.  \\nThis breadth of experience \\nprovides a unique perspective  \\non the conceptual models, \\ntradecraft, processes and  \\nculture of Data Science. ', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 21}),\n",
       " Document(page_content=' Source: Booz Allen Hamilton What makes Data Science Different?\\nData Science supports and encourages shifting between deductive \\n(hypothesis-based) and inductive (pattern-based) reasoning.  This is \\na fundamental change from traditional analytic approaches. Inductive \\nreasoning and exploratory data analysis provide a means to form or \\nrefine hypotheses and discover new analytic paths. In fact, to do the \\ndiscovery of significant insights that are the hallmark of Data Science, \\nyou must have the tradecraft and the interplay between inductive \\nand deductive reasoning. By actively combining the ability to reason \\ndeductively and inductively, Data Science creates an environment \\nwhere models of reality no longer need to be static and empirically \\nbased. Instead, they are constantly tested, updated and improved until \\nbetter models are found. These concepts are summarized in the figure, \\nThe Types of Reason and Their Role in Data Science Tradecraft .\\nTHE TYPES OF REASON…\\nDEDUCTIVE REASONING:\\n › Commonly associated \\nwith “formal logic.”\\n › Involves reasoning from known \\npremises, or premises presumed \\nto be true, to a certain conclusion.\\n › The conclusions reached are \\ncertain, inevitable, inescapable.INDUCTIVE REASONING\\n › Commonly known as “informal \\nlogic,”  or “everyday argument.”\\n › Involves drawing uncertain \\ninferences, based on \\nprobabilistic reasoning.\\n › The conclusions reached \\nare probable, reasonable, \\nplausible, believable.\\n…AND THEIR ROLE IN DATA SCIENCE TRADECRAFT.\\nDEDUCTIVE REASONING:\\n › Formulate hypotheses about \\nrelationships and underlying models.\\n › Carry out experiments with the data \\nto test hypotheses and models.INDUCTIVE REASONING\\n › Exploratory data analysis to \\ndiscover or reﬁne hypotheses.\\n › Discover new relationships, insights \\nand analytic paths from the data.\\nThe Types of Reason and Their Role in Data Science Tradecraft\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 22}),\n",
       " Document(page_content=\" Source: Booz Allen Hamilton \\n23 Start Here for the Basics 23 Start Here for the Basics\\nThe differences between Data Science and traditional analytic \\napproaches do not end at seamless shifting between deductive \\nand inductive reasoning. Data Science offers a distinctly different \\nperspective than capabilities such as Business Intelligence. Data \\nScience should not replace Business Intelligence functions within \\nan organization, however. The two capabilities are additive and \\ncomplementary, each offering a necessary view of business operations \\nand the operating environment. The figure, Business Intelligence and \\nData Science – A Comparison,  highlights the differences between the \\ntwo capabilities. Key contrasts include:\\n››Discovery vs. Pre-canned Questions: Data Science actually \\nworks on discovering the question to ask as opposed to just \\nasking it.\\n››Power of Many vs. Ability of One: An entire team provides \\na common forum for pulling together computer science, \\nmathematics and domain expertise. \\n››Prospective vs. Retrospective:  Data Science is focused on \\nobtaining actionable information from data as opposed to \\nreporting historical facts.\\nLOOKING BACKWARD AND FORWARD\\nFIRST THERE WAS  \\nBUSINESS INTELLIGENCE\\nDeductive Reasoning\\nBackward Looking\\nSlice and Dice Data\\nWarehoused and Siloed Data\\nAnalyze the Past, Guess the Future\\nCreates Reports\\nAnalytic OutputNOW WE'VE ADDED  \\nDATA SCIENCE\\nInductive and Deductive Reasoning\\nForward Looking\\nInteract with Data\\nDistributed, Real Time Data\\nPredict and Advise\\nCreates Data  Products\\nAnswer Questions and Create New Ones\\nActionable Answer\\nBusiness Intelligence and Data Science - A Comparison  (adapted in part from [6])\", metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 23}),\n",
       " Document(page_content='What is the Impact of Data Science?\\nAs we move into the data economy, Data Science is the competitive \\nadvantage for organizations interested in winning – in whatever way \\nwinning is defined. The manner in which the advantage is defined \\nis through improved decision-making. A former colleague liked to \\ndescribe data-informed decision making like this: If you have perfect \\ninformation or zero information then your task is easy – it is in between \\nthose two extremes that the trouble begins.  What he was highlighting is \\nthe stark reality that whether or not information is available, decisions \\nmust be made.\\nThe way organizations make decisions has been evolving for half a \\ncentury. Before the introduction of Business Intelligence, the only \\noptions were gut instinct, loudest voice, and best argument. Sadly, this \\nmethod still exists today, and in some pockets it is the predominant \\nmeans by which the organization acts. Take our advice and never, ever \\nwork for such a company! \\nFortunately for our economy, most organizations began to inform \\ntheir decisions with real information through the application of \\nsimple statistics. Those that did it well were rewarded; those that did \\nnot failed. We are outgrowing the ability of simple stats to keep pace \\nwith market demands, however. The rapid expansion of available data \\nand the tools to access and make use of the data at scale are enabling \\nfundamental changes to the way organizations make decisions. \\nData Science is required to maintain competitiveness in the \\nincreasingly data-rich environment. Much like the application of \\nsimple statistics, organizations that embrace Data Science will be \\nrewarded while those that do not will be challenged to keep pace. As \\nmore complex, disparate datasets become available, the chasm between \\nthese groups will only continue to widen. The figure, The Business \\nImpacts of Data Science, highlights the value awaiting organizations \\nthat embrace Data Science.\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 24}),\n",
       " Document(page_content=\" Source: Booz Allen Hamilton \\n25 Start Here for the Basics 25 Start Here for the Basics\\nDATA SCIENCE IS NECESSARY...\\n17-49%  increase in productivity when organizations increase data \\nusability by 10%\\n11-42%   return on assets (ROA) when organizations increase data \\naccess by 10% \\n241%   increase in ROI when or ganizations use big data to  \\nimprove competitiveness\\n1000%  increase in ROI when deploying analytics across most of \\nthe organization, aligning daily operations with senior \\nmanagement's goals, and incorporating big data\\n5-6%   performanc e improvement for organizations making  \\ndata-driven decisions. \\n...TO COMPETE IN THE FUTURE\\nThe Business Impacts of Data Science  (adapted from [7], [8] and [9])\", metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 25}),\n",
       " Document(page_content='', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 26}),\n",
       " Document(page_content='27 Start Here for the Basics 27 Start Here for the BasicsWhat is Different Now?\\nFor 20 years IT systems were built the same way. We separated \\nthe people who ran the business from the people who managed the \\ninfrastructure (and therefore saw data as simply another thing they \\nhad to manage). With the advent of new technologies and analytic \\ntechniques, this artificial – and highly ineffective – separation of \\ncritical skills is no longer necessary. For the first time, organizations \\ncan directly connect business decision makers to the data. This simple \\nstep transforms data from being ‘something to be managed’ into \\n‘something to be valued.’\\nIn the wake of the transformation, organizations face a stark choice: \\nyou can continue to build data silos and piece together disparate \\ninformation or you can consolidate your data and distill answers. \\nFrom the Data Science perspective, this is a false choice: The siloed \\napproach is untenable when you consider the (a) the opportunity \\ncost of not making maximum use of all available data to help \\nan organization succeed, and (b) the resource and time costs of \\ncontinuing down the same path with outdated processes. The tangible \\nbenefits of data products include: \\n››Opportunity Costs: Because Data Science is an emerging field, \\nopportunity costs arise when a competitor implements and \\ngenerates value from data before you. Failure to learn and account \\nfor changing customer demands will inevitably drive customers \\naway from your current offerings. When competitors are able \\nto successfully leverage Data Science to gain insights, they can \\ndrive differentiated customer value propositions and lead their \\nindustries as a result.\\n››Enhanced Processes: As a result of the increasingly interconnected \\nworld, huge amounts of data are being generated and stored \\nevery instant. Data Science can be used to transform data into \\ninsights that help improve existing processes. Operating costs \\ncan be driven down dramatically by effectively incorporating the \\ncomplex interrelationships in data like never before. This results  \\nin better quality assurance, higher product yield and more \\neffective operations. ', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 27}),\n",
       " Document(page_content='How does Data Science  \\nActually Work?\\nIt’s not rocket science… it’s something better - Data Science\\nLet’s not kid ourselves - Data Science is a complex field. It is difficult, \\nintellectually taxing work, which requires the sophisticated integration \\nof talent, tools and techniques. But as a field guide, we need to cut \\nthrough the complexity and provide a clear, yet effective way to \\nunderstand this new world. \\nTo do this, we will transform the field of Data Science into a set of \\nsimplified activities as shown in the figure, The Four Key Activities of a \\nData Science Endeavor . Data Science purists will likely disagree with \\nthis approach, but then again, they probably don’t need a field guide, \\nsitting as they do in their ivory towers! In the real world, we need \\nclear and simple operating models to help drive us forward. \\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 28}),\n",
       " Document(page_content=' Source: Booz Allen Hamilton \\n1 2 3 4\\nAcquire\\nPrepare\\nAnalyze\\nActLowHigh\\nDegree\\nof \\nEffort\\nData Science ActivitiesTry\\nEvaluate\\nSetup Do\\nEvaluate\\n29 Start Here for the Basics 29 Start Here for the Basics\\nActivity 1: Acquire  \\nThis activity focuses \\non obtaining the \\ndata you need. \\nGiven the nature of \\ndata, the details of \\nthis activity depend \\nheavily on who you \\nare and what you \\ndo. As a result, we \\nwill not spend a \\nlot of time on this \\nactivity other than \\nto emphasize its \\nimportance and \\nto encourage an \\nexpansive view on \\nwhich data can and \\nshould be used. Activity 2: Prepare \\nGreat outcomes \\ndon’t just happen \\nby themselves. \\nA lot depends on \\npreparation, and \\nin Data Science, \\nthat means \\nmanipulating the \\ndata to ﬁt your \\nanalytic needs.  \\nThis stage can \\nconsume a great \\ndeal of time, but \\nit is an excellent \\ninvestment. The \\nbeneﬁts are \\nimmediate and \\nlong term. Activity 3: Analyze \\nThis is the activity \\nthat consumes the \\nlion’s share of the \\nteam’s attention. \\nIt is also the most \\nchallenging and \\nexciting (you will \\nsee a lot of ‘aha \\nmoments’  occur in \\nthis space). As the \\nmost challenging \\nand vexing of the \\nfour activities, \\nthis ﬁeld guide \\nfocuses on helping \\nyou do this better \\nand faster.Activity 4: Act \\nEvery effective \\nData Science team \\nanalyzes its data \\nwith a purpose \\n– that is, to turn \\ndata into actions. \\nActionable and \\nimpactful insights \\nare the holy grail \\nof Data Science. \\nConverting insights \\ninto action can be a \\npolitically charged \\nactivity, however. \\nThis activity \\ndepends heavily \\non the culture and \\ncharacter of your \\norganization, so \\nwe will leave you \\nto ﬁgure out those \\ndetails for yourself .\\nThe Four Key Activities of a Data Science Endeavor', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 29}),\n",
       " Document(page_content='  Acquire\\nAll analysis starts with access to data, and for the Data Scientist \\nthis axiom holds true. But there are some significant differences – \\nparticularly with respect to the question of who stores, maintains and \\nowns the data in an organization.\\nBut before we go there, lets look at what is changing. Traditionally, \\nrigid data silos artificially define the data to be acquired. Stated \\nanother way, the silos create a filter that lets in a very small amount of \\ndata and ignores the rest. These filtered processes give us an artificial \\nview of the world based on the ‘surviving data,’ rather than one that \\nshows full reality and meaning. Without a broad and expansive \\ndataset, we can never immerse ourselves in the diversity of the \\ndata. We instead make decisions based on limited and constrained \\ninformation. \\nEliminating the need for silos gives us access to all the data at once – \\nincluding data from multiple outside sources. It embraces the reality \\nthat diversity is good and complexity is okay . This mindset creates a \\ncompletely different way of thinking about data in an organization by \\ngiving it a new and differentiated role. Data represents a significant \\nnew profit and mission-enhancement opportunity for organizations. \\nBut as mentioned earlier, this first activity is heavily dependent upon \\nthe situation and circumstances. We can’t leave you with anything \\nmore than general guidance to help ensure maximum value: \\n››Look inside first: What data do you have current access  \\nto that you are not using? This is in large part the data  \\nbeing left behind by the filtering process, and may be \\nincredibly valuable.\\n››Remove the format constraints: Stop limiting your data \\nacquisition mindset to the realm of structured databases. \\nInstead, think about unstructured and semi-structured data \\nas viable sources.\\n››Figure out what’s missing: Ask yourself what data would \\nmake a big difference to your processes if you had access to it. \\nThen go find it!\\n››Embrace diversity: Try to engage and connect to publicly \\navailable sources of data that may have relevance to your \\ndomain area.  » Not All Data Is Created Equal\\nAs you begin to aggregate data, \\nremember that not all data is  \\ncreated equally. Organizations have  \\na tendency to collect any data that  \\nis available. Data that is nearby \\n(readily accessible and easily \\nobtained) may be cheap to collect, \\nbut there is no guarantee it is the \\nright data to collect.  Focus on the \\ndata with the highest ROI for your \\norganization.  Your Data Science \\nteam can help identify that data. \\nAlso remember that you need to \\nstrike a balance between the data \\nthat you need and the data that you \\nhave. Collecting huge volumes of \\ndata is useless and costly if it is not \\nthe data that you need. \\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 30}),\n",
       " Document(page_content='31 Start Here for the Basics 31 Start Here for the Basics  Prepare\\nOnce you have the data, you need to prepare it for analysis. \\nOrganizations often make decisions based on inexact data. Data \\nstovepipes mean that organizations may have blind spots. They are \\nnot able to see the whole picture and fail to look at their data and \\nchallenges holistically. The end result is that valuable information is \\nwithheld from decision makers. Research has shown almost 33% of \\ndecisions are made without good data or information. [10] \\nWhen Data Scientists are able to explore and analyze all the data, new \\nopportunities arise for analysis and data-driven decision making. The \\ninsights gained from these new opportunities will significantly change \\nthe course of action and decisions within an organization. Gaining \\naccess to an organization’s complete repository of data, however, \\nrequires preparation.\\nOur experience shows time and time again that the best tool for \\nData Scientists to prepare for analysis is a lake – specifically, the Data \\nLake.[11] This is a new approach to collecting, storing and integrating \\ndata that helps organizations maximize the utility of their data. \\nInstead of storing information in discrete data structures, the Data \\nLake consolidates an organization’s complete repository of data in \\na single, large view. It eliminates the expensive and cumbersome \\ndata-preparation process, known as Extract/Transform/Load (ETL), \\nnecessary with data silos. The entire body of information in the Data \\nLake is available for every inquiry – and all at once. ', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 31}),\n",
       " Document(page_content=' Source: Booz Allen Hamilton \\n  Analyze\\nWe have acquired the data… we have prepared it… now it is time to \\nanalyze it. \\nThe Analyze activity requires the greatest effort of all the activities \\nin a Data Science endeavor. The Data Scientist actually builds the \\nanalytics that create value from data. Analytics in this context is \\nan iterative application of specialized and scalable computational \\nresources and tools to provide relevant insights from exponentially \\ngrowing data. This type of analysis enables real-time understanding \\nof risks and opportunities by evaluating situational, operational and \\nbehavioral data.\\nWith the totality of data fully accessible in the Data Lake, \\norganizations can use analytics to find the kinds of connections and \\npatterns that point to promising opportunities. This high-speed \\nanalytic connection is done within the Data Lake, as opposed to \\nolder style sampling methods that could only make use of a narrow \\nslice of the data. In order to understand what was in the lake, you had \\nto bring the data out and study it. Now you can dive into the lake, \\nbringing your analytics to the data. The figure, Analytic Connection in \\nthe Data Lake,  highlights the concept of diving into the Data Lake to \\ndiscover new connections and patterns . \\nAnalytic Connection in the Data Lake\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 32}),\n",
       " Document(page_content='33 Start Here for the Basics 33 Start Here for the BasicsData Scientists work across the spectrum of analytic goals – Describe, \\nDiscover, Predict and Advise. The maturity of an analytic capability \\ndetermines the analytic goals encompassed. Many variables play key \\nroles in determining the difficulty and suitability of each goal for an \\norganization. Some of these variables are the size and budget of an \\norganization and the type of data products needed by the decision \\nmakers. A detailed discussion on analytic maturity can be found in \\nData Science Maturity within an Organization .\\nIn addition to consuming the greatest effort, the Analyze activity \\nis by far the most complex. The tradecraft of Data Science is an \\nart. While we cannot teach you how to be an artist, we can share \\nfoundational tools and techniques that can help you be successful. \\nThe entirety of Take Off the Training Wheels  is dedicated to sharing \\ninsights we have learned over time while serving countless clients. \\nThis includes descriptions of a Data Science product lifecycle and \\nthe Fractal Analytic Model  (FAM). The Analytic Selection Process and \\naccompanying Guide to Analytic Selection  provide key insights into one \\nof the most challenging tasks in all of Data Science – selecting the \\nright technique for the job.\\n  Act\\nNow that we have analyzed the data, it’s time to take action. \\nThe ability to make use of the analysis is critical. It is also very \\nsituational. Like the Acquire activity, the best we can hope for is to \\nprovide some guiding principles to help you frame the output for \\nmaximum impact. Here are some key points to keep in mind when \\npresenting your results:\\n1. The finding must make sense with relatively little up-front \\ntraining or preparation on the part of the decision maker.\\n2. The finding must make the most meaningful patterns, trends \\nand exceptions easy to see and interpret.\\n3. Every effort must be made to encode quantitative data \\naccurately so the decision maker can accurately interpret and \\ncompare the data.\\n4. The logic used to arrive at the finding must be clear and \\ncompelling as well as traceable back through the data.\\n5. The findings must answer real business questions. ', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 33}),\n",
       " Document(page_content='', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 34}),\n",
       " Document(page_content=' Source: Booz Allen Hamilton \\nProportion\\nof \\nEffortMaturity\\nStages of Maturity\\nCollect\\nDescribe\\nDiscoverPredictAdviseData Silos\\n35 Start Here for the Basics 35 Start Here for the BasicsData Science Maturity within  \\nan Organization\\nThe four activities discussed thus far provide a simplified view of Data \\nScience. Organizations will repeat these activities with each new Data \\nScience endeavor. Over time, however, the level of effort necessary \\nfor each activity will change. As more data is Acquired and Prepared \\nin the Data Lake, for example, significantly less effort will need to \\nbe expended on these activities. This is indicative of a maturing Data \\nScience capability.\\nAssessing the maturity of your Data Science capability calls for a \\nslightly different view. We use The Data Science Maturity Model  as \\na common framework for describing the maturity progression and \\ncomponents that make up a Data Science capability. This framework \\ncan be applied to an organization’s Data Science capability or even \\nto the maturity of a specific solution, namely a data product. At each \\nstage of maturity, powerful insight can be gained. \\nThe Data Science Maturity Model', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 35}),\n",
       " Document(page_content=' Source: Booz Allen Hamilton When organizations start out, they have Data Silos . At this stage, \\nthey have not carried out any broad Aggregate activities. They may \\nnot have a sense of all the data they have or the data they need. The \\ndecision to create a Data Science capability signals the transition into \\nthe Collect  stage. \\nAll of your initial effort will be focused on identifying and aggregating \\ndata. Over time, you will have the data you need and a smaller \\nproportion of your effort can focus on Collect . You can now begin to \\nDescribe  your data. Note, however, that while the proportion of time \\nspent on Collect  goes down dramatically, it never goes away entirely. \\nThis is indicative of the four activities outlined earlier – you will \\ncontinue to Aggregate and Prepare data as new analytic questions \\narise, additional data is needed and new data sources become available.\\nOrganizations continue to advance in maturity as they move through \\nthe stages from Describe to Advise . At each stage they can tackle \\nincreasingly complex analytic goals with a wider breadth of analytic \\ncapabilities. As described for Collect , each stage never goes away \\nentirely. Instead, the proportion of time spent focused on it goes  \\ndown and new, more mature activities begin. A brief description  \\nof each stage of maturity is shown in the table The Stages of Data \\nScience Maturity.\\nThe Stages of Data Science Maturity\\nStage Description Example\\nCollectFocuses on collecting internal \\nor external datasets.Gathering sales records and \\ncorresponding weather data.\\nDescribeSeeks to enhance or \\nreﬁne raw data as well \\nas leverage basic analytic \\nfunctions such as counts.How are my customers \\ndistributed with respect to \\nlocation, namely zip code?  \\nDiscoverIdentiﬁes hidden relationships \\nor patterns.Are there groups within \\nmy regular customers that \\npurchase similarly?\\nPredictUtilizes past observations to \\npredict future observations.Can we predict which products \\nthat certain customer groups \\nare more likely to purchase?\\nAdviseDeﬁnes your possible decisions, \\noptimizes over those decisions, \\nand advises to use the decision \\nthat gives the best outcome.Your advice is to target advertise \\nto speciﬁc groups for certain \\nproducts to maximize revenue.\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 36}),\n",
       " Document(page_content=' Source: Booz Allen Hamilton \\n37 Start Here for the Basics 37 Start Here for the BasicsThe maturity model provides a powerful tool for understanding  \\nand appreciating the maturity of a Data Science capability. \\nOrganizations need not reach maximum maturity to achieve  \\nsuccess. Significant gains can be found in every stage. We believe \\nstrongly that one does not engage in a Data Science effort, however, \\nunless it is intended to produce an output – that is, you have the \\nintent to Advise . This means simply that each step forward in  \\nmaturity drives you to the right in the model diagram. Moving  \\nto the right requires the correct processes, people, culture and \\noperating model – a robust Data Science capability. What Does it  \\nTake to Create a Data Science Capability?  addresses this topic. \\nWe have observed very few organizations actually operating at  \\nthe highest levels of maturity, the Predict  and Advise  stages. The \\ntradecraft of Discover  is only now maturing to the point that \\norganizations can focus on advanced Predict and Advise activities.  \\nThis is the new frontier of Data Science. This is the space in which \\nwe will begin to understand how to close the cognitive gap between \\nhumans and computers. Organizations that reach Advise  will be  \\nmet with true insights and real competitive advantage. »  Where does your organization \\nfall in analytic maturity? \\n Take the quiz!\\n1.   How many data sources do  \\nyou collect?\\na.  Why do we need a bunch of dat a? \\n – 0 points, end here.\\nb.  I don’t know the e xact number.  \\n– 5 points\\nc.  We identiﬁed the required data and \\ncollect it. – 10 points\\n2. Do you know what questions  \\nyour Data Science team is trying  \\nto answer?\\na.  Why do we need ques tions?   \\n- 0 points\\nb.  No, they ﬁgure it out for themselves. \\n– 5 points\\nc.  Yes, we evaluated the questions that \\nwill have the largest impact to the \\nbusiness. – 10 points\\n3. Do you know the important factors \\ndriving your business?\\na. I have no idea.  – 0 points\\nb.  Our quants help me ﬁgure it out.  \\n– 5 points\\nc.  We have a data product for that.  \\n– 10 points\\n4. Do you have an understanding of \\nfuture conditions?\\na. I look at the current conditions and \\nread the tea leaves. – 0 points\\nb.  We have a data product for that.   \\n– 5 points\\n5. Do you know the best course \\nof action to take for your key \\ndecisions?\\na.  I look at the projections and plan a \\ncourse. – 0 points\\nb.  We have a data product for that.  \\n– 5 points\\nCheck your score: \\n0 – Data Silos, 5-10 – Collect,  \\n10-20 – Describe, 20-30 – Discover, \\n30-35 – Predict, 35-40 - Advise', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 37}),\n",
       " Document(page_content='What Does it Take to Create \\na Data Science Capability?\\nData Science is all about building teams and culture.\\nMany organizations (both commercial and government) see the \\npotential in capitalizing on data to unlock operational efficiencies, \\nto create new services and experiences, and to propel innovation. \\nUnfortunately, too many business leaders invest in one-off technical \\nsolutions— with a big price tag and mixed results— instead of \\ninvesting in building a strategic Data Science capability. A Data \\nScience capability embeds and operationalizes Data Science across \\nan enterprise such that it can deliver the next level of organizational \\nperformance and return on investment. A Data Science capability \\nmoves an organization beyond performing pockets of analytics to an \\nenterprise approach that uses analytical insights as part of the normal \\ncourse of business. When building a capability, it is important for an \\norganization to first identify its analytic goals (i.e., what it is trying \\nto achieve through analytics) and then assess its readiness to achieve \\nthose goals – examining both technical readiness and organizational \\nreadiness. An organization can then make strategic choices on how to \\naddress gaps and begin to build their capability. \\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 38}),\n",
       " Document(page_content=' Source: Booz Allen Hamilton \\nCOMPUTER SCIENCE\\nProvides the environment \\nin which data products \\nare created.DOMAIN EXPERTISE\\nProvides understanding \\nof the reality in which a \\nproblem space exists.\\nMATHEMATICS\\nProvides the theoretical \\nstructure in which Data \\nScience problems \\nare examined.\\nThe Data Science Venn Diagram  (inspired by [12])\\n39 Start Here for the Basics 39 Start Here for the BasicsBuilding Y our Data Science Team\\nA critical component to any Data Science capability is having the  \\nright team. Data Science depends on a diverse set of skills as shown  \\nin The Data Science Venn Diagram. Computers provide the \\nenvironment in which data-driven hypotheses are tested, and as such, \\ncomputer science is necessary for data manipulation and processing. \\nMathematics provides the theoretical structure in which Data Science \\nproblems are examined. A rich background in statistics, geometry, \\nlinear algebra, and calculus are all important to understand the basis \\nfor many algorithms and tools. Finally, domain expertise contributes  \\nto an understanding of what problems actually need to be solved,  \\nwhat kind of data exists in the domain, and how the problem space \\nmay be instrumented and measured.\\nRemember that Data Science is a team sport. Most of the time, you \\nwill not be able to find the rare “unicorns” - people with expertise \\nacross all three of the skill areas. Therefore, it is important to build a \\nblended team that covers all three elements of the Data Science  \\nVenn Diagram. ', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 39}),\n",
       " Document(page_content=' Source: Booz Allen Hamilton BALANCING THE DATA  \\nSCIENCE TEAM EQUATION\\nBalancing the composition of a Data Science team \\nis much like balancing the reactants and products in \\na chemical reaction. Each side of the equation must \\nrepresent the same quantity of any particular element. \\nIn the case of Data Science, these elements are the \\nfoundational technical skills Computer Science (CS), \\nMathematics (M) and Domain Expertise (DE). The \\nreactants, your Data Scientists, each have their own \\nunique skills compositions. You must balance the staff \\nmix to meet the skill requirements of the Data Science \\nteam, the product in the reaction. If you don’t correctly \\nbalance the equation, your Data Science team will not \\nhave the desired impact on the organization.\\n2 CS M2 + 2 CS + M DE → CS4 M5 DE\\nIn the example above, your project requires four parts \\ncomputer science, ﬁve parts mathematics and one part \\ndomain expertise. Given the skills mix of the staff, ﬁve \\npeople are needed to balance the equation. Throughout \\nyour Data Science project, the skills requirements of \\nthe team will change. You will need to re-balance the \\nequation to ensure the reactants balance with  \\nthe products.\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 40}),\n",
       " Document(page_content='41 Start Here for the Basics 41 Start Here for the BasicsUnder standing What Makes  \\na Data Scientist \\nData Science often requires a significant investment of time across \\na variety of tasks. Hypotheses must be generated and data must be \\nacquired, prepared, analyzed, and acted upon. Multiple techniques \\nare often applied before one yields interesting results. If that seems \\ndaunting, it is because it is. Data Science is difficult, intellectually \\ntaxing work, which requires lots of talent: both tangible technical \\nskills as well as the intangible “x-factors.”\\nThere are four independent yet comprehensive foundational Data \\nScience competency clusters that, when considered together, convey \\nthe essence of what it means to be a successful Data Scientist. There \\nare also reach back competencies that complement the foundational \\nclusters but do not define the core tradecraft or attributes of the Data \\nScience team. \\nData Science Competency Framework  \\n(see [13] for complete framework) \\nClusters Competencies Description\\nTechnical: \\n“Knows How and \\nWhat to do”Advanced Mathematics; \\nComputer Science; Data \\nMining and Integration; \\nDatabase Science; Research \\nDesign; Statistical Modeling; \\nMachine Learning; \\nOperations Research; \\nProgramming and ScriptingThe technical competency \\ncluster depicts the \\nfoundational technical \\nand specialty knowledge \\nand skills needed for \\nsuccessful performance \\nin each job or role.\\nData Science \\nConsulting:  \\n“Can Do in \\na Client and \\nCustomer \\nEnvironment”Collaboration and Teamwork; \\nCommunications; Data \\nScience Consulting; Ethics \\nand IntegrityThe characteristics in the \\nconsulting competency \\ncluster can help Data \\nScientists easily integrate \\ninto various market or \\ndomain contexts and partner \\nwith business units to \\nunderstand the environment \\nand solve complex problems.\\nCognitive:  \\n“Able to Do or \\nLearn to Do”Critical Thinking; Inductive \\nand Deductive Reasoning; \\nProblem SolvingThe cognitive competency \\ncluster represents the type \\nof critical thinking and \\nreasoning abilities (both \\ninductive and deductive) a \\nData Scientist should have to \\nperform their job.\\nPersonality:  \\n“Willing or \\nMotivated to Do”Adaptability/Flexibility; \\nAmbiguity Tolerance; Detail \\nOrientation; Innovation and \\nCreativity; Inquisitiveness; \\nPerseverance; Resilience \\nand Hardiness; Self-\\nConﬁdence; Work EthicThe personality competency \\ncluster describes the \\npersonality traits that drive \\nbehaviors that are beneﬁcial \\nto Data Scientists, such as \\ninquisitiveness, creativity, \\nand perseverance.\\nReach Back Competencies for Data Science Teams\\nBusiness Acumen; Data Visualization; Domain Expertise; Program Management » The Triple Threat Unicorn \\nIndividuals who are great at \\nall three of the Data Science \\nfoundational technical skills are \\nlike unicorns – very rare and if \\nyou’re ever lucky enough to find \\none they should be treated carefully. \\nWhen you manage these people:\\n ›Encourag e them to lead your \\nteam, but not manage it. \\nDon’t bog them down with \\nresponsibilities of management \\nthat could be done by other staff.\\n ›Put extr a effort into managing \\ntheir careers and interests \\nwithin your organization. Build \\nopportunities for promotion into \\nyour organization that allow \\nthem to focus on mentoring other \\nData Scientists and progressing \\nthe state of the art while also \\nadvancing their careers.\\n ›Make sure that the y have the \\nopportunity to present and \\nspread their ideas in many \\ndifferent forums, but also be \\nsensitive to their time.\\n Source: Booz Allen Hamilton ', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 41}),\n",
       " Document(page_content='The most important qualities of Data Scientists tend to be the \\nintangible aspects of their personalities. Data Scientists are by nature \\ncurious, creative, focused, and detail-oriented.\\n›› Curiosity  is necessary to peel apart a problem and examine the \\ninterrelationships between data that may appear superficially \\nunrelated.\\n›› Creativity  is required to invent and try new approaches to \\nsolving a problem, which often times have never been applied in \\nsuch a context before.\\n›› Focus  is required to design and test a technique over days and \\nweeks, find it doesn’t work, learn from the failure, and try again.\\n›› Attention to Detail is needed to maintain rigor, and to detect and \\navoid over-reliance on intuition when examining data.\\nWe have found the single most important attribute is flexibility in \\novercoming setbacks - the willingness to abandon one idea and try \\na new approach. Often, Data Science is a series of dead ends before, \\nat last, the way forward is identified. It requires a unique set of \\npersonality attributes to succeed in such an environment. Technical \\nskills can be developed over time: the ability to be flexible – and \\npatient, and persistent – cannot.\\nFinding the Athletes for Y our T eam\\nBuilding a Data Science team is complex. Organizations must \\nsimultaneously engage existing internal staff to create an “anchor” who \\ncan be used to recruit and grow the team, while at the same time \\nundergo organizational change and transformation to meaningfully \\nincorporate this new class of employee. Building a team starts with \\nidentifying existing staff within an organization who have a high \\naptitude for Data Science. Good candidates will have a formal \\nbackground in any of the three foundational technical skills we \\nmentioned, and will most importantly have the personality traits \\nnecessary for Data Science. They may often have advanced (masters or \\nhigher) degrees, but not always. The very first staff you identify should \\nalso have good leadership traits and a sense of purpose for the \\norganization, as they will lead subsequent staffing and recruiting \\nefforts. Don’t discount anyone – you will find Data Scientists in the \\nstrangest places with the oddest combinations of backgrounds. » Don’t judge a book by its \\ncover, or a Data Scientist by \\nhis or her degree in this case. \\nAmazing Data Scientists can \\nbe found anywhere. Just look \\nat the diverse and surprising \\nsampling of degrees held by \\nOur Experts:\\n ›Bioinformatics\\n ›Biomedic al Engineering\\n ›Bioph ysics\\n ›Business\\n ›Computer Gr aphics\\n ›Computer S cience\\n ›English\\n ›Forest Management\\n ›History\\n ›Industrial Engineer ing\\n ›Infor mation Technology\\n ›Mathematics\\n ›Natio nal Security Studies\\n ›Operatio ns Research\\n ›Physics\\n ›Wild life & Fisheries \\nManagement\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 42}),\n",
       " Document(page_content=\"43 Start Here for the Basics 43 Start Here for the BasicsShaping the Culture\\nIt is no surprise—building a culture is hard and there is just as \\nmuch art to it as there is science. It is about deliberately creating the \\nconditions for Data Science to flourish (for both Data Scientists and \\nthe average employee). You can then step back to empower collective \\nownership of an organic transformation. \\nData Scientists are fundamentally curious and imaginative. We have \\na saying on our team, “We’re not nosy, we’re Data Scientists.” These \\nqualities are fundamental to the success of the project and to gaining \\nnew dimensions on challenges and questions. Often Data Science \\nprojects are hampered by the lack of the ability to imagine something \\nnew and different. Fundamentally, organizations must foster trust and \\ntransparent communication across all levels, instead of deference to \\nauthority, in order to establish a strong Data Science team. Managers \\nshould be prepared to invite participation more frequently, and offer \\nexplanation or apology less frequently.\\nIt is important to provide a path into the Data Science “club” and  \\nto empower the average employee to feel comfortable and conversant \\nwith Data Science. For something to be part of organizational  \\nculture, it must be part of the fabric of the employee behavior.  \\nThat means employees must interact with and use data products \\nin their daily routines. Another key ingredient to shaping the \\nright culture is that all employees need a baseline of Data Science \\nknowledge, starting with a common lexicon, to facilitate productive \\ncollaboration and instill confidence. While not everyone will be \\nData Scientists, employees need to identify with Data Science and \\nbe equipped with the knowledge, skills, and abilities to work with \\nData Scientists to drive smarter decisions and deliver exponential \\norganizational performance. »  “I'm not nosey, I'm a Data    \\nScientist” \\n ›Always remember that \\nunrelenting curiosity and \\nimagination should be the \\nhallmarks of Data Science. They \\nare fundamental to the success \\nof every Data Science project.\", metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 43}),\n",
       " Document(page_content=' Source: Booz Allen Hamilton \\nData Science Operating Models  \\n(see [13] for complete descriptions)Selecting Y our Operating Model\\nDepending on the size, complexity, and the business drivers, \\norganizations should consider one of three Data Science operating \\nmodels: Centralized, Deployed, or Diffused. These three models are \\nshown in the figure, Data Science Operating Models.\\nCentralized Data Science teams serve the organization across all business \\nunits. The team is centralized under a Chief Data Scientist and they all \\nco-locate together. The domain experts come to this organization for \\nbrief rotational stints to solve challenges around the business. This model \\nprovides greater efficiency with limited Data Science resources but can also \\ncreate the perceived need to compete with other business units for Data \\nScience talent. To address this challenge, it is important to place emphasis \\non portfolio management and creating transparency on how organizations \\nwill identify and select Data Science projects. \\nDeployed Data Science  teams go to the business unit and reside there for \\nshort- or long-term assignments. They are their own entity and they work \\nwith the domain experts within the group to solve hard problems. In \\nthe deployed model, Data Science teams collectively develop knowledge \\nacross business units, with central leadership as a bridging mechanism for \\naddressing organization-wide issues. However, Data Science teams are \\naccountable to business unit leadership and their centralized leadership, \\nwhich could cause confusion and conflict. In this model, it is important  \\nto emphasize conflict management to avoid competing priorities. \\nThe Diffused Data Science  team is one that is fully embedded with each \\ngroup and becomes part of the long-term organization. These teams work \\nbest when the nature of the domain or business unit is already one focused \\non analytics. In the Diffused Model, teams can quickly react to high-\\npriority business unit needs. However, the lack of central management can \\nresult in duplicate software and tools. Additionally, business units with the \\nmost money will often have full access to analytics while other units have \\nnone—this may not translate to the greatest organizational impact. In this \\nmodel, it is important to establish cross-functional groups that promote \\norganization-wide governance and peer collaboration. \\nFull descriptions of each operating model can be found in Booz Allen’s Tips for \\nBuilding a Data Science Capability [13].\\nCENTRALIZED\\nBusiness units bring their \\nproblems to a centralized \\nData Science team.\\nDIFFUSED\\nData Scientists are fully \\nembedded within the  \\nbusiness units.\\nDEPLOYED\\nSmall Data Science teams \\nare forward deployed to \\nbusiness units.\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 44}),\n",
       " Document(page_content='45 Start Here for the Basics 45 Start Here for the BasicsHow to Generate Momentum\\nA Data Science effort can start at the grass roots level by a few folks \\ntackling hard problems, or as directed by the Chief Executive Officer, \\nChief Data Officer, or Chief Analytics Officer. Regardless of how an \\neffort starts, political headwinds often present more of a challenge \\nthan solving any technical hurdles. To help battle the headwinds, it is \\nimportant to generate momentum and prove the value a Data Science \\nteam can provide. The best way to achieve this is usually through \\na Data Science prototype or proof of concept. Proofs of concepts \\ncan generate the critical momentum needed to jump start any Data \\nScience Capability Four qualities, in particular, are essential for every \\nData Science prototype:\\n1. Organizational Buy-in: A prototype will only succeed if the \\nindividuals involved believe in it and are willing to do what \\nthey can to make it successful. A good way to gauge interest \\nis to meet with the middle managers; their views are usually \\nindicative of the larger group. \\n2. Clear ROI:  Before choosing a prototype problem, ensure that \\nthe ROI of the analytic output can be clearly and convincingly \\ndemonstrated for both the project and the organization as a \\nwhole. This outcome typically requires first reaching consensus \\non how the ROI will be determined and measured, so that the \\nbenefit can be quantified.\\n3. Necessary Data: Before selecting a prototype, you must first \\ndetermine exactly what data is needed, whether it will actually \\nbe available, and what it will cost in terms of time and expense. \\nIt is important to note that organizations do not need all the \\npossible data – they can still create successful analytics even \\nwith some gaps.\\n4. Limited Complexity and Duration:  The problem addressed \\nby the prototype should achieve a balance between being too \\ncomplex and too easy. Organizations new to Data Science often \\ntry to show its value with highly complex projects. However, \\nthe greater the complexity, the greater the risk of failure. At the \\nsame time, if the problem is too easy to solve, senior leaders \\nand others in the organization may not see the need for Data \\nScience. Look for efforts that could benefit from large datasets, \\nor bringing together disparate datasets that have never been \\ncombined before, as opposed to those that require complex \\nanalytic approaches. In these cases, there is often low-hanging \\nfruit that can lead to significant value for the organization.  \\n \\n \\n \\n ', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 45}),\n",
       " Document(page_content='', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 46}),\n",
       " Document(page_content='TAKE OFF   the  TRAINING WHEELS\\nTHE PRACTITIONER’S GUIDE  \\nTO DATA SCIENCE\\nRead this section to get beyond the hype and \\nlearn the secrets of being a Data Scientist.', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 47}),\n",
       " Document(page_content='Guiding Principles\\nFailing is good; failing quickly is even better.\\nThe set of guiding principles that govern how we conduct the \\ntradecraft of Data Science are based loosely on the central tenets  \\nof innovation, as the two areas are highly connected. These principles \\nare not hard and fast rules to strictly follow, but rather key tenets  \\nthat have emerged in our collective consciousness. You should use \\nthese to guide your decisions, from problem decomposition  \\nthrough implementation.\\n ›Be willing to fail.  At the core of Data Science is the idea of \\nexperimentation. Truly innovative solutions only emerge when \\nyou experiment with new ideas and applications. Failure is an \\nacceptable byproduct of experimentation. Failures locate regions \\nthat no longer need to be considered as you search for a solution.  \\n ›Fail often and learn quickly. In addition to a willingness to fail, be \\nready to fail repeatedly. There are times when a dozen approaches \\nmust be explored in order to find the one that works. While you \\nshouldn’t be concerned with failing, you should strive to learn from \\nthe attempt quickly. The only way you can explore a large number \\nof solutions is to do so quickly. \\n ›Keep the goal in mind.  You can often get lost in the details and \\nchallenges of an implementation. When this happens, you lose \\nsight of your goal and begin to drift off the path from data to \\nanalytic action. Periodically step back, contemplate your goal, and \\nevaluate whether your current approach can really lead you where \\nyou want to go.  \\n ›Dedication and focus lead to success. You must of ten explore \\nmany approaches before finding the one that works. It’s easy to \\nbecome discouraged. You must remain dedicated to your analytic \\ngoal. Focus on the details and the insights revealed by the data. \\nSometimes seemingly small observations lead to big successes.  \\n ›Complicated does not equal better. As technical practitioners, we \\nhave a tendency to explore highly complex, advanced approaches. \\nWhile there are times where this is necessary, a simpler approach \\ncan often provide the same insight. Simpler means easier and \\nfaster to prototype, implement and verify.  » Tips From the Pros\\n It can be easier to rule out a solution \\nthan conﬁrm its correctness. As a \\nresult, focus on exploring obvious \\nshortcomings that can quickly \\ndisqualify an approach. This will allow \\nyou to focus your time on exploring \\ntruly viable approaches as opposed to \\ndead ends.\\n » Tips From the Pros\\nIf the ﬁrst thing you try to do is to \\ncreate the ultimate solution, you will \\nfail, but only after banging your head \\nagainst a wall for several weeks.\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 48}),\n",
       " Document(page_content='The Importance of Reason\\nBeware: in the world of Data Science, if it walks like a duck \\nand quacks like a duck, it might just be a moose.\\nData Science supports and encourages shifting between deductive \\n(hypothesis-based) and inductive (pattern-based) reasoning.  \\nInductive reasoning and exploratory data analysis provide a means  \\nto form or refine hypotheses and discover new analytic paths.  \\nModels of reality no longer need to be static. They are constantly \\ntested, updated and improved until better models are found.\\nThe analysis of big data has brought inductive reasoning to the \\nforefront. Massive amounts of data are analyzed to identify \\ncorrelations. However, a common pitfall to this approach is confusing \\ncorrelation with causation. Correlation implies but does not prove \\ncausation. Conclusions cannot be drawn from correlations until the \\nunderlying mechanisms that relate the data elements are understood. \\nWithout a suitable model relating the data, a correlation may simply \\nbe a coincidence.  »  Correlation without \\nCausat ion\\nA common example of this \\nphenomenon is the high correlation \\nbetween ice cream consumption and \\nthe murder rate during the summer \\nmonths. Does this mean ice cream \\nconsumption causes murder or, \\nconversely, murder causes ice cream \\nconsumption? Most likely not, but \\nyou can see the danger in mistaking \\ncorrelation for causation. Our job as \\nData Scientists is making sure we \\nunderstand the difference. \\n49 Take off the Training Wheels', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 49}),\n",
       " Document(page_content='››\\nPaul Yacci\\nThe Dangers of Rejection\\nIn the era of big \\ndata, one piece \\nof analysis that \\nis frequently \\noverlooked is \\nthe problem of \\nﬁnding patterns \\nwhen there \\nare actually no \\napparent patterns. In statistics \\nthis is referred to as Type I error. \\nAs scientists, we are always \\non the lookout for a new or \\ninteresting breakthrough that \\ncould explain a phenomenon. \\nWe hope to see a pattern in our \\ndata that explains something \\nor that can give us an answer. \\nThe primary goal of hypothesis \\ntesting is to limit Type I error. \\nThis is accomplished by using \\nsmall α values. For example, \\na α value of 0.05 states that \\nthere is a 1 in 20 chance that \\nthe test will show that there \\nis something signiﬁcant when \\nin actuality there isn’t. This \\nproblem compounds when \\ntesting multiple hypotheses. \\nWhen running multiple \\nhypothesis tests, we are likely \\nto encounter Type I error. As \\nmore data becomes available \\nfor analysis, Type I error \\nneeds to be controlled. \\nOne of my projects required \\ntesting the difference between \\nthe means of two microarray \\ndata samples. Microarray \\ndata contains thousands of \\nmeasurements but is limited \\nin the number of observations. \\nA common analysis approach \\nis to measure the same genes \\nunder different conditions. If \\nthere is a signiﬁcant enough \\ndifference in the amount of \\ngene expression between the \\ntwo samples, we can say that \\nthe gene is correlated with a \\nparticular phenotype. One way \\nto do this is to take the mean of \\neach phenotype for a particular gene and formulate a hypothesis \\nto test whether there is a \\nsigniﬁcant difference between \\nthe means. Given that we were \\nrunning thousands of these tests \\nat α = 0.05, we found several \\ndifferences that were signiﬁcant. \\nThe problem was that some \\nof these could be caused by \\nrandom chance. \\nMany corrections exist to \\ncontrol for false indications of \\nsigniﬁcance. The Bonferroni \\ncorrection is one of the most \\nconservative. This calculation \\nlowers the level below which you \\nwill reject the null hypothesis \\n(your p value). The formula is \\nalpha/n , where n equals the \\nnumber of hypothesis tests \\nthat you are running. Thus, if \\nyou were to run 1,000 tests of \\nsigniﬁcance at α = 0.05, your \\np value should be less than \\n0.00005 (0.05/1,000) to reject the \\nnull hypothesis. This is obviously \\na much more stringent value.  \\nA large number of the previously \\nsigniﬁcant values were no longer \\nsigniﬁcant, revealing the true \\nrelationships within the data.\\nThe corrected signiﬁcance gave \\nus conﬁdence that the observed \\nexpression levels were due to \\ndifferences in the cellular gene \\nexpression rather than noise. We \\nwere able to use this information \\nto begin investigating what \\nproteins and pathways were \\nactive in the genes expressing \\nthe phenotype of interest. By \\nsolidifying our understanding \\nof the causal relationships, we \\nfocused our research on the \\nareas that could lead to new \\ndiscoveries about gene function \\nand, ultimately to improved \\nmedical treatments.\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 50}),\n",
       " Document(page_content='Reason and common sense are foundational to Data Science. Without these, data is \\nsimply a collection of bits. Context, inferences and models are created by humans and \\ncarry with them biases and assumptions. Blindly trusting your analyses is a dangerous \\nthing that can lead to erroneous conclusions. When you approach an analytic \\nchallenge, you should always pause to ask yourself the following questions:\\n ›What problem are we trying  \\nto solve? Articulate the answer \\nas a sentence, especially when \\ncommunicating with the end-\\nuser. Make sure that it sounds \\nlike an answer. For example, \\n“Given a fixed amount of \\nhuman capital, deploying \\npeople with these priorities \\nwill generate the best return \\non their time.”\\n ›Does the approach make sense? \\nWrite out your analytic plan. \\nEmbrace the discipline of \\nwriting, as it brings structure \\nto your thinking. Back of \\nthe envelope calculations are \\nan existence proof of your \\napproach. Without this kind \\nof preparation, computers are \\npower tools that can produce \\nlots of bad answers really fast. \\n ›Does the answer make sense? \\nCan you explain the answer? \\nComputers, unlike children, \\ndo what they are told. Make \\nsure you spoke to it clearly by \\nvalidating that the instructions \\nyou provided are the ones you \\nintended. Document your \\nassumptions and make sure \\nthey have not introduced bias \\nin your work.\\n ›Is it a finding or a mistake?   \\nBe skeptical of surprise \\nfindings. Experience says that \\nit if seems wrong, it probably \\nis wrong. Before you accept \\nthat conclusion, however, \\nmake sure you understand  \\nand can clearly explain why  \\nit is wrong.  ›Does the analysis address the \\noriginal intent? Make sure \\nthat you are not aligning the \\nanswer with the expectations \\nof the client. Always speak \\nthe truth, but remember that \\nanswers of “your baby is ugly” \\nrequire more, not less, analysis.\\n ›Is the story complete? The goal \\nof your analysis is to tell an \\nactionable story. You cannot \\nrely on the audience to stitch \\nthe pieces together. Identify \\npotential holes in your \\nstory and fill them to avoid \\nsurprises. Grammar, spelling \\nand graphics matter; your \\naudience will lose confidence \\nin your analysis if your results \\nlook sloppy.\\n ›Where would we head next? \\nNo analysis is ever finished, \\nyou just run out of resources. \\nUnderstand and explain what \\nadditional measures could  \\nbe taken if more resources  \\nare found. » Tips From the Pros\\nBetter a short pencil than a \\nlong memory. End every day by \\ndocumenting where you are; you \\nmay learn something along the way. \\nDocument what you learned and why \\nyou changed your plan.\\n » Tips From the Pros\\nTest your answers with a friendly \\naudience to make sure your ﬁndings \\nhold water. \\n51 Take off the Training Wheels', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 51}),\n",
       " Document(page_content='Component Parts of  \\nData Science\\nThere is a web of components that interact to create your \\nsolution space. Understanding how they are connected  \\nis critical to your ability to engineer solutions to Data  \\nScience problems.\\nThe components involved in any Data Science project fall into a \\nnumber of different categories including the data types analyzed, the \\nanalytic classes used, the learning models employed and the execution \\nmodels used to run the analytics. The interconnection across these \\ncomponents, shown in the figure, Interconnection Among the Component \\nParts of Data Science , speaks to the complexity of engineering Data \\nScience solutions. A choice made for one component exerts influence \\nover choices made for others categories. For example, data types \\nlead the choices in analytic class and learning models, while latency, \\ntimeliness and algorithmic parallelization strategy inform the \\nexecution model. As we dive deeper into the technical aspects of  \\nData Science, we will begin with an exploration of these components \\nand touch on examples of each. \\n  Read this to get the quick and dirty:\\nWhen engineering a Data \\nScience solution, work from an \\nunderstanding of the components \\nthat define the solution space. \\nRegardless of your analytic goal, \\nyou must consider the data types  \\nwith which you will be working,  \\nthe classes of analytics  you will use \\nto generate your data product, how the learning models  embodied \\nwill operate and evolve, and the \\nexecution models that will govern \\nhow the analytic will be run. \\nYou will be able to articulate a \\ncomplete Data Science solution \\nonly after considering each of \\nthese aspects. \\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 52}),\n",
       " Document(page_content=' Source: Booz Allen Hamilton \\ndata\\nstreaming\\ndata\\nbatch\\ndata\\nstructured\\ndata\\nunstructured\\nanalytics\\ntransforming\\nanalytics\\nlearning\\nanalytics\\npredictive\\nlearning\\nsupervised\\nlearning\\nunsupervised\\nlearning\\nonline\\nlearning\\nofﬂine\\nexecution\\nbatch\\nexecution\\nstreaming\\nexecution\\nparallel\\nexecution\\nserial\\nEXECUTION  \\nMODELSDATA TYPES\\nANALYTIC   \\nCLASSESLEARNING  \\nMODELS\\nInterconnection Among the Component Parts of Data Science\\n53 Take off the Training Wheels', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 53}),\n",
       " Document(page_content='', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 54}),\n",
       " Document(page_content='Data Types\\nData types and analytic goals go hand-in-hand much like the chicken \\nand the egg; it is not always clear which comes first. Analytic goals are \\nderived from business objectives, but the data type also influences the \\ngoals. For example, the business objective of understanding consumer \\nproduct perception drives the analytic goal of sentiment analysis. \\nSimilarly, the goal of sentiment analysis drives the selection of a  \\ntext-like data type such as social media content. Data type also  \\ndrives many other choices when engineering your solutions. \\nThere are a number of ways to classify data. It is common to \\ncharacterize data as structured  or unstructured . Structured data exists \\nwhen information is clearly broken out into fields that have an  \\nexplicit meaning and are highly categorical, ordinal or numeric. \\nA related category, semi-structured, is sometimes used to describe \\nstructured data that does not conform to the formal structure of  \\ndata models associated with relational databases or other forms  \\nof data tables, but nonetheless contains tags or other markers. \\nUnstructured data, such as natural language text, has less clearly \\ndelineated meaning. Still images, video and audio often fall under  \\nthe category of unstructured data. Data in this form requires \\npreprocessing to identify and extract relevant ‘features.’ The features \\nare structured information that are used for indexing and retrieval,  \\nor training classification, or clustering models. \\nData may also be classified by the rate at which it is generated, \\ncollected or processed. The distinction is drawn between streaming \\ndata that arrives constantly like a torrent of water from a fire \\nhose, and batch data, which arrives in buckets. While there is \\nrarely a connection between data type and data rate, data rate has \\nsignificant influence over the execution model chosen for analytic \\nimplementation and may also inform a decision of analytic class or \\nlearning model.\\n55 Take off the Training Wheels', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 55}),\n",
       " Document(page_content=' Source: Booz Allen Hamilton Classes of Analytic T echniques\\nAs a means for helping conceptualize the universe of possible analytic \\ntechniques, we grouped them into nine basic classes. Note that \\ntechniques from a given class may be applied in multiple ways to \\nachieve various analytic goals. Membership in a class simply indicates \\na similar analytic function. The nine analytic classes are shown in the \\nfigure, Classes of Analytic Techniques .\\n›» Transforming Analytics\\n ›Aggregation : Techniques to summarize the data. These \\ninclude basic statistics (e.g., mean, standard deviation), \\ndistribution fitting, and graphical plotting.\\n ›Enrichment : Techniques for adding additional information \\nto the data, such as source information or other labels.\\n ›Processing : Techniques that address data cleaning, \\npreparation, and separation. This group also includes \\ncommon algorithm pre-processing activities such as \\ntransformations and feature extraction.\\n›» Learning Analytics\\n ›Regression : Techniques for estimating relationships among \\nvariables, including understanding which variables are \\nimportant in predicting future values.\\n ›Clustering : Techniques to segment the data into naturally \\nsimilar groups.\\n ›Classification : Techniques to identify data element  \\ngroup membership.\\n ›Recommendation : Techniques to predict the rating or \\npreference for a new entity, based on historic preference  \\nor behavior.\\n›» Predictive Analytics\\n ›Simulation : Techniques to imitate the operation of a real-\\nworld process or system. These are useful for predicting \\nbehavior under new conditions.\\n ›Optimization : Operations Research techniques focused on \\nselecting the best element from a set of available alternatives \\nto maximize a utility function.\\nAggregation Enrichment Processing Simulation Optimization Regression Clustering Classiﬁcation RecommendTRANSFORMING LEARNINGANALYTIC CLASSESPREDICTIVE\\nClasses of Analytic Techniques\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 56}),\n",
       " Document(page_content=' Source: Booz Allen Hamilton Learning Models\\nAnalytic classes that perform predictions, such as regression, \\nclustering, classification and recommendation employ learning \\nmodels. These models characterize how the analytic is trained to \\nperform judgments on new data based on historic observation. \\nAspects of learning models describe both the types of judgments \\nperformed and how the models evolve over time, as shown in the \\nfigure, Analytic Learning Models .\\nLearning models are typically described as belonging to the categories \\nof unsupervised or supervised learning. Supervised learning takes \\nplace when a model is trained using a labeled dataset that has a known \\nclass or category associated with each data element. The model relates \\nfeatures found in training instances with labels so that predictions \\ncan be made for unlabeled instances. Unsupervised learning involves \\nno a-priori knowledge about the classes into which data can be \\nplaced. Unsupervised learning uses the features in the dataset to \\nform groupings based on feature similarity. Semi-supervised learning \\nis a hybrid between these two approaches, using a small amount of \\nlabeled data in conjunction with a large amount of unlabeled data. \\nThis is done to improve learning accuracy in cases where only a \\nsmall number of labeled observations are available for learning.\\nThere are a variety of ways to train learning models. A useful \\ndistinction is between those that are trained in a single pass, which are \\nknown as offline models, and those that are trained incrementally over \\ntime, known as online models. Many learning approaches have online \\nor offline variants. The decision to use one or another is based on the \\nanalytic goals and execution models chosen.\\nGenerating an offline model requires taking a pass over the entire \\ntraining dataset. Improving the model requires making separate \\npasses over the data. These models are static in that once trained, their \\npredictions will not change until a new model is created through a \\nsubsequent training stage. Offline model performance is easier to \\nevaluate due to this deterministic behavior. Deployment of the model \\ninto a production environment involves swapping out the old model \\nfor the new.\\nOnline models dynamically evolve over time, meaning they only \\nrequire a single deployment into a production setting. The fact that Analytic Learning Models\\n »Reinforcement Learning  \\nin Action\\nThe possibilities of Reinforcement \\nLearning captured significant \\nattention with the publication of a \\nstudy in the journal Nature in which \\na computer agent learned to play 49 \\ndifferent video games with accuracy \\nrivaling a professional game tester [14]. \\nThe agent was able to achieve these \\nresults using only the raw screen \\npixels and game score as input. This \\napproach represents the first artificial \\nintelligence agent that is capable \\nof learning complex tasks while \\nbridging between high-dimensional \\nsensory inputs and actions.\\nUnsupervisedSemi-\\nSupervisedSupervised\\nOfﬂine Reinforcement OnlineLEARNING STYLE TRAINING STYLE\\n57 Take off the Training Wheels', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 57}),\n",
       " Document(page_content='these models do not have the entire dataset available when being \\ntrained is a challenge. They must make assumptions about the data \\nbased on the examples observed; these assumptions may be sub-\\noptimal. The impact of sub-optimal predictions can be mitigated in \\ncases where feedback on the model’s predictions is available. Online \\nmodels can rapidly incorporate feedback to improve performance.\\nOne such training style is known as Reinforcement Learning. Under \\nthis approach, an algorithm takes action in an environment and \\nincrementally learns how to achieve goals based on the response to a \\nfunction used to determine the quality of its results. Reinforcement \\nlearning is generally applicable to complex, real-world tasks that \\ninvolve optimization, such as navigation or trading. Due to the \\npublication of many promising results from Reinforcement Learning \\nalgorithms, the popularity of this technique has risen dramatically in \\nrecent years along with Deep Learning. \\nExecution Models\\nExecution models describe how data is manipulated to perform \\nan analytic function. They may be categorized across a number \\nof dimensions. Execution Models are embodied by an execution \\nframework, which orchestrates the sequencing of analytic \\ncomputation. In this sense, a framework might be as simple as a \\nprogramming language runtime, such as the Python interpreter, or \\na distributed computing framework that provides a specific API for \\none or more programming languages such as Hadoop, MapReduce \\nor Spark. Grouping execution models based on how they handle data \\nis common, classifying them as either batch or streaming execution \\nmodels. The categories of execution model are shown in the figure, \\nAnalytic Execution Models.\\nAnalytic Execution Models\\nA batch execution model implies that data is analyzed in large \\nsegments, that the analytic has a state where it is running and a state \\nwhere it is not running and that little state is maintained in memory \\nbetween executions. Batch execution may also imply that the analytic \\nproduces results with a frequency on the order of several minutes or \\nmore. Batch workloads tend to be fairly easy to conceptualize because \\nSEQUENCING\\nSerial Parallel Batch StreamingSCHEDULING\\n Source: Booz Allen Hamilton \\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 58}),\n",
       " Document(page_content='they represent discrete units of work. As such, it is easy to identify \\na specific series of execution steps as well as the proper execution \\nfrequency and time bounds based on the rate at which data arrives. \\nDepending on the algorithm choice, batch execution models are  \\neasily scalable through parallelism. There are a number of frameworks \\nthat support parallel batch analytic execution. Most famously,  \\nHadoop provides a distributed batch execution model in its \\nMapReduce framework.\\nConversely, a streaming model analyzes data as it arrives. Streaming \\nexecution models imply that under normal operation, the analytic \\nis always executing. The analytic can hold state in memory and \\nconstantly deliver results as new data arrives, on the order of seconds \\nor less. Many of the concepts in streaming are inherent in the Unix-\\npipeline design philosophy; processes are chained together by linking \\nthe output of one process to the input of the next. As a result, many \\ndevelopers are already familiar with the basic concepts of streaming. \\nA number of frameworks are available that support the parallel \\nexecution of streaming analytics such as Storm, S4 and Samza. \\nThe choice between batch and streaming execution models often \\nhinges on analytic latency and timeliness requirements. Latency refers \\nto the amount of time required to analyze a piece of data once it \\narrives at the system, while timeliness refers to the average age of an \\nanswer or result generated by the analytic system. For many analytic \\ngoals, a latency of hours and timeliness of days is acceptable and \\nthus lend themselves to the implementation enabled by the batch \\napproach. Some analytic goals have up-to-the-second requirements \\nwhere a result that is minutes old has little worth. The streaming \\nexecution model better supports such goals.\\nBatch and streaming execution models are not the only dimensions \\nwithin which to categorize analytic execution methods. Another \\ndistinction is drawn when thinking about scalability. In many cases, \\nscale can be achieved by spreading computation over a number of \\ncomputers. In this context, certain algorithms require a large shared \\nmemory state, while others are easily parallelizable in a context \\nwhere no shared state exists between machines. This distinction has \\nsignificant impacts on both software and hardware selection when \\nbuilding out a parallel analytic execution environment. » Tips From the Pros\\nIn order to understand system capacity \\nin the context of streaming analytic \\nexecution, collect metrics including: \\nthe amount of data consumed, data \\nemitted, and latency. This will help  \\nyou understand when scale limits  \\nare reached.\\n59 Take off the Training Wheels', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 59}),\n",
       " Document(page_content='Fractal Analytic Model\\nData Science analytics are a lot like broccoli. \\nFractals are mathematical sets that display self-similar patterns. As \\nyou zoom in on a fractal, the same patterns reappear. Imagine a stalk \\nof broccoli. Rip off a piece of broccoli and the piece looks much like \\nthe original stalk. Progressively smaller pieces of broccoli still look like \\nthe original stalk.\\nData Science analytics are a lot like broccoli – fractal in nature in \\nboth time and construction. Early versions of an analytic follow the \\nsame development process as later versions. At any given iteration, the \\nanalytic itself is a collection of smaller analytics that often decompose \\ninto yet smaller analytics.\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 60}),\n",
       " Document(page_content='Setup Try\\nEvaluateDo\\nEvaluateIterative by Nature\\nGood Data Science is fractal in time  — an iterativ e process. Getting \\nan imperfect solution out the door quickly will gain more interest \\nfrom stakeholders than a perfect solution that is never completed. The \\nfigure, The Data Science Product Lifecycle,  summarizes the lifecycle of \\nthe Data Science product. \\nSet up  the infrastructure, aggregate and prepare the data, and \\nincorporate domain expert knowledge. Try different analytic \\ntechniques and models on subsets of the data. Evaluate  the models, \\nrefine, evaluate again, and select a model. Do something with your \\nmodels and results – deploy the models to inform, inspire action, and \\nact. Evaluate  the business results to improve the overall product.The Data Science Product Lifecycle  Source: Booz Allen Hamilton \\n61 Take off the Training Wheels', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 61}),\n",
       " Document(page_content='Smaller Pieces of Broccoli: A Data  \\nScience Product\\nComponents inside and outside of the Data Science product will \\nchange with each iteration. Let’s take a look under the hood of a  \\nData Science product and examine the components during one  \\nsuch iteration.\\nIn order to achieve a greater analytic goal, you need to first decompose \\nthe problem into sub-components to divide and conquer. The figure, \\nThe Fractal Analytic Model , shows a decomposition of the Data Science \\nproduct into four component pieces.\\nGOAL\\n›  Describe\\n›  Discover\\n›  Predict\\n›  Advise\\nACTION\\n›  Productization\\n›  Data Monetization\\n›  Insights & RelationshipsDATA\\n›  Text\\n›  Imagery\\n›  Waveform\\n›  Geo\\n›  Time Series\\nCOMPUTATIONAggregation\\nEnrichment\\nClustering\\nClassificationCLASSES OF ANALYTICS\\nThe Fractal Analytic Model Source: Booz Allen Hamilton \\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 62}),\n",
       " Document(page_content='GOAL\\nYou must first have some idea of your analytic goal and the end state \\nof the analysis. Is it to Discover, Describe, Predict, or Advise? It is \\nprobably a combination of several of those. Be sure that before you \\nstart, you define the business value of the data and how you plan to \\nuse the insights to drive decisions, or risk ending up with interesting \\nbut non-actionable trivia.\\nDATA\\nData dictates the potential insights that analytics can provide. Data \\nScience is about finding patterns in variable data and comparing those \\npatterns. If the data is not representative of the universe of events you \\nwish to analyze, you will want to collect that data through carefully \\nplanned variations in events or processes through A/B testing or \\ndesign of experiments. Datasets are never perfect so don’t wait for \\nperfect data to get started. A good Data Scientist is adept at handling \\nmessy data with missing or erroneous values. Just make sure to spend \\nthe time upfront to clean the data or risk generating garbage results.\\nCOMPUTATION\\nComputation aligns the data to goals through the process of creating \\ninsights. Through divide and conquer, computation decomposes \\ninto several smaller analytic capabilities with their own goals, data, \\ncomputation and resulting actions, just like a smaller piece of broccoli \\nmaintains the structure of the original stalk. In this way, computation \\nitself is fractal. Capability building blocks may utilize different \\ntypes of execution models such as batch computation or streaming, \\nthat individually accomplish small tasks. When properly combined \\ntogether, the small tasks produce complex, actionable results.\\nACTION\\nHow should engineers change the manufacturing process to generate \\nhigher product yield? How should an insurance company choose \\nwhich policies to offer to whom and at what price? The output of \\ncomputation should enable actions that align to the goals of the data \\nproduct. Results that do not support or inspire action are nothing but \\ninteresting trivia.\\nGiven the fractal nature of Data Science analytics in time and \\nconstruction, there are many opportunities to choose fantastic or \\nshoddy analytic building blocks. The Analytic Selection Process offers \\nsome guidance.\\n63 Take off the Training Wheels', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 63}),\n",
       " Document(page_content='The Analytic  \\nSelection Process\\nIf you focus only on the science aspect of Data Science you will \\nnever become a data artist.\\nA critical step in Data Science is to identify an analytic technique that \\nwill produce the desired action. Sometimes it is clear; a characteristic \\nof the problem (e.g., data type) points to the technique you should \\nimplement. Other times, however, it can be difficult to know where \\nto begin. The universe of possible analytic techniques is large. Finding \\nyour way through this universe is an art that must be practiced. We \\nare going to guide you on the next portion of your journey - becoming \\na data artist.\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 64}),\n",
       " Document(page_content='Decomposing the Problem\\nDecomposing the problem into manageable pieces is the first step \\nin the analytic selection process. Achieving a desired analytic action \\noften requires combining multiple analytic techniques into a holistic, \\nend-to-end solution. Engineering the complete solution requires that \\nthe problem be decomposed into progressively smaller sub-problems. \\nThe Fractal Analytic Model  embodies this approach. At any given \\nstage, the analytic itself is a collection of smaller computations that \\ndecompose into yet smaller computations. When the problem is \\ndecomposed far enough, only a single analytic technique is needed \\nto achieve the analytic goal. Problem decomposition creates multiple \\nsub-problems, each with their own goals, data, computations, and \\nactions. The concept behind problem decomposition is shown in the \\nfigure, Problem Decomposition Using the Fractal Analytic Model .\\nGOAL\\n›  Describe\\n›  Discover\\n›  Predict\\n›  Advise\\nACTION\\n›  Productization\\n›  Data Monetization\\n›  Insights & RelationshipsDATA\\n› Text\\n›  Imagery\\n›  Waveform\\n›  Geo\\n›  Time Series\\nDATAGOAL\\nACTION\\nDATAGOAL\\nACTIONAggregation\\nEnrichment\\nClustering\\nClassificationCLASSES OF ANALYTICS\\nProblem Decomposition Using the Fractal Analytic Model Source: Booz Allen Hamilton \\n65 Take off the Training Wheels', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 65}),\n",
       " Document(page_content='On the surface, problem decomposition appears to be a mechanical, \\nrepeatable process. While this may be true conceptually, it is \\nreally the performance of an art as opposed to the solving of an \\nengineering problem. There may be many valid ways to decompose \\nthe problem, each leading to a different solution. There may be \\nhidden dependencies or constraints that only emerge after you begin \\ndeveloping a solution. This is where art meets science. Although the \\nart behind problem decomposition cannot be taught, we have distilled \\nsome helpful hints to help guide you. When you begin to think about \\ndecomposing your problem, look for:\\n ›Compound analytic goals that create natural segmentation . \\nFor example, many problems focused on predicting future \\nconditions include both Discover and Predict goals.\\n ›Natural orderings of analytic goals. For example, when extracting \\nfeatures you must first identify candidate features and then \\nselect the features set with the highest information value. These \\ntwo activities form distinct analytic goals.  \\n ›Data types that dictate processing activities. For example, text or \\nimagery both require feature extraction.\\n ›Requirements for human-in-the-loop feedback.  For example, \\nwhen developing alerting thresholds, you might need to solicit \\nanalyst feedback and update the threshold based on their \\nassessment.\\n ›The need to combine multiple data sources.  For example, you may \\nneed to correlate two datasets to achieve your broader goal. \\nOften this indicates the presence of a Discover goal. \\nIn addition to problem decomposition providing a tractable approach \\nto analytic selection, it has the added benefit of simplifying a highly \\ncomplex problem. Rather than being faced with understanding the \\nentire end-to-end solution, the computations are discrete segments \\nthat can be explored. Note, however, that while this technique helps \\nthe Data Scientist approach the problem, it is the complete end-to-\\nend solution that must be evaluated.  » Tips From the Pros\\nOne of your ﬁrst steps should be to \\nexplore available data sources that \\nhave not been previously combined. \\nEmerging relationships between data \\nsources often allow you to pick low \\nhanging fruit.\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 66}),\n",
       " Document(page_content='Compare \\nDatasetsList of \\nrecently \\nregistered \\ncompany \\ndomains\\nList of \\ncandidate \\nspoofed \\ndomains\\nList of \\nrecently \\nregistered \\ncompany \\ndomainsDiscover spoofed \\ndomains\\nTest &\\nEvaluation\\nTest &\\nEvaluation\\nTest &\\nEvaluationCalculate\\nMetricSet\\nThresholdData\\nCollectionSimulate\\nSpoofed\\nData\\nStore\\nGenerated\\nDomains\\nGenerate\\nCandidate\\nDomainsAlert on spoofed domains to \\nprovide opportuinity to \\nminimize brand image and \\nconsumer conﬁdence damageDiscover likely \\ncandidates for \\nspoofed domains\\nList of candidate \\nspoofed domainsList of recently \\nregistered \\ncompany domainsDescribe closeness of \\nspoof to valid domains\\nQuantitative \\nmeasure of feature \\ninformation valueThreshold that balances \\nfalse positive and false \\nnegative rate\\nQuantitative threshold for \\nautomated result ranking› \\n› \\nList of candidate spoofed \\ndomains\\nList of recently registered \\ncompany domains\\nQuantitative measure of \\nfeature information value› \\n› \\n› Stephanie \\nRivera\\nIdentifying Spoofed Domains\\nIdentifying spoofed domains is important for an organization \\nto preserve their brand image and to avoid eroded customer \\nconﬁdence. Spoofed domains occur when a malicious actor  \\ncreates a website, URL or email address that users believe is \\nassociated with a valid organization. When users click the link,  \\nvisit the website or receive emails, they are subjected to some  \\ntype of nefarious activity.\\nOur team was faced with the problem of \\nidentifying spoofed domains for a commercial \\ncompany. On the surface, the problem sounded \\neasy; take a recently registered domain, check \\nto see if it is similar to the company’s domain \\nand alert when the similarity is sufﬁciently high. \\nUpon decomposing the problem, however, the \\nmain computation quickly became complicated.\\nWe needed a computation that determined \\nsimilarity between two domains. As we \\ndecomposed the similarity computation, \\ncomplexity and speed became a concern.  \\nAs with many security-related problems, fast alert speeds are vital. Result speed created \\nan implementation constraint that forced us to \\nre-evaluate how we decomposed the problem.\\nRevisiting the decomposition process led us \\nto a completely new approach. In the end, \\nwe derived a list of domains similar to those \\nregistered by the company. We then compared \\nthat list against a list of recently registered \\ndomains. The ﬁgure, Spoofed Domain Problem \\nDecomposition,  illustrates our approach. Upon \\ntesting and initial deployment, our analytic \\ndiscovered a spoofed domain within 48 hours.  ››\\nSpoofed Domain Problem Decomposition Source: Booz Allen Hamilton \\n67 Take off the Training Wheels', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 67}),\n",
       " Document(page_content='', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 68}),\n",
       " Document(page_content='SPEED:  The speed at which an \\nanalytic outcome must be produced \\n(e.g., near real-time, hourly, daily) or the time \\nit takes to develop and implement the \\nanalytic solution\\nANALYTIC COMPLEXITY:  \\nAlgorithmic complexity (e.g., complexity class \\nand execution resources) \\nACCURACY & PRECISION:  The ability \\nto produce exact versus approximate  \\nsolutions as well as the ability to provide a \\nmeasure of conﬁdence\\nDATA SIZE: The size of the dataset \\n(e.g., number of rows)\\nDATA COMPLEXITY:  The data \\ntype, formal complexity measures \\nincluding measures of overlap and \\nlinear separability, number of \\ndimensions /columns, and linkages \\nbetween datasets\\nSPEED\\nANALYTIC\\nCOMPLEXITYDATA\\nCOMPLEXITY\\nACCURACY\\n&\\nPRECISIONDATA SIZEImplementation Constraints\\nIn the spoofed domains case study, the emergence of an \\nimplementation constraint caused the team to revisit its approach. \\nThis demonstrates that analytic selection does not simply mean \\nchoosing an analytic technique to achieve a desired outcome. It also \\nmeans ensuring that the solution is feasible to implement. \\nThe Data Scientist may encounter a wide variety of implementation \\nconstraints. They can be conceptualized, however, in the context of \\nfive dimensions that compete for your attention: analytic complexity, \\nspeed, accuracy & precision, data size, and data complexity. Balancing \\nthese dimensions is a zero sum game - an analytic solution cannot \\nsimultaneously exhibit all five dimensions, but instead must make \\ntrades between them. The figure, Balancing the Five Analytic \\nDimensions,  illustrates this relationship. \\n \\nImplementation constraints occur when an aspect of the problem \\ndictates the value for one or more of these dimensions. As soon as  \\none dimension is fixed, the Data Scientist is forced to make trades \\namong the others. For example, if the analytic problem requires \\nactions to be produced in near real-time, the speed dimension is  \\nfixed and trades must be made among the other four dimensions. \\nUnderstanding which trades will achieve the right balance among  \\nthe five dimensions is an art that must be learned over time.As we compiled this section, we \\ntalked extensively about ways to \\ngroup and classify implementation \\nconstraints. After much discussion \\nwe settled on these five dimensions. \\nWe present this model in hopes  \\nthat others weigh in and offer  \\ntheir own perspectives.Balancing the Five Analytic Dimensions Source: Booz Allen Hamilton \\n69 Take off the Training Wheels', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 69}),\n",
       " Document(page_content='Some common examples of implementation  \\nconstraints include:\\n• Computation frequency.  The solution may need to run on a regular \\nbasis (e.g., hourly), requiring that computations be completed \\nwithin a specified window of time. The best analytic is useless if it \\ncannot solve the problem within the required time. \\n• Solution timeliness.  Some applications require near real-time \\nresults, pointing toward streaming approaches. While some \\nalgorithms can be implemented within streaming frameworks, \\nmany others cannot.  \\n• Implementation speed. A project may require that you rapidly \\ndevelop and implement a solution to quickly produce analytic \\ninsights. In these cases, you may need to focus on less complex \\ntechniques that can be quickly implemented and verified.\\n• Computational resource limitations.  Although you may be able \\nto store and analyze your data, data size may be sufficiently large \\nthat algorithms requiring multiple computations across the full \\ndataset are too resource intensive. This may point toward needing \\napproaches that only require a single pass on the data (e.g., canopy \\ncluster as opposed to k-means clustering).  \\n• Data storage limitations . There are times when big data becomes  \\nso big it cannot be stored or only a short time horizon can be \\nstored. Analytic approaches that require long time horizons may \\nnot be possible. \\nOrganizational policies and regulatory requirements are a major \\nsource of implicit constraints that merit a brief discussion. Policies \\nare often established around specific classes of data such as Personally \\nIdentifiable Information (PII) or Personal Health Information (PHI). \\nWhile the technologies available today can safely house information \\nwith a variety of security controls in a single system, these policies \\nforce special data handling considerations including limited retention \\nperiods and data access. Data restrictions impact the data size and \\ncomplexity dimensions outlined earlier, creating yet another layer of \\nconstraints that must be considered.  » Tips From the Pros\\nWhen possible, consider approaches \\nthat make use of previously computed \\nresults. Your algorithm will run  \\nmuch faster if you can avoid  \\nre-computing values across  \\nthe full time horizon of data.\\n » Tips From the Pros\\nOur Data Science Product Lifecycle  \\nhas evolved to produce results quickly \\nand then incrementally improve  \\nthe solution.\\n » Tips From the Pros\\nStreaming approaches may be useful \\nfor overcoming storage limitations.\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 70}),\n",
       " Document(page_content='4\\n Data \\nScience\\n3DESCRIBE  \\nDISCOVER  \\nPREDICT \\nADVISE 21\\nGuide to Analytic Selection\\nYour senses are incapable of perceiving the entire universe, so \\nwe drew you a map.\\nThe universe of analytic techniques is vast and hard to comprehend. \\nWe created this diagram to aid you in finding your way from data  \\nand goal to analytic action. Begin at the center of the universe  \\n(Data Science) and answer questions about your analytic goals and \\nproblem characteristics. The answers to your questions will guide you \\nthrough the diagram to the appropriate class of analytic techniques \\nand provide recommendations for a few techniques to consider.\\nn  TIP: There are several situations where dimensionality reduction may be needed:\\n ›Models fail to converge\\n ›Models produce results equivalent to  \\nrandom chance\\n ›You lack the computational power to \\nperform operations across the  feature space\\n ›You do not know which aspects of the \\ndata are\\n › the most important\\no  Feature Extraction  is a broad topic and is highly dependent upon the domain area.  \\nThis topic could be the subject of an entire book. As a result, a detailed exploration  \\nhas been omitted from this diagram. See the Featuring Engineering  and Feature \\nSelection sections in the Life in the Trenches  chapter for additional information.\\np  TIP: Always check data labels for correctness. This is particularly true for time stamps, \\nwhich may have reverted to system default values.\\nq  TIP: Smart enrichment can greatly speed-up computational time. It can also be a huge \\ndifferentiator between the accuracy of different end-to-end analytic solutions.\\n Source: Booz Allen Hamilton \\n71 Take off the Training Wheels', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 71}),\n",
       " Document(page_content='', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 72}),\n",
       " Document(page_content=' Data \\nScience\\nFILTERING \\nHow do I identify \\ndata based on \\nits absolute or \\nrelative values?\\nIMPUTATION \\nHow do I ﬁll in \\nmissing values \\nin my data?\\nDIMENSIONALITY \\nREDUCTION  n  \\nHow do I reduce \\nthe number of \\ndimensions \\nin my data?\\nNORMALIZATION & \\nTRANSFORMATION \\nHow do I reconcile \\nduplication \\nrepresentations \\nin the data?\\nFEATURE \\nEXTRACTION o  \\nPROCESSING p  \\nHow do I clean \\nand separate \\nmy data?If you want to add or remove data based on its value, start with:\\n› Relational algebra projection and selection \\nIf early results are uninformative and duplicative, start with:\\n› Outlier removal  › Gaussian ﬁlter\\n› Exponential smoothing › Median ﬁlter \\nIf you are unfamiliar with the dataset, start with \\nbasic statistics: \\n› Count › Standard deviation › Box plots\\n› Mean › Range  › Scatter plots \\nIf your approach assumes the data follows a \\ndistribution, start with:\\n› Distribution ﬁtting\\nIf you want to understand all the information \\navailable on an entity, start with:\\n› “Baseball card” aggregation    \\nIf you need to keep track of source information or other \\nuser-deﬁned parameters, start with:\\n› Annotation\\nIf you often process certain data ﬁelds together or use \\none ﬁeld to compute the value of another, start with:\\n› Relational algebra rename,  \\n› Feature addition (e.g., Geography, Technology, Weather)If you want to generate values from other observations in your dataset, start with:\\n› Random sampling\\n› Markov Chain Monte Carlo (MC)\\nIf you want to generate values without using other observations in your dataset, \\nstart with:\\n› Mean   › Regression models\\n› Statistical distributions\\nIf you need to determine whether there is multi-dimensional correlation, \\nstart with:\\n› PCA and other factor analysis\\nIf you can represent individual observations by membership in a group, start with:\\n› K-means clustering\\n› Canopy clustering\\nIf you have unstructured text data, start with:\\n› Term Frequency/Inverse Document Frequency (TF IDF) \\nIf you have a variable number of features but your \\nalgorithm requires a ﬁxed number, start with:\\n› Feature hashing\\nIf you are not sure which features are the most important, start with: \\n› Wrapper methods\\n› Sensitivity analysis\\nIf you need to facilitate understanding of the \\nprobability distribution of the space, start with: \\n› Self organizing maps\\nIf you suspect duplicate data elements, start with:\\n› Deduplication\\nIf you want your data to fall within a speciﬁed range, start with:\\n› Normalization  \\nIf your data is stored in a binary format, start with:\\n› Format Conversion \\nIf you are operating in frequency space, start with:\\n› Fast Fourier Transform (FFT),\\n› Discrete wavelet transform \\nIf you are operating in Euclidian space, start with:\\n› Coordinate transform\\nDESCRIBE  \\nHow do I develop \\nan understanding \\nof the content of \\nmy data?\\nENRICHMENT q \\nHow do I add \\nnew information \\nto my data?AGGREGATION \\nHow do I collect \\nand summarize \\nmy data?1\\n2\\n4\\n3\\nPREDICT\\nDISCOVER\\nADVISE\\n \\n Source: Booz Allen Hamilton \\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 73}),\n",
       " Document(page_content='If you are unfamiliar with the dataset, start with If you want to generate values from other observations in your dataset, start with:\\nIf you want to generate values without using other observations in your dataset, \\nIf you need to determine whether there is multi-dimensional correlation, \\nIf you can represent individual observations by membership in a group, start with:\\nCLASSIFICATION\\nHow do I \\npredict group \\nmembership?\\nIf you want an ordered set of clusters with variable precision, start with:  \\n› Hierarchical\\nr If you have a known number of clusters, start with:     \\n› X-means\\n› Canopy\\n› Apriori\\nIf you have text data, start with:   \\n› Topic modeling\\nIf you have non-elliptical clusters, start with:    \\n› Fractal\\n› DB Scan\\nIf you want soft membership in the clusters, start with:   \\n› Gaussian mixture models\\ns If you have an known number of clusters, start with:   \\n› K-means\\nIf your data has unknown  structure, start with:   \\n› Tree-based methods\\nIf statistical measures of importance are \\nneeded, start with:   \\n› Generalized linear models\\nIf statistical measures of importance are not \\nneeded, start with:   \\n› Regression with shrinkage (e.g., LASSO, Elastic net)\\n› Stepwise regression\\nIf you want to compare two groups\\n› T-test\\nIf you want to compare multiple groups\\n› ANOVA\\n2\\nDISCOVER  \\nWhat are the \\nkey relationships \\nin the data?REGRESSION \\nHow do I \\ndetermine which \\nvariables may \\nbe important?\\nHYPOTHESIS \\nTESTING\\nHow do I \\ntest ideas?CLUSTERING \\nHow do I segment \\nthe data to \\nﬁnd natural \\ngroupings?\\nDESCRIBE\\n Data \\nScience\\n3\\nPREDICT\\nADVISE\\n1\\n4\\nr  TIP:  Canopy clustering is good when you only want to make a single pass over the data.\\ns   TIP:  Use canopy or hierarchical clustering to estimate the number of clusters you \\nshould generate.\\n Source: Booz Allen Hamilton ', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 74}),\n",
       " Document(page_content=\"If you have known dependent relationships between variables\\n› Bayesian network\\nIf you are unsure of feature importance, start with:  \\n› Neural nets,\\n› Random forests\\n› Deep learning\\nIf you require a highly transparent model, start with:   \\n› Decision trees\\nIf you have <20 data dimensions, start with:   \\n› K-nearest neighbors\\nIf you have a large dataset with an unknown classiﬁcation \\nsignal, start with:    \\n› Naive bayes\\nIf you want to estimate an unobservable state based on \\nobservable variables, start with:    \\n› Hidden markov model\\nu If you don't know where else to begin, start with:   \\n› Support vector machines (SVM)\\n› Random forests\\nIf the data structure is unknown, \\nstart with:    \\n› Tree-based methods\\nIf you require a highly \\ntransparent model, start with:  \\n › Generalized linear models\\nIf you have <20 data dimensions, \\nstart with:   \\n› K-nearest neighbors\\nPREDICT \\nWhat are the \\nlikely future \\noutcomes?REGRESSION \\nHow do I predict \\na future value?\\nIf you only have knowledge of how people interact with items, \\nstart with:    \\n › Collaborative ﬁltering\\nIf you have a feature vector of item characteristics, start with:    \\n › Content-based methods\\nIf you only have knowledge of how items are connected to one \\nanother, start with:   \\n › Graph-based methods\\nRECOMMENDATION  vw  \\nHow do I predict relevant \\nconditions?CLASSIFICATION  t \\nHow do I \\npredict group \\nmembership?\\n3\\n2\\nDISCOVER\\n1\\nDESCRIBE\\n Data \\nScience\\n4\\nADVISE\\nIf you want an ordered set of clusters with variable precision, start with:  \\nIf your data has unknown  structure, start with:   \\nIf statistical measures of importance are \\nIf statistical measures of importance are not \\n› Regression with shrinkage (e.g., LASSO, Elastic net)\\nt  TIP: It can be difﬁcult to predict which classiﬁer will work best on your dataset.  \\nAlways try multiple classiﬁers. Pick the one or two that work the best to reﬁne and \\nexplore further.\\nu TIP:  These are our favorite, go-to classiﬁcation algorithms. \\nv  TIP:  Be careful of the “recommendation bubble”, the tendency of recommenders to \\nrecommend only what has been seen in the past.  \\nYou must ensure you add diversity to avoid this phenomenon. \\nw  TIP:  SVD and PCA are good tools for creating better features for recommenders.\\n Source: Booz Allen Hamilton \", metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 75}),\n",
       " Document(page_content=\"If the data structure is unknown, \\ntransparent model, start with:  \\nIf you have <20 data dimensions, \\nIf you only have knowledge of how people interact with items, \\nIf you have a feature vector of item characteristics, start with:    \\nIf you only have knowledge of how items are connected to one \\nADVISE \\nWhat course \\nof action \\nshould I take?If you have expert knowledge to capture\\n › Expert systems\\nIf you're looking for basic facts\\n › Logical reasoning\\nLOGICAL \\nREASONING\\nHow do I sort \\nthrough different \\nevidence?\\nIf you must model discrete entities, start with:   \\n › Discrete event simulation (DES)\\nIf there are a discrete set of possible states, start with:   \\n › Markov models\\nIf there are actions and interactions among autonomous \\nentities, start with:    \\n › Agent-based simulation\\nIf you do not need to model discrete entities, start with:    \\n › Monte Carlo simulation\\nIf you are modeling a complex system with feedback \\nmechanisms between actions, start with:    \\n› Systems dynamics\\nIf you require continuous tracking of system behavior, \\nstart with:   \\n › Activity-based simulation\\nIf you already have an understanding of what factors \\ngovern the system, start with:   \\n › ODES\\n › PDES\\nIf you have imprecise categories\\n › Fuzzy logic\\nSIMULATION\\nHow do I characterize\\na system that does not\\nhave a closed-form\\nrepresentation?\\nIf your problem is represented by a \\nnon-deterministic utility function, start with:   \\n › Stochastic search\\nIf approximate solutions are acceptable, \\nstart with:   \\n › Genetic algorithms\\n › Simulated annealing\\n › Gradient search\\nIf your problem is represented by a \\ndeterministic utility function, start with:   \\n › Linear programming\\n › Integer programming\\n › Non-linear programming\\nIf you have limited resources to search with\\n › Active learning\\nIf you want to try multiple models\\n › Ensemble learning\\nOPTIMIZATION \\nHow do I identify the \\nbest course of action \\nwhen my objective \\ncan be expressed as \\na utility function?4\\n2\\nDISCOVER\\nDESCRIBE\\n Data \\nScience\\n3\\nPREDICT\\n1\\n Source: Booz Allen Hamilton \", metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 76}),\n",
       " Document(page_content='', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 77}),\n",
       " Document(page_content='Compiled by: Booz Allen Hamilton\\nTechnique Description Tips From the ProsReferences we  \\nlove to read\\nActive \\nLearningIntelligent sample selection \\nto improve performance \\nof model.  Samples are \\nselected to provide the \\ngreatest information \\nto a learning model.Can be paired with a human in-the-loop \\nto help capture domain knowledge.Burr, Settles B. “Active \\nLearning: Synthesis Lectures \\non Artiﬁcial Intelligence and \\nMachine Learning.” Morgan \\n& Claypool, 2012. Print.\\nAgent Based \\nSimulationSimulates the actions \\nand interactions of \\nautonomous agents.In many systems, complex behavior \\nresults from surprisingly simple rules. \\nKeep the logic of your agents simple \\nand gradually build in sophistication.Macal, Charles, and Michael \\nNorth. “Agent-based Modeling and \\nSimulation.” Winter Simulation \\nConference . Austin, TX. 2009. \\nConference Presentation. \\nANOVAHypothesis testing for \\ndifferences between \\nmore than two groups.Check model assumptions before \\nutilizing, and watch out for Family Wise \\nerror when running multiple tests.Bhattacharyya, Gouri K., \\nand Richard A. Johnson. \\nStatistical Concepts and \\nModels . Wiley, 1977. Print.\\nAssociation \\nRule Mining \\n(Apriori)Data mining technique \\nto identify the common \\nco-occurances of items.Utilize when you have a need to understand \\npotential relationships between elements.Agrawal, Rakesh, and \\nRamakrishnan Srikant. \\n“Fast Algorithms for Mining \\nAssociation Rules.” Proc. Of \\n20th Intl. Conf. on VLDB . 1994. \\nConference Presentation.\\nBayesian \\nNetworkModels conditional \\nprobabilities amongst \\nelements, visualized as a \\nDirected Acyclic Graph.Calculate by hand before using larger \\nmodels to ensure understanding.Russel, Stuart, and Peter \\nNorvig. “Artiﬁcial Intelligence: \\nA Modern Approach.”\\xa0Prentice \\nHall, 2009 Print.\\xa0Detailed Table of Analytics\\nGetting you to the right starting point isn’t enough. We also \\nprovide a translator so you understand what you’ve been told.\\nIdentifying several analytic techniques that can be applied to your \\nproblem is useful, but their name alone will not be much help. The \\nDetailed Table of Analytics translates the names into something more \\nmeaningful. Once you’ve identified a technique in the Guide to \\nAnalytic Selection, find the corresponding row in the table. There you \\nwill find a brief description of the techniques, tips we’ve learned and a \\nfew references we’ve found helpful. \\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 78}),\n",
       " Document(page_content=\"Compiled by: Booz Allen HamiltonTechnique Description Tips From the ProsReferences we  \\nlove to read\\nCollaborative \\nFilteringAlso known as \\n'Recommendation,' suggest \\nor eliminate items from a \\nset by comparing a history \\nof actions against items \\nperformed by users. Finds \\nsimilar items based on who \\nused them or similar users \\nbased on the items they use.Use Singular Value Decomposition \\nbased Recommendation for cases \\nwhere there are latent factors in your \\ndomain, e.g., genres in movies.Owen, Sean, Robin Anil, Ted \\nDunning, and Ellen Friedman. \\nMahout in Action.  New Jersey: \\nManning, 2012. Print.\\nCoordinate \\nTransforma -\\ntionProvides a different \\nperspective on data.Changing the coordinate system for data, for \\nexample, using polar or cylindrical coordinates, \\nmay more readily highlight key structure in the \\ndata. A key step in coordinate transformations \\nis to appreciate multidimensionality and to \\nsystematically analyze subspaces of the data.Abbott, Edwin A., Flatland: A \\nRomance of Many Dimensions. \\nUnited Kingdom: Seely & Co., \\n1884. Print.\\nDeep LearningMethod that learns \\nfeatures that leads to \\nhigher concept learning.  \\nUsually very deep neural \\nnetwork architectures.Utilize a GPU to efﬁciently train complex \\nmodels.Bengio, Yoshua, and Yann \\nLeCun. “Scaling Learning \\nAlgorithms towards AI.” Large-\\nScale Kernel Machines . New \\nYork: MIT Press, 2007. Print.\\nDesign of \\nExperimentsApplies controlled \\nexperiments to quantify \\neffects on system output \\ncaused by changes to inputs.Fractional factorial designs can signiﬁcantly \\nreduce the number of different types of \\nexperiments you must conduct.Montgomery, Douglas. Design \\nand Analysis of Experiments. \\nNew Jersey: John Wiley \\n& Sons, 2012. Print.\\nDifferential \\nEquationsUsed to express \\nrelationships between \\nfunctions and their \\nderivatives, for example, \\nchange over time.Differential equations can be used to formalize \\nmodels and make predictions. The equations \\nthemselves can be solved numerically and \\ntested with different initial conditions to study \\nsystem trajectories.Zill, Dennis, Warren Wright, \\nand Michael Cullen. Differential \\nEquations with Boundary-Value \\nProblems.  Connecticut: Cengage \\nLearning, 2012. Print.\\nDiscrete Event \\nSimulationSimulates a discrete \\nsequence of events where \\neach event occurs at a \\nparticular instant in time. \\nThe model updates its state \\nonly at points in time when \\nevents occur.Discrete event simulation is useful when \\nanalyzing event based processes such as \\nproduction lines and service centers to \\ndetermine how system level behavior changes \\nas different process parameters change. \\nOptimization can integrate with simulation to \\ngain efﬁciencies in a process.Burrus, C. Sidney, Ramesh A. \\nGopinath, Haitao Guo, Jan E. \\nOdegard and Ivan W. Selesnick. \\nIntroduction to Wavelets and \\nWavelet Transforms: A Primer. \\nNew Jersey: Prentice Hall, 1998. \\nPrint. \\nDiscrete \\nWavelet \\nTransformTransforms time series \\ndata into frequency \\ndomain preserving \\nlocality information.Offers very good time and frequency \\nlocalization. The advantage over Fourier \\ntransforms is that it preserves both frequency \\nand locality. Burrus, C.Sidney, Ramesh \\nA. Gopinath, Haitao Guo, \\nJan E. Odegard, and Ivan W. \\nSelesnick. Introduction to \\nWavelets and Wavelet Transforms: \\nA Primer . New Jersey: \\nPrentice Hall, 1998. Print.\\nEnsemble \\nLearningLearning multiple models \\nand combining output to \\nachieve better performance.Be careful not to overﬁt data by having too many \\nmodel parameters and  overtraining.Dietterich, Thomas G. “Ensemble \\nMethods in Machine Learning.” \\nLecture Notes in Computer \\nScience. Springer, 2000. Print. \\nExpert \\nSystemsSystems that use symbolic \\nlogic to reason about facts.  \\nEmulates human reasoning.Useful to have a human readable explanation of \\nwhy a system came to a conclusion.Shortliffe, Edward H., and \\nBruce G. Buchanan. “A Model of \\nInexact Reasoning in Medicine.” \\nMathematical Biosciences. \\nElsevier B.V., 1975. Print. \\nExponential \\nSmoothingUsed to remove artifacts \\nexpected from collection \\nerror or outliers.In comparison to a using moving average \\nwhere past observations are weighted equally, \\nexponential smoothing assigns exponentially \\ndecreasing weights over time.Chatﬁeld, Chris, Anne B. \\nKoehler, J. Keith Ord, and \\nRalph D. Snyder. “A New Look \\nat Models for Exponential \\nSmoothing.” Journal of the Royal \\nStatistical Society: Series D (The \\nStatistician). Royal Statistical \\nSociety, 2001. Print.\\n79 Take off the Training Wheels\", metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 79}),\n",
       " Document(page_content='Compiled by: Booz Allen HamiltonTechnique Description Tips From the ProsReferences we  \\nlove to read\\nFactor \\nAnalysisDescribes variability among \\ncorrelated variables with the \\ngoal of lowering the number \\nof unobserved variables, \\nnamely, the factors.If you suspect there are inmeasurable \\ninﬂuences on your data, then you may want to \\ntry factor analysis.Child, Dennis. The Essentials of \\nFactor Analysis. United Kingdom: \\nCassell Educational, 1990. Print.\\nFast Fourier \\nTransformTransforms time series from \\ntime to frequency domain \\nefﬁciently. Can also be used \\nfor image improvement by \\nspatial transforms.Filtering a time varying signal can be done \\nmore effectively in the frequency domain. Also, \\nnoise can often be identiﬁed in such signals by \\nobserving power at aberrant frequencies.Mitra, Partha P., and Hemant \\nBokil. Observed Brain Dynamics.  \\nUnited Kingdom: Oxford \\nUniversity Press, 2008. Print.\\nFormat \\nConversionCreates a standard \\nrepresentation of data \\nregardless of source format. \\nFor example, extracting raw \\nUTF-8 encoded text from \\nbinary ﬁle formats such as \\nMicrosoft Word or PDFs.There are a number of open source software \\npackages that support format conversion and \\ncan interpret a wide variety of formats. One \\nnotable package is Apache Tikia.Ingersoll, Grant S., Thomas S. \\nMorton, and Andrew L. Farris. \\nTaming Text: How to Find, \\nOrganize, and Manipulate It.  New \\nJersey: Manning, 2013. Print.\\nFuzzy LogicLogical reasoning that \\nallows for degrees of truth \\nfor a statement.Utilize when categories are not clearly deﬁned.  \\nConcepts such as \"warm\", \"cold\", and \"hot\" can \\nmean different things at different temperatures \\nand domains.Zadeh L.A., \"Fuzzy Sets.” \\nInformation and Control. \\nCalifornia: University of \\nCalifornia, Berkeley, 1965. Print.\\nGaussian \\nFilteringActs to remove noise \\nor blur data.Can be used to remove speckle \\nnoise from images.Parker, James R. Algorithms for \\nImage Processing and Computer \\nVision.  New Jersey: John Wiley & \\nSons, 2010. Print.\\nGeneralized \\nLinear ModelsExpands ordinary linear \\nregression to allow \\nfor error distribution \\nthat is not normal.Use if the observed error in your system does \\nnot follow the normal distribution.MacCullagh, P., and John A. \\nNelder. Generalized Linear \\nModels.  Florida: CRC Press, \\n1989. Print.\\nGenetic \\nAlgorithmsEvolves candidate \\nmodels over generations \\nby evolutionary \\ninspired operators of \\nmutation and crossover \\nof parameters.Increasing the generation size adds diversity \\nin considering parameter combinations, but \\nrequires more objective function evaluation. \\nCalculating individuals within a generation \\nis strongly parallelizable. Representation of \\ncandidate solutions can impact performance.De Jong, Kenneth A. Evolutionary \\nComputation - A Uniﬁed \\nApproach. Massachusetts: \\nMIT Press, 2002. Print.\\nGrid SearchSystematic search across \\ndiscrete parameter \\nvalues for parameter \\nexploration problems.A grid across the parameters is used to \\nvisualize the parameter landscape and assess \\nwhether multiple minima are present.Kolda, Tamara G., Robert M. \\nLewis, and Virginia Torczon. \\n“Optimization by Direct \\nSearch: New Perspectives on \\nSome Classical and Modern \\nMethods.” SIAM Review. Society \\nfor Industrial and Applied \\nMathematics, 2003. Print.\\nHidden Markov \\nModelsModels sequential data by \\ndetermining the discrete \\nlatent variables, but \\nthe observables may be \\ncontinuous or discrete.One of the most powerful properties of Hidden \\nMarkov Models is their ability to exhibit \\nsome degree of invariance to local warping \\n(compression and stretching) of the time axis. \\nHowever, a signiﬁcant weakness of the Hidden \\nMarkov Model is the way in which it represents \\nthe distribution of times for which the system \\nremains in a given state.Bishop, Christopher M. Pattern \\nRecognition and Machine \\nLearning.  New York: Springer, \\n2006. Print.\\nHierarchical \\nClusteringConnectivity based \\nclustering approach \\nthat sequentially builds \\nbigger (agglomerative) \\nor smaller (divisive) \\nclusters in the data.Provides views of clusters at multiple \\nresolutions of closeness. Algorithms \\nbegin to slow for larger datasets due \\nto most implementations exhibiting \\nO(N3) or O(N2) complexity.Rui Xu, and Don Wunsch. \\nClustering. New Jersey: Wiley-\\nIEEE Press, 2008. Print.\\nK-means \\nand X-means \\nClusteringCentroid based clustering \\nalgorithms, where with \\nK means the number \\nof clusters is set and X \\nmeans the number of \\nclusters is unknown.When applying clustering techniques, make \\nsure to understand the shape of your data. \\nClustering techniques will return poor results if \\nyour data is not circular or ellipsoidal shaped.Rui Xu, and Don Wunsch. \\nClustering. New Jersey: Wiley-\\nIEEE Press, 2008. Print.\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 80}),\n",
       " Document(page_content='Compiled by: Booz Allen HamiltonTechnique Description Tips From the ProsReferences we  \\nlove to read\\nLinear, \\nNon-linear, \\nand Integer \\nProgrammingSet of techniques for \\nminimizing or maximizing a \\nfunction over a constrained \\nset of input parameters.Start with linear programs because algorithms \\nfor integer and non-linear variables can take \\nmuch longer to run.Winston, Wayne L. Operations \\nResearch: Applications and \\nAlgorithms.  Connecticut: \\nCengage Learning, 2003. Print.\\nMarkov Chain \\nMonte Carlo \\n(MCMC)A method of sampling \\ntypically used in Bayesian \\nmodels to estimate the joint \\ndistribution of parameters \\ngiven the data. Problems that are intractable using analytic \\napproaches can become tractable using MCMC, \\nwhen even considering high-dimensional \\nproblems. The tractability is a result of using \\nstatistics on the underlying distributions of \\ninterest, namely, sampling with Monte Carlo and \\nconsidering the stochastic sequential process of \\nMarkov Chains.Andrieu, Christophe, Nando \\nde Freitas, Amaud Doucet, \\nand Michael I. Jordan. “An \\nIntroduction to MCMC for \\nMachine Learning.” Machine \\nLearning. Kluwer Academic \\nPublishers, 2003. Print. \\nMonte Carlo \\nMethodsSet of computational \\ntechniques to generate \\nrandom numbers.Particularly useful for numerical integration, \\nsolutions of differential equations, computing \\nBayesian posteriors, and high dimensional \\nmultivariate sampling.Fishman, George S. Monte \\nCarlo: Concepts, Algorithms, and \\nApplications. New York: Springer, \\n2003. Print.\\nNaïve BayesPredicts classes following \\nBayes Theorem that \\nstates the probability of \\nan outcome given a set of \\nfeatures is based on the \\nprobability of features given \\nan outcome.Assumes that all variables are independent, \\nso it can have issues learning in the context of \\nhighly interdependent variables. The model can \\nbe learned on a single pass of data using simple \\ncounts and therefore is useful in determining \\nwhether exploitable patterns exist in large \\ndatasets with minimal development time.Ingersoll, Grant S., Thomas S. \\nMorton, and Andrew L. Farris. \\nTaming Text: How to Find, \\nOrganize, and Manipulate It.  New \\nJersey: Manning, 2013. Print.\\nNeural \\nNetworksLearns salient features in \\ndata by adjusting weights \\nbetween nodes through a \\nlearning rule.Training a neural network takes substantially \\nlonger than evaluating new data with an already \\ntrained network. Sparser network connectivity \\ncan help to segment the input space and \\nimprove performance on classiﬁcation tasks.Haykin, Simon O. Neural \\nNetworks and Learning \\nMachines. New Jersey: \\nPrentice Hall, 2008. Print.\\nOutlier \\nRemovalMethod for identifying and \\nremoving noise or artifacts \\nfrom data.Be cautious when removing outliers. Sometimes \\nthe most interesting behavior of a system is at \\ntimes when there are aberrant data points.Maimon, Oded, and Lior \\nRockach. Data Mining and \\nKnowledge Discovery Handbook:  \\nA Complete Guide for Practitioners \\nand Researchers.  The \\nNetherlands: Kluwer Academic \\nPublishers, 2005. Print.\\nPrincipal \\nComponents \\nAnalysisEnables dimensionality \\nreduction by identifying \\nhighly correlated \\ndimensions.Many large datasets contain correlations \\nbetween dimensions; therefore part of the \\ndataset is redundant. When analyzing the \\nresulting principal components, rank order \\nthem by variance as this is the highest \\ninformation view of your data. Use skree plots to \\ninfer the optimal number of components.Wallisch, Pascal, Michael E. \\nLusignan, Marc D. Benayoun, \\nTanya I. Baker, Adam Seth \\nDickey, and Nicholas G. \\nHatsopoulos. Matlab for \\nNeuroscientists.  New Jersey: \\nPrentice Hall, 2009. Print.\\nRandom \\nSearchRandomly adjust \\nparameters to ﬁnd a  \\nbetter solution than \\ncurrently found.Use as a benchmark for how well a search \\nalgorithm is performing. Be careful to use a \\ngood random number generator and new seed.Bergstra J. and Bengio Y. \\nRandom Search for Hyper-\\nParameter Optimization, \\nJournal of Machine Learning \\nResearch 13, 2012.\\nRegression \\nwith Shrinkage \\n(Lasso)A method of variable \\nselection and prediction \\ncombined into a possibly \\nbiased linear model. There are different methods to select the \\nlambda parameter. A typical choice is cross \\nvalidation with MSE as the metric. Tibshirani, Robert. “Regression \\nShrinkage and Selection via the \\nLasso.” Journal of the Royal \\nStatistical Society. Series B \\n(Methodological). Toronto: Royal \\nStatistical Society, 1996. Print.\\nSensitivity \\nAnalysisInvolves testing individual \\nparameters in an analytic \\nor model and observing the \\nmagnitude of the effect.Insensitive model parameters during an \\noptimization are candidates for being set to \\nconstants. This reduces the dimensionality \\nof optimization problems and provides an \\nopportunity for speed up.Saltelli, A., Marco Ratto, Terry \\nAndres, Francesca Campolongo, \\nJessica Cariboni, Debora Gatelli, \\nMichaela Saisana, and Stefano \\nTarantola. Global Sensitivity \\nAnalysis: the Primer .  New Jersey: \\nJohn Wiley & Sons, 2008. Print.\\n81 Take off the Training Wheels', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 81}),\n",
       " Document(page_content=\"Compiled by: Booz Allen HamiltonTechnique Description Tips From the ProsReferences we  \\nlove to read\\nSimulated \\nAnnealingNamed after a controlled \\ncooling process in \\nmetallurgy, and by \\nanalogy using a changing \\ntemperature or annealing \\nschedule to vary \\nalgorithmic convergence.The standard annealing function allows for \\ninitial wide exploration of the parameter space \\nfollowed by a narrower search. Depending on \\nthe search priority the annealing function can \\nbe modiﬁed to allow for longer explorative \\nsearch at a high temperature.Bertsimas, Dimitris, and John \\nTsitsiklis. “Simulated Annealing.” \\nStatistical Science. 1993. Print.\\nStepwise \\nRegressionA method of variable \\nselection and prediction. \\nAkaike's information \\ncriterion AIC is used as \\nthe metric for selection. \\nThe resulting predictive \\nmodel is based upon \\nordinary least squares, \\nor a general linear model \\nwith parameter estimation \\nvia maximum likelihood. Caution must be used when considering \\nStepwise Regression, as over ﬁtting often \\noccurs. To mitigate over ﬁtting try to limit the \\nnumber of free variables used.Hocking, R.R. “The Analysis  \\nand Selection of Variables in \\nLinear Regression.” Biometrics. \\n1976. Print.\\nStochastic \\nGradient \\nDescentGeneral-purpose \\noptimization for learning of \\nneural networks, support \\nvector machines, and \\nlogistic regression models.Applied in cases where the objective \\nfunction is not completely differentiable \\nwhen using sub-gradients.Witten, Ian H., Eibe Frank, \\nand Mark A. Hall. Data Mining: \\nPractical Machine Learning Tools \\nand Techniques. Massachusetts: \\nMorgan Kaufmann, 2011. Print.\\nSupport Vector \\nMachinesProjection of feature vectors \\nusing a kernel function into \\na space where classes are \\nmore separable.Try multiple kernels and use k-fold cross \\nvalidation to validate the choice of the best one.Hsu, Chih-Wei, Chih-Chung \\nChang, and Chih-Jen Lin. “A \\nPractical Guide to Support Vector \\nClassiﬁcation.” National Taiwan \\nUniversity Press, 2003. Print.\\nTerm \\nFrequency \\nInverse \\nDocument \\nFrequencyA statistic that measures \\nthe relative importance of a \\nterm from a corpus.Typically used in text mining. Assuming a \\ncorpus of news articles, a term that is very \\nfrequent such as “the” will likely appear many \\ntimes in many documents, having a low value. A \\nterm that is infrequent such as a person’s last \\nname that appears in a single article will have a \\nhigher TD IDF score.Ingersoll, Grant S., Thomas S. \\nMorton, and Andrew L. Farris. \\nTaming Text: How to Find, \\nOrganize, and Manipulate It. New \\nJersey: Manning, 2013. Print.\\nTopic Modeling \\n(Latent \\nDirichlet \\nAllocation)Identiﬁes latent topics \\nin text by examining \\nword co-occurrence.Employ part-of-speech tagging to eliminate \\nwords other than nouns and verbs. Use raw \\nterm counts instead of TF/IDF weighted terms.Blei, David M., Andrew Y. Ng, \\nand Michael I. Jordan. “Latent \\nDirichlet Allocation.” Journal \\nof Machine Learning Research. \\n2003. Print.\\nTree Based \\nMethodsModels structured as graph \\ntrees where branches \\nindicate decisions.Can be used to systematize a process or act as \\na classiﬁer.James, G., D. Witten, T. Hastie, \\nand R. Tibshirani. “Tree Based \\nMethods.” An Introduction to \\nStatistical Learning. New York: \\nSpringer, 2013. Print.\\nT-TestHypothesis test used to  \\ntest for differences between \\ntwo groups.Make sure you meet the tests assumptions and \\nwatch out for Family Wise error when running \\nmultiple tests.Bhattacharyya, Gouri K., and \\nRichard A. Johnson. Statistical \\nConcepts and Models. Wiley, \\n1977. Print.\\nWrapper \\nMethodsFeature set reduction \\nmethod that utilizes \\nperformance of a set of \\nfeatures on a model, as \\na measure of the feature \\nset’s performance. Can \\nhelp identify combinations \\nof features in models that \\nachieve high performance.Utilize k-fold cross validation \\nto control over ﬁtting.John, George H., Ron \\nKohavi, and Karl Pﬂeger. \\n“Irrelevant Features and the \\nSubset Selection Problem.” \\nProceedings of ICML-94, 11th \\nInternational Converence \\non Machine Learning. New \\nBrunswick, New Jersey. 1994. \\nConference  Presentation.\\nTHE FIELD  GUIDE to  DATA  SCIENCE\", metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 82}),\n",
       " Document(page_content='', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 83}),\n",
       " Document(page_content='', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 84}),\n",
       " Document(page_content=' LIFE in    THE TRENCHES\\nNAVIGATING NECK DEEP IN DATA\\nOur Data Science experts have learned \\nand developed new solutions over the years \\nfrom properly framing or reframing analytic \\nquestions. In this section, we list a few \\nimportant topics to Data Science coupled \\nwith firsthand experience from our experts. ', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 85}),\n",
       " Document(page_content='Going Deep into  \\nMachine Learning\\nMachines are getting better at learning by mimicking the \\nhuman brain.\\nThink about where you were 10 years ago. Could computers understand \\nand take action based upon your spoken word? Recently, speech-to-text \\nquality has improved dramatically to nearly perfect accuracy, much to \\nthe delight of many mobile phone users. In other complex tasks, similar \\nmagic capabilities have emerged. The world-record high scores in 29 \\nvideo games are now held by a machine learning algorithm with no \\nspecific knowledge of Atari or computer games in general.\\nThese impressive feats were made possible by deep learning, a different \\nway of approaching machine learning problems. Most approaches to \\nmachine learning require humans to encode logic and rules to create \\nfeatures, which are then fed into machine learning models. In some \\ndomains, such as audio, text, image, and signal processing, effective \\nfeature engineering requires considerable human expertise to achieve \\ndecent model performance. Deep learning avoids the necessity \\nof human-encoded features and instead incorporates the feature \\nengineering, feature selection, and model fitting into one step.\\nDeep learning is an extension of an idea originating in the \\n1950s called neural networks, which are loosely inspired by our \\nunderstanding of how neurons in our brains operate. Recent \\nhardware developments, originally designed for faster renderings \\nof graphics, birthed a renaissance in neural networks. The latest \\ngraphical processing units, or GPUs, have more than 3,000 processing \\ncores that are well suited for parallel processing of complex matrix \\nmanipulations required for rendering graphics – and for executing \\ncomputations on neural networks.\\nIn the late 2000s, the combination of GPUs, advances in algorithms, \\nand collections of big data reignited interest in neural networks. GPUs \\nenabled computers to process much larger networks in much less time, \\nand clever advances in algorithms made the model fitting process more \\nefficient. Large collections of image, video, and text data provided \\ncontent for the deep learning algorithms to learn. The ability to train \\nlarger networks with more data drove the exploration of new neural \\nnetwork architectures featuring additional hidden layers and widening \\nthe breadth of the networks. \\nPresently, deep learning has moved beyond academic applications and is \\nfinding its way into our daily lives. Deep learning powers speech-to-text \\non our mobile phones and smart devices, image search provided by major \\ntech companies, language translation services for text and spoken word, \\nand even drug discovery within advanced pharmaceutical companies. \\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 86}),\n",
       " Document(page_content='››\\nAaron Sander\\nNational Data Science Bowl\\nThe ﬁrst-ever National Data Science Bowl offered Data Scientists \\na platform through which individuals could harness their passion, \\nunleash their curiosity and amplify their impact to affect change \\non a global scale. The competition presented participants with \\nmore than 100,000 underwater images provided by the Hatﬁeld \\nMarine Science Center. Participants were challenged to develop a \\nclassiﬁcation algorithm that would enable researchers to monitor \\nocean health at a speed and scale never before possible. \\nMore than 1,000 teams submitted a  \\ntotal of approximately 15,000 solutions \\nover the 90 days of the competition.  \\nA large proportion of the participants’ \\nimplemented solutions used deep \\nlearning-based approaches, speciﬁcally \\nConvolutional Neural Nets (CNNs). \\nThe competition forum exploded \\nwith competitors collectively sharing \\nknowledge and collaborating to advance \\nthe state-of-the-art in computer vision. \\nParticipants tested new techniques \\nfor developing CNNs and contributed \\nto the development of open source \\nsoftware for creating CNN models. \\nThe top three competitors, Team Deep Sea , Happy Lantern Festival, \\nand Poisson Process, all used CNNs \\nin their solutions. Their results \\nincreased algorithm accuracy by 10% \\nover the state of the art. Without their \\nalgorithms, it would have taken marine \\nresearchers more than two lifetimes to \\nmanually complete the classiﬁcation \\nprocess. The work submitted by all \\nthe participants represents major \\nadvances for both the marine research \\nand Data Science communities. \\nINPUT LAYER HIDDEN LAYER\\nOUTPUT\\nLAYER\\nA Representation of Deep Learning Source: Booz Allen Hamilton  »Visit www.DataScienceBowl.com \\nto learn more about the first-ever \\nNational Data Science Bowl\\n87 Life in the Trenches', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 87}),\n",
       " Document(page_content='Feature Engineering\\nFeature engineering is a lot like oxygen. You can’t do without \\nit, but you rarely give it much thought. \\nFeature engineering is the process by which one establishes the \\nrepresentation of data in the context of an analytic approach. It is the \\nfoundational skill in Data Science. Without feature engineering, it \\nwould not be possible to understand and represent the world through \\na mathematical model. Feature engineering is a challenging art. Like \\nother arts, it is a creative process that manifests uniquely in each \\nData Scientist. It will be influenced substantially by the scientist’s \\nexperiences, tastes and understanding of the field. \\nWhen faced with the problem of feature engineering, there are \\nseveral paths that one may initially take. Generally speaking, better \\nfeatures can be developed with more knowledge of the domain. One \\napproach to feature engineering is to begin by describing smaller \\nelements of the domain and continuously constructing more intricate \\nfeatures as the model becomes more complex. These more complicated \\nfeatures can be defined by considering other attributes of the domain, \\naggregating features together into different groups or using advanced \\nstatistical and mathematical techniques to devise new features. The \\nultimate judge in this process is the performance of the machine \\nlearning algorithm which makes decisions based on this feature vector.\\nConsider the example of email spam classification. Because the \\ndomain is a set of emails, one possible choice of an initial feature \\nvector is the integer array that counts the number of times a \\ngiven word appears in the email. This is called the \"bag of words\" \\nassumption, where the order that words appear in a text is ignored.  \\nIf an algorithm with this feature vector does not adequately \\ndistinguish between spam and non-spam emails, a feature could  \\nbe added that counts the number of misspelled words in the text.  \\nThis new feature uses the spam recognition domain knowledge that \\nasserts many spam emails misspell words. These misspelled words  \\nalert filters saying that the existence of certain words automatically \\nlabel an email as spam. If this new feature is not enough, there are  \\nstill additional features to be considered such as whether or not a  \\nfirst or last name is used in the email.\\nFeature engineering represents a complex, but crucial aspect of Data \\nScience. The Learning Optimal Features sidebar goes into detail about \\nfeature learning – an automated approach to feature engineering that \\napplies machine learning techniques.  »What differentiates a great \\nmodel from a bad one? \\nIn most cases, the inputs to the model \\nmatter even more than the choice \\nof the algorithm. The traditional \\napproach has a two-step process \\nwhere heuristics and subject-matter \\nexpertise are used to ﬁnd a good set of \\nfeatures, and then algorithms optimize \\nmodel parameters. Deep learning \\ncombines these steps into one. \\nFeature engineering, feature selection, \\nand model parameter estimation \\nare accomplished simultaneously. \\nThis reduces the need for highly-\\nspecialized domain knowledge and \\noften results in better models.\\nFor example, in the context of images \\nfrom the natural world, deep networks \\nmay learn low-level features such as \\nlines at various angles and curved \\nlines. Middle layers may combine the \\nlower-level features into more complex \\ngeometric shapes and patterns. \\nHigher-level layers combine the mid-\\nlevel features into more complicated \\nfeatures that begin to resemble faces \\nand shapes of animals. Applied to \\nother types of data, such as audio \\nand text, deep neural networks learn \\nincreasingly sophisticated features \\nat each layer in a similar manner.\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 88}),\n",
       " Document(page_content='››\\nEd Kohlwey\\nChemoinformatic Search\\nOn one assignment, my \\nteam was confronted \\nwith the challenge of \\ndeveloping a search \\nengine over chemical \\ncompounds. The goal \\nof chemoinformatic \\nsearch is to predict \\nthe properties that \\na molecule will exhibit as well as to \\nprovide indices over those predicted \\nproperties to facilitate data discovery \\nin chemistry-based research. These \\nproperties may either be discreet (e.g., \\n“a molecule treats disease x well”) \\nor continuous (e.g., “a molecule may \\nbe dissolved up to 100.21 g/ml”).\\nMolecules are complex 3D structures, \\nwhich are typically represented as \\na list of atoms joined by chemical \\nbonds of differing lengths with varying \\nelectron domain and molecular \\ngeometries. The structures are \\nspeciﬁed by the 3-space coordinates \\nand the electrostatic potential \\nsurface of the atoms in the molecule. \\nSearching this data is a daunting \\ntask when one considers that \\nnaïve approaches to the problem \\nbear signiﬁcant semblance to the \\nGraph Isomorphism Problem.[15]\\nThe solution we developed was \\nbased on previous work in molecular \\nﬁngerprinting (sometimes also called \\nhashing or locality sensitive hashing). \\nFingerprinting is a dimensionality \\nreduction technique that dramatically \\nreduces the problem space by \\nsummarizing many features, often \\nwith relatively little regard to the \\nimportance of the feature. When \\nan exact solution is likely to be \\ninfeasible, we often turn to heuristic \\napproaches such as ﬁngerprinting.\\nOur approach used a training set \\nwhere all the measured properties of the molecules were available. We \\ncreated a model of how molecular \\nstructural similarities might affect \\ntheir properties. We began by \\nﬁnding all the sub-graphs of each \\nmolecule with length n, resulting \\nin a representation similar to \\nthe bag-of-words approach from \\nnatural language processing. \\nWe summarized each molecule \\nfragment in a type of ﬁngerprint \\ncalled a “Counting Bloom Filter.”\\nNext, we used several exemplars from \\nthe set to create new features. We \\nfound the distance from each member \\nof the full training set to each of the \\nexemplars. We fed these features into \\na non-linear regression algorithm \\nto yield a model that could be used \\non data that was not in the original \\ntraining set. This approach can be \\nconceptualized as a “hidden manifold,” \\nwhereby a hidden surface or shape \\ndeﬁnes how a molecule will exhibit a \\nproperty. We approximate this shape \\nusing a non-linear regression and a \\nset of data with known properties. \\nOnce we have the approximate \\nshape, we can use it to predict the \\nproperties of new molecules. \\nOur approach was multi-staged and \\ncomplex – we generated sub-graphs, \\ncreated bloom ﬁlters, calculated \\ndistance metrics and ﬁt a linear-\\nregression model. This example \\nprovides an illustration of how many \\nstages may be involved in producing a \\nsophisticated feature representation. \\nBy creatively combining and building \\n“features on features,” we were able \\nto create new representations of data \\nthat were richer and more descriptive, \\nyet were able to execute faster and \\nproduce better results. \\n89 Life in the Trenches', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 89}),\n",
       " Document(page_content='Feature Selection\\nModels are like honored guests; you should only feed them the \\ngood parts.\\nFeature selection is the process of determining the set of features with \\nthe highest information value to the model. Two main approaches are \\nfiltering and wrapper methods. Filtering methods analyze features \\nusing a test statistic and eliminate redundant or non-informative \\nfeatures. As an example, a filtering method could eliminate features \\nthat have little correlation to the class labels. Wrapper methods \\nutilize a classification model as part of feature selection. A model is \\ntrained on a set of features and the classification accuracy is used to \\nmeasure the information value of the feature set. One example is that \\nof training a neural network with a set of features and evaluating the \\naccuracy of the model. If the model scores highly on the test set, then \\nthe features have high information value. All possible combinations of \\nfeatures are tested to find the best feature set. \\nThere are tradeoffs between these techniques. Filtering methods \\nare faster to compute since each feature only needs to be compared \\nagainst its class label. Wrapper methods, on the other hand, evaluate \\nfeature sets by constructing models and measuring performance.  \\nThis requires a large number of models to be trained and evaluated  \\n(a quantity that grows exponentially in the number of features).  \\nWhy would anyone use a wrapper method? Feature sets may perform \\nbetter than individual features.[16] With filter methods, a feature \\nwith weak correlation to its class labels is eliminated. Some of \\nthese eliminated features, however, may have performed well when \\ncombined with other features.\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 90}),\n",
       " Document(page_content='››\\nPaul Yacci\\nCancer Cell Classiﬁcation\\nOn one project, \\nour team was \\nchallenged \\nto classify \\ncancer cell \\nproﬁles. The \\noverarching \\ngoal was \\nto classify different types \\nof Leukemia, based on \\nMicroarray proﬁles from 72 \\nsamples[17] using a small \\nset of features. We utilized \\na hybrid Artiﬁcial Neural \\nNetwork (ANN)[18] and Genetic \\nAlgorithm[19] to identify subsets \\nof 10 features selected from \\nthousands.[20] We trained the \\nANN and tested performance \\nusing cross-fold validation. \\nThe performance measure was used as feedback into \\nthe Genetic Algorithm. When \\na set of features contained \\nno useful information, the \\nmodel performed poorly and \\na different feature set would \\nbe explored. Over time, this \\nmethod selected a set of \\nfeatures that performed with \\nhigh accuracy. The down-\\nselected feature set increased \\nspeed and performance as \\nwell as allowed for better \\ninsight into the factors that \\nmay govern the system. This \\nallowed our team to design \\na diagnostic test for only a \\nfew genetic markers instead \\nof thousands, substantially \\nreducing diagnostic test \\ncomplexity and cost.\\n91 Life in the Trenches', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 91}),\n",
       " Document(page_content='Ensemble Models\\nNone of us is as smart as all of us, but some are smarter  \\nthan others.\\nIn 1906, Sir Francis Galton attended a fair at which there was a \\ncontest to guess the weight of an ox. Galton had the idea to collect the \\nguesses of the 787 entrants and compute the mean. To his surprise, \\nthe mean was only one pound off from the ox’s real weight of 1,198 \\npounds. Together, the estimates made by many amateurs formed a \\nprediction that was more accurate than that of individual experts. \\nGalton’s “wisdom of crowds” extends to Data Science in the form of \\nensemble learning, which is colloquially and somewhat equivalently \\ncalled ensembling, blending, or stacking. An ensemble takes the \\npredictions of many individual models and combines them to \\nmake a single prediction. Like the people guessing the ox’s weight, \\nData Science models have unique strengths and weaknesses (i.e., \\ndetermined by their design), and are influenced by varied perspectives \\nbased on past experience (i.e., the data they have observed). \\nEnsembles overcome individual weaknesses to make predictions with \\nmore accuracy than their constituent models. These models need not \\nstem from different methodologies; an ensemble might employ the \\nsame method with different parameters or weights (e.g., boosting), \\nfeature subsets (e.g., random forests), or sub-samples of data (e.g., \\nbagging). The ensembling methodology may be as simple as averaging \\ntwo outputs, or as complex as using a “meta model” to learn an \\noptimal combination. \\nAn ensemble’s ability to reduce individual errors arises from the \\ndiversity of its members. If one model over fits the data, it is balanced \\nby a different model that under fits the data. If one subset is skewed \\nby outlier values, another subset is included without them. If one \\nmethod is unstable to noisy inputs, it is bolstered by another method \\nthat is more robust. \\nIn practice, ensembling typically improves a model by a few percent. \\nThe price of this accuracy is paid in complexity. The accuracy vs. \\ncomplexity tradeoff can make it difficult to know when ensembling \\nis justified. On one hand, ensembles appear to be a fit for high-stakes \\nproblems—think detecting cancer in MRI images vs. detecting \\nunripe blueberries on a conveyer belt. On the other hand, high-stakes \\nproblems mandate higher standards for auditing model functionality. \\nThe Data Scientist must manage a balance between ensemble \\ninterpretability and black-box complexity. If this seems easy, it isn’t! \\nPut yourself in the driver’s seat of the machine learning code for a \\nself-driving car. If a well-behaved regression model makes a right \\ndecision 99.5% of the time, but a complex, less-explainable ensemble \\nis right 99.8% of the time, which would you pick? \\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 92}),\n",
       " Document(page_content=\"››\\nWill Cukierski\\nThe Value of  \\nEnsemble Models\\nSeveral years ago, the Kaggle Photo Quality Prediction  \\ncompetition posed the question “Given anonymized information \\non thousands of photo albums, predict whether a human \\nevaluator would mark them as 'good'.” Participants were \\nsupplied a large collection of user-generated photos. The goal \\nwas to create an algorithm that could automatically pick out \\nparticularly enjoyable or impressive photos from the collection.Log likelihood (lower is better)Final Team Rank\\n      Ensemble\\n      Private Leaderboard\\nRank=1\\nValue of Ensembling for the Kaggle Photo Quality Prediction Competition  \\n(results courtesy of Ben Hamner, Kaggle CTO)\\nThe-blue line shows the individual scores \\nfor each of the top 50 teams. The orange \\nline shows the ensembled score for the top \\nn teams, where n ranges from 1 to the value \\non the axis. For example, the ensemble point \\nfor Final Team Rank 5 is an ensemble of the \\nentries for teams 1 through 5. As shown in \\nthe graph, the ensembled score is lower than \\nany single individual score. The diversity of \\nmodels included within the ensemble causes \\nthe respective errors to cancel out, resulting \\nin an overall lower score. This holds true for all points across the top 50 teams. However, \\nafter we increase the number of models in \\nthe ensemble beyond 15, we begin to see \\nthe ensembled score increase. This occurs \\nbecause we are introducing less accurate (i.e., \\npotentially overﬁt) models into the ensemble. \\nThe results of this simple experiment quantify \\nthe value of creating an ensemble model, while \\nreinforcing the idea that we must be thoughtful \\nwhen selecting the individual models contained \\nwithin the ensemble.Over the course of the competition, 207 people submitted entries. The log likelihood metric was \\nused to evaluate the accuracy of the entries. Scores for the top 50 teams ranged from 0.18434 to \\n0.19884, where lower is better . Kaggle data scientist Ben Hamner used the results to illustrate the \\nvalue of ensembling by means of averaging the top 50 scores. The ﬁgure below shows the results.\\n93 Life in the Trenches\", metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 93}),\n",
       " Document(page_content='Data Veracity\\nWe’re Data Scientists, not data alchemists. We can’t make \\nanalytic gold from the lead of data.\\nWhile most people associate data volume, velocity, and variety with \\nbig data, there is an equally important yet often overlooked dimension \\n– data veracity. Data veracity refers to the overall quality and \\ncorrectness of the data. You must assess the truthfulness and accuracy \\nof the data as well as identify missing or incomplete information. As \\nthe saying goes, “Garbage in, garbage out.” If your data is inaccurate or \\nmissing information, you can’t hope to make analytic gold.\\nAssessing data truthfulness is often subjective. You must rely on your \\nexperience and an understanding of the data origins and context. \\nDomain expertise is particularly critical for the latter. Although data \\naccuracy assessment may also be subjective, there are times when \\nquantitative methods may be used. You may be able to re-sample from \\nthe population and conduct a statistical comparison against the stored \\nvalues, thereby providing measures of accuracy.\\nThe most common issues you will encounter are missing or \\nincomplete information. There are two basic strategies for dealing \\nwith missing values – deletion and imputation. In the former, entire \\nobservations are excluded from analysis, reducing sample size and \\npotentially introducing bias. Imputation, or replacement of missing \\nor erroneous values, uses a variety of techniques such as random \\nsampling (hot deck imputation) or replacement using the mean, \\nstatistical distributions or models. »Tips From the Pros\\nFind an approach that works, \\nimplement it, and move on. You \\ncan worry about optimization and \\ntuning your approaches later during \\nincremental improvement.\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 94}),\n",
       " Document(page_content='Brian Keller››\\nTime Series Modeling \\nOn one of our projects, the team was faced with correlating the time \\nseries for various parameters. Our initial analysis revealed that the \\ncorrelations were almost non-existent. We examined the data and \\nquickly discovered data veracity issues. There were missing and \\nnull values, as well as negative-value observations, an impossibility \\ngiven the context of the measurements (see the ﬁgure, Time Series \\nData Prior to Cleansing ). Garbage data meant garbage results. \\nBecause sample size was already small, deleting \\nobservations was undesirable. The volatile nature \\nof the time series meant that imputation through \\nsampling could not be trusted to produce values \\nin which the team would be conﬁdent. As a result, \\nwe quickly realized that the best strategy was an \\napproach that could ﬁlter and correct the noise in  \\nthe data. \\nWe initially tried a simplistic approach in which we \\nreplaced each observation with a moving average. \\nWhile this corrected some noise, including the \\noutlier values in our moving-average computation \\nshifted the time series. This caused undesirable distortion in the underlying signal, and we quickly \\nabandoned the approach.\\nOne of our team members who had experience in \\nsignal processing suggested a median ﬁlter. The \\nmedian ﬁlter is a windowing technique that moves \\nthrough the data point-by-point, and replaces it \\nwith the median value calculated for the current \\nwindow. We experimented with various window \\nsizes to achieve an acceptable tradeoff between \\nsmoothing noise and smoothing away signal. The \\nﬁgure, Time Series Data After Cleansing , shows the \\nsame two time series after median ﬁlter imputation. \\nThe application of the median ﬁlter approach was \\nhugely successful. Visual inspection of the time \\nseries plots reveals smoothing of the outliers \\nwithout dampening the naturally occurring peaks \\nand troughs (no signal loss). Prior to smoothing, \\nwe saw no correlation in our data, but afterwards, \\nSpearman’s Rho was ~0.5 for almost all parameters. By addressing our data veracity issues, we were \\nable to create analytic gold. While other approaches \\nmay also have been effective, implementation speed \\nconstraints prevented us from doing any further \\nanalysis. We achieved the success we were after and \\nmoved on to address other aspects of the problem. Time Series Data Prior to Cleansing\\nTime Series Data After Cleansing Source: Booz Allen Hamilton \\n Source: Booz Allen Hamilton \\nBrian Keller››\\nTime Series Modeling \\nOn one of our projects, the team was faced with correlating the time \\nseries for various parameters. Our initial analysis revealed that the \\ncorrelations were almost non-existent. We examined the data and \\nquickly discovered data veracity issues. There were missing and \\nnull values, as well as negative-value observations, an impossibility \\ngiven the context of the measurements (see the ﬁgure, Time Series \\nData Prior to Cleansing ). Garbage data meant garbage results. \\nBecause sample size was already small, deleting \\nobservations was undesirable. The volatile nature \\nof the time series meant that imputation through \\nsampling could not be trusted to produce values \\nin which the team would be conﬁdent. As a result, \\nwe quickly realized that the best strategy was an \\napproach that could ﬁlter and correct the noise in  \\nthe data. \\nWe initially tried a simplistic approach in which we \\nreplaced each observation with a moving average. \\nWhile this corrected some noise, including the \\noutlier values in our moving-average computation \\nshifted the time series. This caused undesirable distortion in the underlying signal, and we quickly \\nabandoned the approach.\\nOne of our team members who had experience in \\nsignal processing suggested a median ﬁlter. The \\nmedian ﬁlter is a windowing technique that moves \\nthrough the data point-by-point, and replaces it \\nwith the median value calculated for the current \\nwindow. We experimented with various window \\nsizes to achieve an acceptable tradeoff between \\nsmoothing noise and smoothing away signal. The \\nﬁgure, Time Series Data After Cleansing , shows the \\nsame two time series after median ﬁlter imputation. \\nThe application of the median ﬁlter approach was \\nhugely successful. Visual inspection of the time \\nseries plots reveals smoothing of the outliers \\nwithout dampening the naturally occurring peaks \\nand troughs (no signal loss). Prior to smoothing, \\nwe saw no correlation in our data, but afterwards, \\nSpearman’s Rho was ~0.5 for almost all parameters. By addressing our data veracity issues, we were \\nable to create analytic gold. While other approaches \\nmay also have been effective, implementation speed \\nconstraints prevented us from doing any further \\nanalysis. We achieved the success we were after and \\nmoved on to address other aspects of the problem. Time Series Data Prior to Cleansing\\nTime Series Data After Cleansing Source: Booz Allen Hamilton \\n Source: Booz Allen Hamilton \\n95 Life in the Trenches', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 95}),\n",
       " Document(page_content='Application of  \\nDomain Knowledge \\nWe are all special in our own way. Don’t discount what  \\nyou know.\\nKnowledge of the domain in which a problem lies is immensely \\nvaluable and irreplaceable. It provides an in-depth understanding  \\nof your data and the factors influencing your analytic goal. Many \\ntimes domain knowledge is a key differentiator to a Data Science \\nteam’s success. Domain knowledge influences how we engineer and \\nselect features, impute data, choose an algorithm, and determine \\nsuccess. One person cannot possibly be a domain expert in every  \\nfield, however. We rely on our team, other analysts and domain  \\nexperts as well as consult research papers and publications to build  \\nan understanding of the domain. \\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 96}),\n",
       " Document(page_content='››\\nGEOSPATIAL HOTSPOTS\\nTEMPORAL HOTSPOT\\nSun\\nSat\\nFri\\nThu\\nWed\\nTue\\nMon\\n9pm 6pm 3pm Noon 9am 6am 3am9pm 6pm 3pm Noon 9am 6am 3am\\nArmen \\nKherlopian\\nMotor Vehicle Theft\\nOn one project, \\nour team explored \\nhow Data Science \\ncould be applied to \\nimprove public safety. \\nAccording to the \\nFBI, approximately \\n$8 Billion is lost \\nannually due to \\nautomobile theft. Recovery of the \\none million vehicles stolen every \\nyear in the U.S. is less than 60%. \\nDealing with these crimes represents \\na signiﬁcant investment of law \\nenforcement resources. We wanted \\nto see if we could identify how to \\nreduce auto theft while efﬁciently \\nusing law enforcement resources.Our team began by parsing and \\nverifying San Francisco crime data. \\nWe enriched stolen car reporting with \\ngeneral city data. After conducting \\nseveral data experiments across both \\nspace and time, three geospatial and \\none temporal hotspot emerged (see \\nﬁgure, Geospatial and Temporal Car \\nTheft Hotspots ). The domain expert \\non the team was able to discern \\nthat the primary geospatial hotspot \\ncorresponded to an area surrounded \\nby parks. The parks created an urban \\nmountain with a number of over-foot \\naccess points that were conducive to \\ncar theft. \\nOur team used the temporal hotspot information in tandem with the insights \\nfrom the domain expert to develop a Monte Carlo model to predict the likelihood \\nof a motor vehicle theft at particular city intersections. By prioritizing the \\nintersections identiﬁed by the model, local governments would have the \\ninformation necessary to efﬁciently deploy their patrols. Motor vehicle thefts \\ncould be reduced and law enforcement resources could be more efﬁciently \\ndeployed. The analysis, enabled by domain expertise, yielded actionable insights \\nthat could make the streets safer.Geospatial and Temporal Car Theft Hotspots Source: Booz Allen Hamilton \\n97 Life in the Trenches', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 97}),\n",
       " Document(page_content='The Curse of \\nDimensionality\\nThere is no magical potion to cure the curse, but there is PCA.\\nThe “curse of dimensionality” is one of the most important results \\nin machine learning. Most texts on machine learning mention this \\nphenomenon in the first chapter or two, but it often takes many years \\nof practice to understand its true implications.\\nClassification methods, like most machine learning methods, are \\nsubject to the implications of the curse of dimensionality. The basic \\nintuition in this case is that as the number of data dimensions \\nincreases, it becomes more difficult to create generalizable \\nclassification models (models that apply well over phenomena not \\nobserved in the training set). This difficulty is usually impossible to \\novercome in real world settings. There are some exceptions in domains \\nwhere things happen to work out, but usually you must work to \\nminimize the number of dimensions. This requires a combination \\nof clever feature engineering and use of dimensionality reduction \\ntechniques (see Feature Engineering and Feature Selection  Life in the \\nTrenches ). In our practical experience, the maximum  \\nnumber of dimensions seems to be ~10 for linear model-based \\napproaches. The limit seems to be in the tens of thousands for more \\nsophisticated methods such as support vector machines, but the limit \\nstill exists nonetheless.\\nA counterintuitive consequence of the curse of dimensionality is  \\nthat it limits the amount of data needed to train a classification  \\nmodel. There are roughly two reasons for this phenomenon. In one \\ncase, the dimensionality is small enough that the model can be  \\ntrained on a single machine. In the other case, the exponentially \\nexpanding complexity of a high-dimensionality problem makes it \\n(practically) computationally impossible to train a model. In our \\nexperience, it is quite rare for a problem to fall in a “sweet spot” \\nbetween these two extremes. \\nRather than trying to create super-scalable algorithm \\nimplementations, focus your attention on solving your immediate \\nproblems with basic methods. Wait until you encounter a problem \\nwhere an algorithm fails to converge or provides poor cross-validated \\nresults, and then seek new approaches. Only when you find that \\nalternate approaches don’t already exist, should you begin building \\nnew implementations. The expected cost of this work pattern is lower \\nthan over-engineering right out of the gate. \\nPut otherwise, “Keep it simple, stupid”.\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 98}),\n",
       " Document(page_content='Baking the Cake \\nI was once given a time series set of roughly \\n1,600 predictor variables and 16 target variables \\nand asked to implement a number of modeling \\ntechniques to predict the target variable \\nvalues. The client was challenged to handle the \\ncomplexity associated with the large number of \\nvariables and needed help. Not only did I have \\na case of the curse, but the predictor variables \\nwere also quite diverse. At ﬁrst glance, it looked \\nlike trying to bake a cake with everything in the cupboard.  \\nThat is not a good way to bake or to make predictions!\\xa0\\nThe data diversity could be \\npartially explained by the fact \\nthat the time series predictors \\ndid not all have the same \\nperiodicity. The target time \\nseries were all daily values \\nwhereas the predictors were \\ndaily, weekly, quarterly, and \\nmonthly. This was tricky to \\nsort out, given that imputing \\nzeros isn’t likely to produce \\ngood results. For this speciﬁc \\nreason, I chose to use neural \\nnetworks for evaluating the \\nweekly variable contributions. Using this approach, I was \\nable to condition upon week, \\nwithout greatly increasing \\nthe dimensionality. For the \\nother predictors, I\\xa0used \\na variety of techniques, \\nincluding projection and \\ncorrelation, to make heads \\nor tails of the predictors.\\xa0My \\napproach successfully reduced \\nthe number of variables, \\naccomplishing the client’s goal \\nof making the problem space \\ntractable. As a result, the cake \\nturned out just ﬁne.››\\nStephanie \\nRivera\\n99 Life in the Trenches', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 99}),\n",
       " Document(page_content='Model Validation\\nRepeating what you just heard does not mean that you  \\nlearned anything. \\nModel validation is central to construction of any model. This answers \\nthe question “How well did my hypothesis fit the observed data?”\\nIf we do not have enough data, our models cannot connect the dots. \\nOn the other hand, given too much data the model cannot think \\noutside of the box. The model learns specific details about the training \\ndata that do not generalize to the population. This is the problem of \\nmodel over fitting. \\nMany techniques exist to combat model over fitting. The simplest \\nmethod is to split your dataset into training, testing and validation \\nsets. The training data is used to construct the model. The model \\nconstructed with the training data is then evaluated with the testing \\ndata. The performance of the model against the testing set is used to \\nfurther reduce model error. This indirectly includes the testing data \\nwithin model construction, helping to reduce model over fit. Finally, \\nthe model is evaluated on the validation data to assess how well the \\nmodel generalizes.\\nA few methods where the data is split into training and testing sets \\ninclude: k-fold cross-validation, Leave-One-Out cross-validation, \\nbootstrap methods, and resampling methods. Leave-One-Out cross-\\nvalidation can be used to get a sense of ideal model performance \\nover the training set. A sample is selected from the data to act as the \\ntesting sample and the model is trained on the rest of the data. The \\nerror on the test sample is calculated and saved, and the sample is \\nreturned to the dataset. A different sample is then selected and the \\nprocess is repeated. This continues until all samples in the testing set \\nhave been used. The average error over the testing examples gives a \\nmeasure of the model’s error.\\nThere are other approaches for testing how well your hypothesis \\nreflects the data. Statistical methods such as calculating the coefficient \\nof determination, commonly called the R-squared value are used to \\nidentify how much variation in the data your model explains. Note \\nthat as the dimensionality of your feature space grows, the R-squared \\nvalue also grows. An adjusted R-squared value compensates for this \\nphenomenon by including a penalty for model complexity. When \\ntesting the significance of the regression as a whole, the F-test \\ncompares the explained variance to unexplained variance. A regression \\nresult with a high F-statistic and an adjusted R-squared over 0.7 is \\nalmost surely significant. »Do we really need a case study \\nto know that you should  \\ncheck your work?\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 100}),\n",
       " Document(page_content='', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 101}),\n",
       " Document(page_content='', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 102}),\n",
       " Document(page_content='PUTTING  it    ALL TOGETHER\\n', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 103}),\n",
       " Document(page_content='Streamlining Medication Review \\nAnalytic Challenge\\nThe U.S. Food and Drug Administration (FDA) is responsible for advancing public \\nhealth by supporting the delivery of new treatments to patients; assessing the safety, \\nefﬁcacy and quality of regulated products; and conducting \\nresearch to drive medical innovation. Although the FDA \\nhouses one of the world’s largest repositories of regulatory \\nand scientiﬁc data, reviewers are not able to easily leverage \\ndata-driven approaches and analytics methods to extract \\ninformation, detect signals and uncover trends to enhance \\nregulatory decision-making and protect public health. In \\naddition, a rapid increase in the volume, velocity and variety \\nof data that must be analyzed to address and respond to \\nregulatory challenges, combined with variances in data \\nstandards, formats, and quality, severely limit the ability \\nof FDA Center for Drug Evaluation and Research (CDER) \\nregulatory scientists to conduct cross-study, cross-product, \\nretrospective, and meta-analysis during product reviews.\\nBooz Allen Hamilton was engaged to research, develop, \\nand evaluate emerging informatics tools, methods, and \\ntechniques to determine their ability to address regulatory \\nchallenges faced by the FDA Center for Drug Evaluation \\nand Research (CDER). The main goal was to enable the CDER community to fully \\nutilize the agency’s expansive data resources for efﬁcient and effective drug review \\nthrough the design and development of informatics capabilities based on Natural \\nLanguage Processing (NLP), data integration, and data visualization methodologies.\\nOur Approach\\nTo support transformational change \\nat CDER, we designed and developed \\na set of informatics prototypes for \\nthe analysis and modeling of complex \\nstructured, unstructured, and \\nfragmented datasets. We developed \\nmultiple prototypes to enable the \\nevaluation of emerging informatics \\ntools, methods, and techniques and \\ntheir ability to enable a critical-value \\ndriver – e.g., co-locate complex, \\nheterogeneous data to identify patterns \\nand foster development of strategies \\nto protect public health. For example, \\nwe implemented NLP algorithms \\nto compare adverse events across datasets, and geographic visualization \\ncapabilities to support the inspection of \\npharmaceutical manufacturing facilities. \\nProduct Safety Analytics. The review, \\nsurveillance, and analysis of adverse \\nevents throughout the product lifecycle \\nrequire signiﬁcant resources. The ability \\nto identify actionable insights that lead \\nto informed decision-making requires \\nsigniﬁcant investment of effort, including \\nthe active and passive surveillance \\nof adverse events. To address these \\nchallenges, we developed a Product \\nSafety Dashboard that compares adverse \\nevents listed in the product label (i.e., ››\\n » Our Case Studies\\nHey, we have given you a lot of \\nreally good technical content. We \\nknow that this section has the look \\nand feel of marketing material, \\nbut there is still a really good story \\nhere. Remember, storytelling comes \\nin many forms and styles, one of \\nwhich is the marketing version. You \\nshould read this chapter for what it \\nis – great information told with a \\nmarketing voice. \\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 104}),\n",
       " Document(page_content='package inserts) with data from the \\nFDA Adverse Event Reporting System \\n(FAERS). Using NLP, we extracted \\nadverse events from the product label \\nto create a structured table of label \\ndata out of unstructured text. This \\ndashboard allows safety evaluators to \\nview whether or not a reported adverse \\nevent is already known, without having \\nto access an external data source \\nand read through product labels.\\nProduct Quality Analytics.   \\nTo support CDER’s mission of reviewing \\nand managing product quality, novel \\nmethodologies and tools are needed \\nto improve the efﬁciency and efﬁcacy of the product quality-review process. \\nIntegration of disparate data sources is \\nthe ﬁrst step in building a comprehensive \\nproﬁle of manufacturers, facilities, and \\nthe products associated with individual \\nfacilities. To address these challenges, \\nwe developed a Facility Inventory Report \\nto show the geographic location of \\nfacilities and their associated metadata. \\nThis geovisualization tool processes and \\ntransforms raw data into a user-friendly \\nvisual interface with mapping features \\nto enhance the surveillance capabilities \\nof CDER and provide reviewers with the \\nability to establish connections between \\nfacility data and product quality.\\nOur Impact\\nSince the FDA is responsible for regulating 25 cents of every dollar that Americans \\nspend, the agency’s ability to fully use regulatory datasets and meaningfully integrate \\npreviously incompatible data to rapidly detect product quality and safety issues is \\ncritical for safeguarding public health. NLP approaches provide CDER with the ability \\nto more efﬁciently search a broader range of textual data and enhances the ability to \\ngain insight from additional data forms that may seem unrelated. Data integration \\nand visualization directly increase the efﬁciency of researchers by reducing their time \\nspent on searching for frequently-performed aggregate or granular calculations, \\nand by proactively presenting the most frequently desired data to the reviewer \\nthrough thoughtful and contextual dashboards designed to reveal patterns and \\ntrends in disparate data sources. These new capabilities position the FDA to enhance \\nregulatory decision-making, drive advances in personalized medicine, and enable \\nearlier detection of safety signals in the general population. \\n105 Putting it all Together', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 105}),\n",
       " Document(page_content='Reducing Flight Delays\\nAnalytic Challenge\\nDomestic airline departure delays are estimated to cost the U.S. economy $32.9 billion \\nannually. The Federal Aviation Administration’s (FAA’s) Trafﬁc Flow Management \\nSystem (TFMS) is used to strategically manage ﬂights and includes a ﬂight departure-\\ndelay prediction engine which applies simple heuristics to predict ﬂight delays.\\nHowever , the limited predictive power of these heuristics constrains the FAA’s ability \\nto act in accordance with its existing departure-delay management plan. In response, \\nthe FAA’s NextGen Advanced Concepts and Technology Development Group wanted to \\ncreate a predictive probabilistic model to improve aircraft departure time predictions. \\nThis new model would help the FAA understand the causes of departure delays and \\ndevelop policies and actions to improve the reliability of departure time predictions for \\nreal-time air trafﬁc ﬂow management.\\nOur Approach\\nThe commercial aviation industry is rich \\nin ﬂight operations data, much of which \\nis publicly available through government \\nwebsites and a few subscription \\nvendors. Booz Allen Hamilton leveraged \\nthese sources to gather over 4 TB of \\ndata detailing tarmac and airspace \\ncongestion, weather conditions, network \\neffects, Trafﬁc Management Initiatives, \\nand airline and aircraft-speciﬁc \\nattributes for every commercial ﬂight \\ndeparting from U.S. airports between \\n2008 and 2012. This data included over 50 \\nmillion ﬂights and around 100 variables \\nfor each ﬂight. The data included \\ncomposite variables (e.g. incoming ﬂight \\ndelay) that were constructed from the \\nraw data to capture relevant dynamics \\nof ﬂight operations. Data acquisition, \\nprocessing, quality control, and accuracy \\nbetween disparate datasets were \\nimportant steps during this process. \\nThe team applied supervised learning \\nalgorithms to develop Bayesian Belief \\nNetwork (BBN) models to predict ﬂight departure deviation. The most critical \\nsteps in model development were the \\nselection of optimal algorithms to \\ndiscretize model variables, and the \\nselection of appropriate machine learning \\ntechniques to learn the model from the \\ndata. The team followed information \\ntheory principles to discretize model \\nvariables to maximize the model’s \\npredictive power, and to represent the \\ndata as closely as possible with the \\nleast amount of network complexity. \\nBooz Allen segmented the model \\nvariables into three different categories \\nbased on the time to ﬂight departure: \\n24 hours, 11 hours, and one hour. \\nCertain ﬂight variables could only \\nbe known for speciﬁc pre-departure \\ntimes. For example, the tarmac and \\nairspace congestion variables for \\na ﬂight are only known just before \\nthe ﬂight, and hence those variables \\nfeature only in the one hour category. \\nDeparture delays were predicted for \\neach of the three time horizons. ››\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 106}),\n",
       " Document(page_content=\"Our Impact\\nFor a typical airport, the model delivers a delay prediction improvement of between \\n100,000 and 500,000 minutes annually over previous FAA predictions. The model can \\nbe used by a range of aviation stakeholders, such as airlines, to better understand \\nand predict network ﬂight delays. This can improve the airlines’ operational decisions \\nto include more proactive schedule adjustments during times of disruption (e.g. \\nweather or sector load). The improved reliability of departure prediction will improve \\nFAA's predictions for airports, sectors, and other resources, and has the potential to \\nenable improved real-time trafﬁc ﬂow management, which can signiﬁcantly reduce \\nairline departure, delays, and the associated economic costs. This means a more \\nefﬁcient and effective air transportation network.\\n107 Putting it all Together\", metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 107}),\n",
       " Document(page_content='Making Vaccines Safer  \\nAnalytic Challenge\\nThe U.S. Food and Drug Administration (FDA) Center for Biologics Evaluation and \\nResearch (CBER) is responsible for protecting public health by assuring the safety \\nand efﬁcacy of biologics, including vaccines, blood and blood products. CBER’s \\ncurrent surveillance process, which requires resource-intensive manual review by \\nexpert Medical Ofﬁcers, does not scale well to short-term workload variation and \\nlimits long-term improvements in review cycle-time. In addition, the large volume of \\nAdverse Event (AE) reports received by the Agency makes it difﬁcult for reviewers to \\ncompare safety issues across products and patient populations. \\nCBER engaged Booz Allen Hamilton to develop advanced analytics approaches for \\nthe triage and analysis of AE reports. The main goal was to leverage (1) Natural \\nLanguage Processing (NLP) to alleviate resource pressures by semi-automating \\nsome of the manual review steps through techniques, such as text classiﬁcation \\nand entity extraction, and (2) network visualizations to offer alternative interactions \\nwith datasets and support AE pattern recognition. By integrating NLP and network \\nanalysis capabilities into the Medical Ofﬁcer’s review process, Booz Allen successfully \\nprovided decision-makers with important information concerning product risks and \\npossible mitigations that can reduce risk.\\nOur Approach\\nWe designed and developed a set \\nof prototypes for the analysis and \\nvisualization of complex structured \\nand unstructured AE datasets. We \\ndeveloped tools that leverage NLP \\nand network analysis to extend and \\nenhance CBER’s efforts to monitor the \\nsafety of biologics and manage safety \\nthroughout the product lifecycle. \\nAdverse Event Text Mining Analytics. \\nReviewing AE reports involves sorting \\nbased on the likelihood of a relationship \\nbetween a product and reported adverse \\nevents. Since much of an AE report is \\nunstructured text, and most reports \\nare not directly related to the use of \\nthe implicated biologic, manual review \\nis time consuming and inefﬁcient. To \\naddress these challenges, we enhanced \\nand integrated tools for text mining \\nand NLP of AE reports using open \\nsource tools, including Python and R. By extracting diagnosis, cause of death, and \\ntime to onset, and presenting relevant \\ninformation for review, the text-mining \\ntool streamlines and enhances the post \\nmarket surveillance process.\\nAdverse Event Network Analytics. \\nVisualizing relationships between \\nvaccines and AEs can reveal new \\npatterns and trends in the data, leading \\nreviewers to uncover safety issues. \\nTo assist CBER Medical Ofﬁcers and \\nresearchers in identifying instances \\nwhere certain vaccines or combinations \\nof vaccines might have harmful \\neffects on patients, we developed an \\nAE network analysis tool using open \\nsource tools. This network analyzer \\nallows users to select partitions of the \\nFDA Vaccine Adverse Event Reporting \\nSystem (VAERS) database, generate a \\nco-occurrence matrix, view networks \\nand network metrics (e.g., betweenness, ››\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 108}),\n",
       " Document(page_content='closeness, degree, strength), and \\ninteract with network nodes to gain \\ninsights into product safety issues.\\nOther Analytics Solutions.  In addition, \\nBooz Allen refactored, modularized, \\nand expended the capabilities of CBER’s \\ncomputer simulation model of the Bovine \\nSpongiform Encephalopathy (BSE) \\nagent to improve estimates of variant \\nCreutzfeldt-Jakob disease (vCJD) risk \\nfor blood products, developed code to handle large amounts of data generated \\nby a Monte Carlo Markov Chain analysis \\nof the spread of inﬂuenza, developed \\na large database analysis strategy \\ninvolving the application of classiﬁcation \\nalgorithms to simulated genomic data, \\nand implemented a Statistical Analysis \\nSoftware (SAS) macro that automatically \\ncompares the relative potency of a given \\nlot of vaccine using a matched set of dose \\nresponse curves.  \\nOur Impact\\nNew methods for post market surveillance of biologics are critical for FDA reviewers \\nwho must determine whether reported adverse events are actually a result of a \\nbiologic product. With more than 10 million vaccines administered each year to \\nchildren less than one-year old, CBER reviewers are under pressure to quickly \\nevaluate potential safety signals through manual evaluation of AE reports, review \\nof scientiﬁc literature, and analysis of cumulative data using frequency calculations \\nor statistical algorithms. Booz Allen’s support resulted in the development \\nof innovative and data-driven approaches for the analysis of structured and \\nunstructured AE reports. We increased the speed of existing text mining tools by \\ntwo thousand times, allowing CBER reviewers to run a text mining algorithm to \\nextract information contained in VAERS reports in seconds, instead of hours. We \\nalso increased the productivity of Medical Ofﬁcers through the implementation \\nof text mining and network analysis tools. These new capabilities allow CBER to \\nstreamline the post market review process, extract knowledge from scientiﬁc data, \\nand address public concerns regarding vaccine safety more quickly and efﬁciently.\\n109 Putting it all Together', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 109}),\n",
       " Document(page_content='Forecasting the Relative Risk \\nfor the Onset of Mass Killings to \\nHelp Prevent Future Atrocities\\nAnalytic Challenge\\nMass atrocities are rare yet devastating crimes. They are also preventable. Studies \\nof past atrocities show that we can detect early warning signs of atrocities and that \\nif policy makers act on those warnings and develop preventive strategies, we can \\nsave lives. Yet despite this awareness, all too often we see warning signs missed and \\naction taken too late, if at all, in response to threats of mass atrocities. \\nThe Early Warning Project, an initiative of the United States Holocaust Memorial \\nMuseum (Holocaust Museum), aims to assess a country’s level of risk for the onset \\nof future mass killings. Over time, the hope is to learn which models and which \\nindicators are the best at helping anticipate future atrocities to aid in the design and \\nimplementation of more targeted and effective preventive strategies. By seeking to \\nunderstand why and how each countries’ relative level of risk rises and falls over \\ntime, the system will deepen understanding of where new policies and resources can \\nhelp make a difference in averting atrocities and what strategies are most effective. \\nThis will arm governments, advocacy groups, and at-risks societies with earlier and \\nmore reliable warning, and thus more opportunity to take action, well before mass \\nkillings occur.\\nThe project’s statistical risk assessment seeks to build statistical and machine \\nlearning algorithms to predict the onset of a mass killing in the succeeding 12 months \\nfor each country with a population larger than 500,000. The publically available system \\naggregates and provides access to open source datasets as well as democratizes the \\nsource code for analytic approaches developed by the Holocaust Museum staff and \\nconsultants, the research community, and the general public. The Holocaust Museum \\nengaged Booz Allen to validate existing approaches as well as explore new and \\ninnovative approaches for the statistical risk assessment. \\nOur Approach\\nTaking into account the power of \\ncrowdsourcing, Booz Allen put out a call \\nto employees to participate in a hack-a-\\nthon—just the start of the team’s support \\nas the Museum reﬁned and implemented \\nthe recommendations. More than 80 \\nBooz Allen Hamilton software engineers, \\ndata analysts, and social scientists \\ndevoted a Saturday to participate. \\nInterdisciplinary teams spent 12 hours identifying new datasets, building new \\nmachine learning models, and creating \\nframeworks for ensemble modeling \\nand interactive results visualization.  \\nFollowing the hack-a-thon, Booz \\nAllen Data Scientists worked with \\nHolocaust Museum staff to create \\na data management framework to \\nautomate the download, aggregation, \\nand transformation of the open ››\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 110}),\n",
       " Document(page_content='source datasets used by the statistical \\nassessment. This extensible \\nframework allows integration of new \\ndatasets with minimal effort, thereby supporting greater engagement by \\nthe Data Science community. \\n  \\nOur Impact\\nPublically launched in the fall of 2015, the Early Warning Project can now leverage \\nadvanced quantitative and qualitative analyses to provide governments, advocacy \\ngroups and at-risk societies with assessments regarding the potential for mass \\natrocities around the world. Integration of the project’s statistical risk assessment \\nmodels and expert opinion pool created a publicly available source of invaluable \\ninformation and positioned Data Science at the center of global diplomacy.  \\nThe machine learning models developed during the hack-a-thon achieved \\nperformance on par with state of the art approaches as well as demonstrated the \\nefﬁcacy of predictions 2-5 years into the future. Teams also identiﬁed approaches for \\nconstructing test/validation sets that support more robust model evaluation. These \\nrisk assessments are an important technological achievement in and of themselves, \\nbut what this initiative means for the Data Science community’s position in global \\ndiplomatic dialogue marks an entirely new era for those on the frontiers of Big Data.\\nThe data management framework developed from the lessons learned of the hack-\\na-thon represents a great leap forward for the Holocaust Museum. The periodicity \\nof aggregating and transforming data was reduced from twice per year to once \\nper week. In addition to providing the community with more up-to-date data, the \\nreduced burden on researchers enables them to spend more time analyzing data and \\nidentifying new and emergent trends. The extensible framework will also allow the \\nHolocaust Museum to seamlessly integrate new datasets as they become available or \\nare identiﬁed by the community as holding analytic value for the problem at hand. \\nThrough this project, the Holocaust Museum was able to shift the dynamic from \\nmonitoring ongoing violence to determining where it is likely to occur 12 to 24 months \\ninto the future by integrating advanced quantitative and qualitative analyses to assess \\nthe potential for mass atrocities around the world. The Early Warning Project is an \\ninvaluable predictive resource supporting the global diplomatic dialogue. While the \\nfocus of this effort was on the machine learning and data management technologies \\nbehind the initiative, it demonstrates the growing role the Data Science community is \\nplaying at the center of global diplomatic discussions.\\n111 Putting it all Together', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 111}),\n",
       " Document(page_content='Predicting Customer Response\\nAnalytic Challenge\\nIt is very challenging to know how a customer will respond to a given promotional \\ncampaign.  Together with the InterContinental Hotels Group (IHG), Booz Allen \\nHamilton explored approaches to predict customer-by-customer response to a state-\\nof-the-art promotional campaign in order to better understand and increase return on \\ninvestment (ROI). \\nIn the past, conventional statistics have worked well for analyzing the impact of \\ndirect marketing promotions on purchase behavior . Today, modern multi-channel \\npromotions often result in datasets that are highly dimensional and sometimes \\nsparse, which strains the power of conventional statistical methods to accurately \\nestimate the effect of a promotion on individual purchase decisions. Because of \\nthe growing frequency of multi-channel promotions, IHG was driven to investigate \\nnew approaches. In particular , IHG and Booz Allen studied one recent promotional \\ncampaign using hotel, stay, and guest data for a group of loyalty program customers.  \\nOur Approach\\nWorking closely with IHG experts, Booz Allen investigated three key elements related \\nto different stages of analytic maturity:\\nDescribe:  Using initial data mining, what \\ninsights or tendencies in guest behaviors \\ncan be identiﬁed after joining multiple, \\ndisparate datasets?\\nDiscover: Can we determine which \\ncontrol group members would be likely to \\nregister for a promotion if offered? If so, \\ncan we also quantify their registration?\\nPredict: How would a hotel guest that \\nreceived the promotion have responded \\nif they were not offered the promotion? \\nHow would a hotel guest that did not \\nreceive the promotion have responded \\nif they were offered the promotion?\\nFor the promotion that was the focus \\nof this case study, not everything about \\ncustomers could be controlled as required \\nby traditional statistics. However , because a probabilistic Bayesian Belief Network \\n(BBN) can learn the pairwise relationships \\nbetween all individual customer attributes \\nand their impact on promotional \\nreturn, Booz Allen investigated how \\nthis technique could be used to model \\neach treated customer without an exact \\ncontrolled look-alike.  \\nSpeciﬁcally, Booz Allen developed a BBN \\nto predict customer-by-customer impacts \\ndriven by promotional campaign offers, \\nsubsequently estimating the aggregated \\nROI of individual campaigns. We used six \\nmachine learning techniques (support \\nvector machine, random forest, decision \\ntree, neural network, linear model, and \\nAdaBoost) in unison with the BBN to \\npredict how each customer would be \\ninﬂuenced by a promotional offer.››\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 112}),\n",
       " Document(page_content='Our Impact\\nThe probabilistic model was capable of predicting customer response to the \\npromotion, without relying on a costly control group. This ﬁnding represents millions \\nof dollars of savings per promotional campaign. This analysis is an industry-\\nﬁrst for the travel and hospitality sector, where demand for more data-driven \\napproaches to optimize marketing ROI at an individual level is rapidly growing.\\nBecause Booz Allen and IHG’s approach enabled estimation of ROI for each \\nhypothetical customer, even when no exact look-alikes exist, there are a number \\nof valuable future applications. One such application is optimal campaign design—\\nthe ability to estimate the promotional attributes for an individual customer \\nthat are likely to drive the greatest incremental spend. Another application is \\nefﬁcient audience selection - which would reduce the risk of marketing “spam” \\nthat prompts costly unsubscriptions and can negatively impact a hotel’s brand. \\n113 Putting it all Together', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 113}),\n",
       " Document(page_content='', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 114}),\n",
       " Document(page_content='CLOSING    TIME', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 115}),\n",
       " Document(page_content='THE FUTURE   of   \\n        DATA SCIENCE  \\nData Science is rapidly evolving as it touches every aspect of our \\nlives on a daily basis. As Data Science changes the way we interact \\nwith, and explore our world, the algorithms and applications of \\nData Science continue to advance. We expect this trend to continue \\nas Data Science has an increasingly profound effect on humanity. \\nWe describe here some of the trends and developments we \\nanticipate emerging in the field of Data Science over the coming years. \\nThe advancements in some Data Science algorithms will deliberately \\ntrack the evolution of data structures and data models that Data \\nScientists are using to represent their domains of study. One of the \\nclearest examples of this linkage is in the development of massive-\\nscale graph analytics algorithms, which are deployed on graph \\ndatabases (including network data and semantically linked databases) . \\nIt is sometimes said “all the world is a graph,” and consequently the \\nmost natural data structure is not a table with rows and columns, but \\na network graph with nodes and edges. Graph analytics encompasses \\ntraditional methods of machine learning, but with a graph-data twist.\\nAnother growth area in Data Science algorithms is in the domain \\nof geospatial temporal predictive analytics, which can be applied \\nto any dataset that involves geospatial location and time – that \\ndescribes just about everything in our lives! We expect increasingly \\nsophisticated deployments of this methodology in the areas of law \\nenforcement, climate change, disaster management, population \\nhealth, sociopolitical change, and more. \\nIt is obvious that bigger, faster, and more complex datasets will \\nrequire faster (hyperfast!) analytics. We anticipate advanced \\nData Science algorithms that take advantage of technological \\nadvancements in quantum machine-learning, in-memory data \\noperations, and machine learning on specialized devices (e.g., \\nthe GPU, Raspberry Pi, or the next-generation mobile handheld \\n“supercomputer”).  In such commodity devices, we expect to see \\ndevelopment of more embedded machine learning (specifically, deep \\nlearning)  algorithms that perform time-critical data-to-insights \\ntransformations at the point of data collection. Such use cases will \\nbe in great abundance within the emerging Internet of Things  (IoT) , \\nincluding the industrial IoT and the internet of everything.\\nAdvances in cognitive machine learning are on the horizon, \\nincluding open source and configurable algorithms that exploit \\nstreaming real-time data’s full content, context, and semantic \\nmeaning. The ability to use the 360-degree view of a situation will \\nenable the delivery of the right action, at the right time, at the right \\nplace, in the right context – this is the essence of cognitive analytics. \\nAnother way to view cognitive analytics is that, given all of the \\ndata and the context for a given object or population, the algorithm \\nidentifies the right question that you should be asking of your data \\n(which might not be the question that you traditionally asked) .››\\nKirk Borne\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 116}),\n",
       " Document(page_content='Another area of Data Science evolution that tracks with the growth \\nin a particular data type is that of unstructured data, specifically text. \\nThe growth of such unstructured data is phenomenal, and demands \\nricher algorithms than those used on numerical data, since there are \\nmany more shades of meaning in natural language than in tables of \\nnumbers. The new Data Science algorithms for unstructured data \\nwill be applied in multiple directions. Natural Language Generation \\nwill be used to convert data points into text, which can be used \\nto generate the data’s story automatically.  Structured Database \\nGeneration will transform text documents or other unstructured \\ndata into data points (i.e., converting qualitative data into machine-\\ncomputable quantitative data).\\nAll of these technical advancements, plus others that we cannot \\nyet imagine, will be brought to bear on new domains. Some of the \\nhottest, most critical domains in which Data Science will be applied \\nin the coming years include: \\n ›Cybersecurity  including advanced detection, modeling, prediction, and  \\nprescriptive analytics\\n ›Healthcare  including genomics, precision medicine, population health, healthcare \\ndelivery, health data sharing and integration, health record mining, and wearable \\ndevice analytics\\n ›IoT  including sensor analytics, smart data, and emergent discovery alerting and response\\n ›Customer Engagement and Experience  including 360-degree view, gamification, \\nand just-in-time personalization\\n ›Smart X , where X = cities, highways, cars, delivery systems, supply chain, and more\\n ›Precision Y , where Y = medicine, farming, harvesting, manufacturing, pricing, and more\\n ›Personalized Z , where Z = marketing, advertising, healthcare, learning, and more\\n ›Human capital (talent) and organizational analytics\\n ›Societal good\\nTHE FUTURE OF\\nDATA SCIENCEAlgorithms Applications\\n› Massive-scale Graph\\n› Geospatial Temporal Predictive Analytics\\n› Hyperfast Analytics\\n› Embedded Deep Learning\\n› Cognitive Machine Learning\\n› Natural Language Generation\\n› Structured Database Generation › Cybersecurity\\n› Healthcare\\n› Internet of Things\\n› Customer Engagement & Experience\\n› Smart Everything\\n› Human Capital\\n› Data for Societal Good \\n117 Closing Time', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 117}),\n",
       " Document(page_content='', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 118}),\n",
       " Document(page_content='PARTING   \\nTHOUGHTS  \\nData Science capabilities are creating data analytics that are \\ntouching every aspect of our lives on a daily basis. From visiting \\nthe doctor, to driving our cars, to shopping for services Data \\nScience is quietly changing the way we interactive with and \\nexplore our world. We hope we have helped you truly understand \\nthe potential of your data and how to become extraordinary \\nthinkers by asking the right questions. We hope we have helped \\ncontinue to drive forward the science and art of Data Science. \\nMost importantly, we hope you are leaving with a newfound \\npassion and excitement for Data Science.  \\nThank you for taking this journey with us. Please join our \\nconversation and let your voice be heard. Email us your ideas \\nand perspectives at data_science@bah.com  or submit them \\nvia a pull request on the Github repository .  \\n \\nTell us and the world what you know. Join us. Become an \\nauthor of this story.››\\n119 Closing Time', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 119}),\n",
       " Document(page_content='REFERENCES\\n1. Commonly attributed to: Nye, Bill. Reddit Ask Me Anything  (AMA). \\nJuly 2012. Web. Accessed 15 October 2013. SSRN: < http://www.reddit.\\ncom/r/IAmA/comments/x9pq0/iam_bill_nye_the_science_guy_ama >\\n2. Fayyad, Usama, Gregory Piatetsky-Shapiro, and Padhraic Smyth. “From \\nData Mining to Knowledge Discovery in Databases.” AI Magazine 17.3 \\n(1996): 37-54. Print.\\n3. “Mining Data for Nuggets of Knowledge.” Knowledge@Wharton ,1999. \\nWeb. Accessed 16 October 2013. SSRN: < http://knowledge.wharton.\\nupenn.edu/article/mining-data-for-nuggets-of-knowledge >\\n4. Cleveland, William S. “Data Science: An Action Plan for Expanding \\nthe Technical Areas of the Field of Statistics.” International Statistical \\nReview  69.1 (2001): 21-26. Print.\\n5. Davenport, Thomas H., and D.J. Patil. “Data Scientist: The Sexiest Job \\nof the 21st Century.” Harvard Business Review  90.10 (October 2012): \\n70–76. Print.\\n6. Smith, David. “Statistics vs Data Science vs BI.” Revolutions , 15 \\nMay 2013. Web. Accessed 15 October 2013. SSRN:< http://blog.\\nrevolutionanalytics.com/2013/05/statistics-vs-data-science-vs-bi.html >\\n7. Brynjolfsson, Erik, Lorin M. Hitt, and Heekyung H. Kim. “Strength \\nin Numbers: How Does Data-Driven Decision Making Affect Firm \\nPerformance?” Social Science Electronic Publishing , 22 April 2011. Web. \\nAccessed 15 October 2013. SSRN: < http://ssrn.com/abstract=1819486 \\nor http://dx.doi.org/10.2139/ssrn.1819486 >\\n8. “The Stages of an Analytic Enterprise.” Nucleus Research . February 2012. \\nWhitepaper.\\n9. Barua, Anitesh, Deepa Mani, and Rajiv Mukherjee. “Measuring the \\nBusiness Impacts of Effective Data.” University of Texas . Web. Accessed \\n15 October 2013. SSRNL: < http://www.sybase.com/files/White_Papers/\\nEffectiveDataStudyPt1-MeasuringtheBusinessImpactsofEffectiveDa\\nta-WP .pdf >\\n10. Zikopoulos, Paul, Dirk deRoos, Kirshnan Parasuraman, Thomas Deutsch, \\nDavid Corrigan and James Giles. Harness the Power of Big Data: The IBM \\nBig Data Platform . New York: McGraw Hill, 2013. Print. 281pp.››\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 120}),\n",
       " Document(page_content='11. Booz Allen Hamilton. Cloud Analytics Playbook . 2013. Web. Accessed 15 \\nOctober 2013. SSRN: < http://www.boozallen.com/media/file/Cloud-\\nplaybook-digital.pdf >\\n12. Conway, Drew. “The Data Science Venn Diagram.” March 2013. \\nWeb. Accessed 15 October 2013. SSRN: < http://drewconway.com/\\nzia/2013/3/26/the-data-science-venn-diagram >\\n13. Booz Allen Hamilton. Tips for Building a Data Science Capability . 2015. \\nWeb Accessed 2 September 2015. SSRN: < https://www.boozallen.com/\\ncontent/dam/boozallen/documents/2015/07/DS-Capability-Handbook.pdf >\\n14. Mnih et al. 2015. Human-level control through deep reinforcement \\nlearning. Nature. 518: 529-533.\\n15. Torán, Jacobo. “On the Hardness of Graph Isomorphism.” SIAM Journal \\non Computing . 33.5 (2004): 1093-1108. Print.\\n16. Guyon, Isabelle and Andre Elisseeff. “An Introduction to Variable and \\nFeature Selection.” Journal of Machine Learning Research 3 (March \\n2003):1157-1182. Print.\\n17. Golub T., D. Slonim, P. Tamayo, C. Huard, M. Gaasenbeek, J. Mesirov, \\nH. Coller, M. Loh, J. Downing, M. Caligiuri, C. Bloomfield, and E. \\nLander. “Molecular Classification of Cancer: Class Discovery and Class \\nPrediction by Gene Expression Monitoring.” Science.  286.5439 (1999): \\n531-537. Print.\\n18. Haykin, Simon O. Neural Networks and Learning Machines . New Jersey: \\nPrentice Hall, 2008. Print.\\n19. De Jong, Kenneth A. Evolutionary Computation - A Unified Approach . \\nMassachusetts: MIT Press, 2002. Print.\\n20. Yacci, Paul, Anne Haake, and Roger Gaborski. “Feature Selection of \\nMicroarray Data Using Genetic Algorithms and Artificial Neural \\nNetworks.” ANNIE 2009. St Louis, MO. 2-4 November 2009. \\nConference Presentation.\\n121 Closing Time', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 121}),\n",
       " Document(page_content='', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 122}),\n",
       " Document(page_content='About  \\n  BOOZ ALLEN    \\n  HAMILTON\\nBooz Allen Hamilton  has been at the forefront of strategy and \\ntechnology for more than 100 years. Today, the firm provides \\nmanagement and technology consulting and engineering services to \\nleading Fortune 500 corporations, governments, and not-for-profits \\nacross the globe. Booz Allen partners with public and private sector \\nclients to solve their most difficult challenges through a combination \\nof consulting, analytics, mission operations, technology, systems \\ndelivery, cybersecurity, engineering, and innovation expertise.\\nWith international headquarters in McLean, Virginia, the firm \\nemploys more than 22,500 people globally, and had revenue of $5.27 \\nbillion for the 12 months ended March 31, 2015. To learn more, visit \\nwww.boozallen.com . (NYSE: BAH)››\\n123 Closing Time', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 123}),\n",
       " Document(page_content='', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 124}),\n",
       " Document(page_content='', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 125})]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunkdata = RecursiveCharacterTextSplitter(chunk_size=5000,chunk_overlap=0) # Chunk size as 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitdocs = chunkdata.split_documents(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splitdocs) # Length of splitted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{117}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{len(splitdocs[0].page_content)} # Finding number of characters after chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='ACKNOWLEDGEMENTS\\nWe  w o u l d  l i k e  to  e x p r e s s  o u r  s i n c e r e s t  g ra t i t u d e  to  \\nall those who have made The Field Guide to Data \\nScience  such a success. \\nThank you to the nearly 15,000 \\npeople who have downloaded \\nthe digital copy from our website \\nand the 100+ people who have \\nconnected with The Field Guide \\non our GitHub page . We have \\nbeen overwhelmed by the \\npopularity of the work within the \\nData Science community. \\nThank you to all of the \\npractitioners who are using The \\nField Guide as a resource. We are \\nexcited to know that the work has \\nhad such a strong influence, from \\nshaping technical approaches to \\nserving as the foundation for the \\nvery definition and role of Data \\nScience within major government \\nand commercial organizations. Thank you to the educators and \\nacademics who have incorporated \\nThe Field Guide into your course \\nwork. We appreciate your trusting \\nthis guide as a way to introduce \\nyour students to Data Science.   \\nIt is an honor to know that we are \\nshaping the next generation of \\nData Scientists.\\nThank you to the organizational \\nleaders who have shared your \\nfeedback, encouragement, and \\nsuccess stories. We are thrilled  \\nto know that The Field Guide  \\nhas helped so many organizations, \\nfrom energy, to life sciences,  \\nto retail, to begin their Data \\nScience journeys.  \\nWe hope you will all continue to find value from The Field \\nGuide to Data Science and to share in our excitement around the \\nrelease of this second edition. Please continue to be part of the \\nconversation and take this journey with us. ››', metadata={'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf', 'page': 9, 'text': 'ACKNOWLEDGEMENTS\\nWe  w o u l d  l i k e  to  e x p r e s s  o u r  s i n c e r e s t  g ra t i t u d e  to  \\nall those who have made The Field Guide to Data \\nScience  such a success. \\nThank you to the nearly 15,000 \\npeople who have downloaded \\nthe digital copy from our website \\nand the 100+ people who have \\nconnected with The Field Guide \\non our GitHub page . We have \\nbeen overwhelmed by the \\npopularity of the work within the \\nData Science community. \\nThank you to all of the \\npractitioners who are using The \\nField Guide as a resource. We are \\nexcited to know that the work has \\nhad such a strong influence, from \\nshaping technical approaches to \\nserving as the foundation for the \\nvery definition and role of Data \\nScience within major government \\nand commercial organizations. Thank you to the educators and \\nacademics who have incorporated \\nThe Field Guide into your course \\nwork. We appreciate your trusting \\nthis guide as a way to introduce \\nyour students to Data Science.   \\nIt is an honor to know that we are \\nshaping the next generation of \\nData Scientists.\\nThank you to the organizational \\nleaders who have shared your \\nfeedback, encouragement, and \\nsuccess stories. We are thrilled  \\nto know that The Field Guide  \\nhas helped so many organizations, \\nfrom energy, to life sciences,  \\nto retail, to begin their Data \\nScience journeys.  \\nWe hope you will all continue to find value from The Field \\nGuide to Data Science and to share in our excitement around the \\nrelease of this second edition. Please continue to be part of the \\nconversation and take this journey with us. ››'})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitdocs[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing pinecone vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"langchain2\" # Created index in pinecone db and defined here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "vembeddings = PineconeVectorStore.from_documents(splitdocs[:15],OllamaEmbeddings(model='mxbai-embed-large'),index_name=index_name) # Ollama Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performed Ollama Embeddings and performed vector embeddings for the book. Sliced out the book since it contains a lot of pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instancing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "groqllm = ChatGroq(model='llama3-8b-8192',temperature=0) # Groq Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(groqllm,chain_type=\"map_reduce\",verbose=True)  # Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"DATA SCIENCEtoTHE\n",
      "FIEL D GUIDE\n",
      "    \n",
      " \n",
      "SECOND  \n",
      "EDITION\n",
      "© COPYRIGHT 2015 BOOZ ALLEN HAMILTON INC. ALL RIGHTS RESERVED.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"FOREWORD\n",
      "Data Science touches every aspect of our lives on a \n",
      "daily basis. When we visit the doctor, drive our cars, \n",
      "get on an airplane, or shop for services, Data Science \n",
      "is changing the way we interact with and explore  \n",
      "our world.  \n",
      "Our world is now measured, \n",
      "mapped, and recorded in digital \n",
      "bits. Entire lives, from birth to \n",
      "death, are now catalogued in \n",
      "the digital realm. These data, \n",
      "originating from such diverse \n",
      "sources as connected vehicles, \n",
      "underwater microscopic cameras, \n",
      "and photos we post to social \n",
      "media, have propelled us into \n",
      "the greatest age of discovery \n",
      "humanity has ever known. It is \n",
      "through Data Science that we \n",
      "are unlocking the secrets hidden \n",
      "within these data. We are making \n",
      "discoveries that will forever \n",
      "change how we live and interact \n",
      "with the world around us. \n",
      "The impact of these changes \n",
      "is having a profound effect on \n",
      "humanity. We have propelled \n",
      "ourselves into this age of \n",
      "discovery through our incremental \n",
      "technological improvements. \n",
      "Data Science has become the \n",
      "catalyzing force behind our next \n",
      "evolutionary leap. Our own \n",
      "evolution is now inextricably \n",
      "linked to that of computers. The \n",
      "way we live our lives and the skills \n",
      "that are important to our very \n",
      "existence are directly dependent \n",
      "upon the functions Data Science \n",
      "can achieve on our behalf.   As we move into this new \n",
      "future, it is clearer than ever, that \n",
      "businesses must adjust to these \n",
      "changes or risk being left behind. \n",
      "From influencing retail markets, \n",
      "to setting public health and safety \n",
      "policies, or to addressing social \n",
      "unrest, organizations of all types \n",
      "are generating value through  \n",
      "Data Science. Data is our new \n",
      "currency and Data Science is  \n",
      "the mechanism by which we tap \n",
      "into it. \n",
      "Data Science is an auspicious and \n",
      "profound way of applying our \n",
      "curiosity and technical tradecraft \n",
      "to solve humanity’s toughest \n",
      "challenges. The growing power, \n",
      "importance, and responsibility \n",
      "of applying Data Science \n",
      "methodologies to these challenges \n",
      "is unimaginable. Our own \n",
      "biases and assumptions can have \n",
      "profound outcomes on business, \n",
      "national security, and our daily \n",
      "lives. A new class of practitioners \n",
      "and leaders are needed to navigate \n",
      "this new future. Data Scientists \n",
      "are our guides on this journey as \n",
      "they are creating radical new ways \n",
      "of thinking about data and the \n",
      "world around us.  \n",
      " \n",
      "We want to share our passion for  Data Science  and start a \n",
      "conversation with you. This is a journey worth taking.  ››\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"Everyone you  \n",
      "will ever meet  \n",
      "knows something  \n",
      "you don’t.  [1]\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"THE STORY    \n",
      "    of    THE FIELD  \n",
      "GUIDE\n",
      "Several years ago we created The Field Guide to Data Science because \n",
      "we wanted to help organizations of all types and sizes.  There were \n",
      "countless industry and academic publications describing what  Data \n",
      "Science is and  why  we should care, but very little information was \n",
      "available to explain how to make use of data as a resource. We find \n",
      "that situation to be just as true today as we did two years ago, when \n",
      "we created the first edition of the field guide. \n",
      "At Booz Allen Hamilton, we built an industry-leading team of \n",
      "Data Scientists. Over the course of hundreds of analytic challenges \n",
      "for countless clients, we’ve unraveled the DNA of Data Science. \n",
      "Many people have put forth their thoughts on single aspects of \n",
      "Data Science. We believe we can offer a broad perspective on the \n",
      "conceptual models, tradecraft, processes and culture of Data Science \n",
      "– the what , the why, the who and the how.  Companies with strong \n",
      "Data Science teams often focus on a single class of problems – graph \n",
      "algorithms for social network analysis, and recommender models for \n",
      "online shopping are two notable examples. Booz Allen is different. \n",
      "In our role as consultants, we support a diverse set of government \n",
      "and commercial clients across a variety of domains. This allows us to \n",
      "uniquely understand the DNA of Data Science. \n",
      "Our goal in creating The Field Guide to Data Science was to  \n",
      "capture what we have learned and to share it broadly. The field  \n",
      "of Data Science has continued to advance since we first released  \n",
      "the field guide. As a result, we decided to release this second edition, \n",
      "incorporating a few new and important concepts. We also added \n",
      "technical depth and richness that we believe practitioners will  \n",
      "find useful. \n",
      "We want this effort to continue driving forward the science and \n",
      "art of Data Science.\n",
      "This field guide came from the passion our team feels for its \n",
      "work. It is not a textbook nor is it a superficial treatment. \n",
      "Senior leaders will walk away with a deeper understanding of \n",
      "the concepts at the heart of Data Science. Practitioners will \n",
      "add to their toolbox. We hope everyone will enjoy the journey.››\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"WE ARE ALL  \n",
      "AUTHORS   of    THIS   \n",
      "STORY\n",
      "We recognize that Data Science is a team sport. The Field Guide \n",
      "to Data Science  provides Booz Allen Hamilton’s perspective on the \n",
      "complex and sometimes mysterious field of Data Science. We cannot \n",
      "capture all that is Data Science. Nor can we keep up - the pace at \n",
      "which this field progresses outdates work as fast as it is produced.  \n",
      "As a result, we opened this field guide to the world as a living \n",
      "document to bend and grow with technology, expertise, and  \n",
      "evolving techniques. \n",
      "Thank you to all the people that have emailed us your ideas as \n",
      "well as the 100+ people who have watched, starred, or forked our \n",
      "GitHub repository. We truly value the input of the community, as \n",
      "we work together to advance the science and art of Data Science. \n",
      "This is why we have included authors from outside Booz Allen \n",
      "Hamilton on this second edition of The Field Guide to Data Science . \n",
      "If you find the guide to be useful, neat, or even lacking, then \n",
      "we encourage you to add your expertise, including:\n",
      "››Case studies from which you have learned \n",
      "››Citations from journal articles or papers that inspire you \n",
      "››Algorithms and techniques that you love \n",
      "››Your thoughts and comments on other people’s additions \n",
      " \n",
      "Email us your ideas and perspectives at data_science@bah.com  \n",
      "or submit them via a pull request on the GitHub repository .   \n",
      "Join our conversation and take the journey with us. Tell us and \n",
      "the world what you know. Become an author of this story.››\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"ACKNOWLEDGEMENTS\n",
      "We  w o u l d  l i k e  to  e x p r e s s  o u r  s i n c e r e s t  g ra t i t u d e  to  \n",
      "all those who have made The Field Guide to Data \n",
      "Science  such a success. \n",
      "Thank you to the nearly 15,000 \n",
      "people who have downloaded \n",
      "the digital copy from our website \n",
      "and the 100+ people who have \n",
      "connected with The Field Guide \n",
      "on our GitHub page . We have \n",
      "been overwhelmed by the \n",
      "popularity of the work within the \n",
      "Data Science community. \n",
      "Thank you to all of the \n",
      "practitioners who are using The \n",
      "Field Guide as a resource. We are \n",
      "excited to know that the work has \n",
      "had such a strong influence, from \n",
      "shaping technical approaches to \n",
      "serving as the foundation for the \n",
      "very definition and role of Data \n",
      "Science within major government \n",
      "and commercial organizations. Thank you to the educators and \n",
      "academics who have incorporated \n",
      "The Field Guide into your course \n",
      "work. We appreciate your trusting \n",
      "this guide as a way to introduce \n",
      "your students to Data Science.   \n",
      "It is an honor to know that we are \n",
      "shaping the next generation of \n",
      "Data Scientists.\n",
      "Thank you to the organizational \n",
      "leaders who have shared your \n",
      "feedback, encouragement, and \n",
      "success stories. We are thrilled  \n",
      "to know that The Field Guide  \n",
      "has helped so many organizations, \n",
      "from energy, to life sciences,  \n",
      "to retail, to begin their Data \n",
      "Science journeys.  \n",
      "We hope you will all continue to find value from The Field \n",
      "Guide to Data Science and to share in our excitement around the \n",
      "release of this second edition. Please continue to be part of the \n",
      "conversation and take this journey with us. ››\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"THE OUTLINE    \n",
      "                                of   OUR STORY\n",
      "12    ›› Meet Your Guides\n",
      "17    ›› The Short Version – The Core Concepts of Data Science\n",
      "18    ›› Start Here for the Basics –  An Introduction to Data Science\n",
      "What Do We Mean by Data Science?\n",
      "How Does Data Science Actually Work?\n",
      "What Does It Take to Create a Data Science Capability?\n",
      "46    ›› Take off the Training W heels –  The Practitioner’s Guide to Data Science\n",
      "Guiding Principles\n",
      "The Importance of Reason\n",
      "Component Parts of Data Science\n",
      "Fractal Analytic Model\n",
      "The Analytic Selection Process\n",
      "Guide to Analytic Selection  \n",
      "Detailed Table of Analytics\n",
      "84    ›› Life in the Trenches – Navigating Neck Deep in Data\n",
      "Going Deep into Machine Learning\n",
      "Feature Engineering\n",
      "Feature Selection\n",
      "Ensemble Models\n",
      "Data Veracity\n",
      "Application of Domain Knowledge\n",
      "The Curse of Dimensionality \n",
      "Model Validation\n",
      "102    ›› Putting it all T ogether –  Our Case Studies\n",
      "Streamlining Medication Review\n",
      "Reducing Flight Delays\n",
      "Making Vaccines Safer\n",
      "Forecasting the Relative Risk for the Onset of\n",
      " Mass Killings to Help Pr event Future Atrocities \n",
      "Predicting Customer Response\n",
      "114   ›› Closing Time  \n",
      "The Future of Data Science\n",
      "Parting Thoughts\n",
      "References\n",
      "About Booz Allen Hamilton››\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"MEET  your GUIDES\n",
      "Fred Blackburn\n",
      "(@boozallen)\n",
      "Data Science is a field that is  \n",
      "evolving at a very rapid pace…be  \n",
      "part of the journey.  \n",
      "Angela Zutavern\n",
      "(@angelazutavern)\n",
      "Data Science is about asking bigger \n",
      "questions, seeing future possibilities, \n",
      "and creating outcomes you desire.  Josh Sullivan \n",
      "(@joshdsullivan)\n",
      "Leading our Data Science team \n",
      "shows me every day the incredible \n",
      "power of discovery and human \n",
      "curiosity. Don’t be afraid to blend \n",
      "art and science to advance your \n",
      "own view of data analytics – it \n",
      "can be a powerful mixture.\n",
      "Steve Escaravage\n",
      "(@sescarav)\n",
      "Invest your time and energy \n",
      "in data that is difficult to \n",
      "assemble.  If it doesn’t exist, \n",
      "find a way to make it exist.Peter Guerra \n",
      "(@petrguerra)\n",
      "Data Science is the most fascinating \n",
      "blend of art and math and code \n",
      "and sweat and tears. It can take \n",
      "you to the highest heights and the \n",
      "lowest depths in an instant, but it \n",
      "is the only way we will be able to \n",
      "understand and describe the why.\n",
      "Ezmeralda Khalil\n",
      "(@ezmeraldakhalil)\n",
      "The power of data science \n",
      "lies in the execution.››\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"Steven Mills \n",
      "(@stevndmills)\n",
      "Data Science truly can \n",
      "change the world.\n",
      "Stephanie Beben\n",
      "(@boozallen)\n",
      "Begin every new data challenge \n",
      "with deep curiosity along with \n",
      "a healthy dose of skepticism.Alex Cosmas \n",
      "(@boozallen)\n",
      "Data scientists should be truth-\n",
      "seekers, not fact-seekers.\n",
      "Kirk Borne\n",
      "(@KirkDBorne)\n",
      "Focus on value, not volume.Brian Keller \n",
      "(@boozallen)\n",
      "Grit will get you farther than talent.\n",
      "Drew Farris \n",
      "(@drewfarris)\n",
      "Don’t forget to play. Play with \n",
      "tools, play with data, and play with \n",
      "algorithms. You just might discover \n",
      "something that will help you solve \n",
      "that next nagging problem. \n",
      "13 Meet Your Guides\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"Paul Yacci\n",
      "(@paulyacci)\n",
      "In the jungle of data, don't \n",
      "miss the forest for the trees, \n",
      "or the trees for the forest.\n",
      " \n",
      "Stephanie Rivera \n",
      "(@boozallen)\n",
      "I treat Data Science like I do rock \n",
      "climbing: awesome dedication \n",
      "leads to incremental improvement. \n",
      "Persistence leads to the top.Charles Glover\n",
      "(@MindAfterMath)\n",
      "The beauty of data science lies \n",
      "in satisfying curiosities about \n",
      "important problems by playing \n",
      "with data and algorithms.\n",
      "Aaron Sander \n",
      "(@ajsander) \n",
      "Data science is changing corporate \n",
      "culture to be more like the open \n",
      "source environment. More open, \n",
      "more collaborative, and faster paced.Michael Kim \n",
      "(@boozallen)\n",
      "Data science is both an art  \n",
      "and science. \n",
      "We would like to thank the following people for their \n",
      "contributions and edits: \n",
      "Tim Andrews, Mike Delurey, Greg Dupier, Jason Escaravage, \n",
      "Christine Fantaskey, Juergen Klenk, Dan Liebermann, Mark \n",
      "Rockley and Katie Wilks.\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"COMMUNITY  CONTRIBUTORS\n",
      "Will Cukierski, kaggle\n",
      "(@kaggle)\n",
      " \n",
      "I took the one in the direction  \n",
      "of the negative gradient,   \n",
      "And that has made all the difference.\n",
      "Armen Kherlopian \n",
      "(@akherlopian)\n",
      "A Data Scientist must \n",
      "continuously seek truth in spite \n",
      "of ambiguity; therein rests the \n",
      "basis of rigor and insight.Mark Herman\n",
      "(@cloudEBITDA)\n",
      "End every analysis with…  \n",
      "‘and therefore.’Ed Kohlwey \n",
      "(@ekohlwey)\n",
      "Data Science is about formally \n",
      "analyzing everything around you \n",
      "and becoming data driven.››\n",
      "Two roads diverged in a wood, and I—\n",
      "15 Meet Your Guides\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"TheSHORT                  \n",
      "  VERSION\n",
      "››Data Science is the art of turning data into actions.  \n",
      "It’s all about the tradecraft. Tradecraft is the process, tools and \n",
      "technologies for humans and computers to work together to \n",
      "transform data into insights.\n",
      "››Data Science tradecraft creates data products .  \n",
      "Data products provide actionable information without exposing \n",
      "decision makers to the underlying data or analytics (e.g., buy/sell \n",
      "strategies for financial instruments, a set of actions to improve \n",
      "product yield, or steps to improve product marketing).\n",
      "››Data Science supports and encourages shifting between \n",
      "deductive (hypothesis-based) and inductive (pattern-\n",
      "based) reasoning.  \n",
      "This is a fundamental change from traditional analysis approaches. \n",
      "Inductive reasoning and exploratory data analysis provide a means \n",
      "to form or refine hypotheses and discover new analytic paths. \n",
      "Models of reality no longer need to be static. They are constantly \n",
      "tested, updated and improved until better models are found. \n",
      "››Data Science is necessary for companies to stay with the \n",
      "pack and compete in the future.   \n",
      "Organizations are constantly making decisions based on gut \n",
      "instinct, loudest voice and best argument – sometimes they are \n",
      "even informed by real information. The winners and the losers in \n",
      "the emerging data economy are going to be determined by their \n",
      "Data Science teams. \n",
      "››Data Science capabilities can be built over time.  \n",
      "Organizations mature through a series of stages – Collect, \n",
      "Describe, Discover, Predict, Advise – as they move from data \n",
      "deluge to full Data Science maturity. At each stage, they can \n",
      "tackle increasingly complex analytic goals with a wider breadth \n",
      "of analytic capabilities. However, organizations need not reach \n",
      "maximum Data Science maturity to achieve success. Significant \n",
      "gains can be found in every stage.\n",
      "››Data Science is a different kind of team sport.   \n",
      "Data Science teams need a broad view of the organization. Leaders \n",
      "must be key advocates who meet with stakeholders to ferret out \n",
      "the hardest challenges, locate the data, connect disparate parts of \n",
      "the business, and gain widespread buy-in.››\n",
      "17 The Short Version 17\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"AN INTRODUCTION TO DATA SCIENCE\n",
      "If you haven’t heard of Data Science, you’re behind the \n",
      "times. Just renaming your Business Intelligence group \n",
      "the Data Science group is not the solution. START HERE    for   THE BASICS\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"What do We Mean by  \n",
      "Data Science?\n",
      "Describing Data Science is like trying to describe a sunset – it \n",
      "should be easy, but somehow capturing the words is impossible.\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"21 Start Here for the Basics 21 Start Here for the BasicsData Science Defined\n",
      "Data Science is the art of turning data into actions. This is \n",
      "accomplished through the creation of data products, which provide \n",
      "actionable information without exposing decision makers to the \n",
      "underlying data or analytics (e.g., buy/sell strategies for financial \n",
      "instruments, a set of actions to improve product yield, or steps to \n",
      "improve product marketing).\n",
      "Performing Data Science requires the extraction of timely, actionable \n",
      "information from diverse data sources to drive data products. \n",
      "Examples of data products include answers to questions such as: \n",
      "“Which of my products should I advertise more heavily to increase \n",
      "profit? How can I improve my compliance program, while reducing \n",
      "costs? What manufacturing process change will allow me to build a \n",
      "better product?” The key to answering these questions is: understand \n",
      "the data you have and what the data inductively tells you. » Data Product\n",
      "A data product provides actionable \n",
      "information without exposing \n",
      "decision makers to the underlying \n",
      "data or analytics. Examples include:\n",
      "• Movie Reco mmendations      \n",
      "• Weather F orecasts\n",
      "• Stock Market Predictions\n",
      "• Production Process \n",
      "Improvements\n",
      "• Health Diagnosis\n",
      "• Flu T rend Predictions\n",
      "• Targeted AdvertisingRead this for additional background:\n",
      "The term Data Science appeared \n",
      "in the computer science literature \n",
      "throughout the 1960s-1980s. \n",
      "It was not until the late 1990s \n",
      "however, that the field as we \n",
      "describe it here, began to  \n",
      "emerge from the statistics and \n",
      "data mining communities  \n",
      "(e.g., [2] and [3]). Data Science \n",
      "was first introduced as an \n",
      "independent discipline in 2001.[4] \n",
      "Since that time, there have been \n",
      "countless articles advancing the \n",
      "discipline, culminating with \n",
      "Data Scientist being declared the \n",
      "sexiest job of the 21st century.[5] \n",
      "We established our first Data \n",
      "Science team at Booz Allen \n",
      "in 2010. It began as a natural \n",
      "extension of our Business \n",
      "Intelligence and cloud infrastructure development  \n",
      "work. We saw the need for a  \n",
      "new approach to distill value \n",
      "from our clients’ data. We \n",
      "approached the problem \n",
      "with a multidisciplinary \n",
      "team of computer scientists, \n",
      "mathematicians and domain \n",
      "experts. They immediately \n",
      "produced new insights and \n",
      "analysis paths, solidifying the \n",
      "validity of the approach. Since \n",
      "that time, our Data Science  \n",
      "team has grown to 250 staff \n",
      "supporting dozens of clients \n",
      "across a variety of domains.  \n",
      "This breadth of experience \n",
      "provides a unique perspective  \n",
      "on the conceptual models, \n",
      "tradecraft, processes and  \n",
      "culture of Data Science.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"Source: Booz Allen Hamilton What makes Data Science Different?\n",
      "Data Science supports and encourages shifting between deductive \n",
      "(hypothesis-based) and inductive (pattern-based) reasoning.  This is \n",
      "a fundamental change from traditional analytic approaches. Inductive \n",
      "reasoning and exploratory data analysis provide a means to form or \n",
      "refine hypotheses and discover new analytic paths. In fact, to do the \n",
      "discovery of significant insights that are the hallmark of Data Science, \n",
      "you must have the tradecraft and the interplay between inductive \n",
      "and deductive reasoning. By actively combining the ability to reason \n",
      "deductively and inductively, Data Science creates an environment \n",
      "where models of reality no longer need to be static and empirically \n",
      "based. Instead, they are constantly tested, updated and improved until \n",
      "better models are found. These concepts are summarized in the figure, \n",
      "The Types of Reason and Their Role in Data Science Tradecraft .\n",
      "THE TYPES OF REASON…\n",
      "DEDUCTIVE REASONING:\n",
      " › Commonly associated \n",
      "with “formal logic.”\n",
      " › Involves reasoning from known \n",
      "premises, or premises presumed \n",
      "to be true, to a certain conclusion.\n",
      " › The conclusions reached are \n",
      "certain, inevitable, inescapable.INDUCTIVE REASONING\n",
      " › Commonly known as “informal \n",
      "logic,”  or “everyday argument.”\n",
      " › Involves drawing uncertain \n",
      "inferences, based on \n",
      "probabilistic reasoning.\n",
      " › The conclusions reached \n",
      "are probable, reasonable, \n",
      "plausible, believable.\n",
      "…AND THEIR ROLE IN DATA SCIENCE TRADECRAFT.\n",
      "DEDUCTIVE REASONING:\n",
      " › Formulate hypotheses about \n",
      "relationships and underlying models.\n",
      " › Carry out experiments with the data \n",
      "to test hypotheses and models.INDUCTIVE REASONING\n",
      " › Exploratory data analysis to \n",
      "discover or reﬁne hypotheses.\n",
      " › Discover new relationships, insights \n",
      "and analytic paths from the data.\n",
      "The Types of Reason and Their Role in Data Science Tradecraft\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"Source: Booz Allen Hamilton \n",
      "23 Start Here for the Basics 23 Start Here for the Basics\n",
      "The differences between Data Science and traditional analytic \n",
      "approaches do not end at seamless shifting between deductive \n",
      "and inductive reasoning. Data Science offers a distinctly different \n",
      "perspective than capabilities such as Business Intelligence. Data \n",
      "Science should not replace Business Intelligence functions within \n",
      "an organization, however. The two capabilities are additive and \n",
      "complementary, each offering a necessary view of business operations \n",
      "and the operating environment. The figure, Business Intelligence and \n",
      "Data Science – A Comparison,  highlights the differences between the \n",
      "two capabilities. Key contrasts include:\n",
      "››Discovery vs. Pre-canned Questions: Data Science actually \n",
      "works on discovering the question to ask as opposed to just \n",
      "asking it.\n",
      "››Power of Many vs. Ability of One: An entire team provides \n",
      "a common forum for pulling together computer science, \n",
      "mathematics and domain expertise. \n",
      "››Prospective vs. Retrospective:  Data Science is focused on \n",
      "obtaining actionable information from data as opposed to \n",
      "reporting historical facts.\n",
      "LOOKING BACKWARD AND FORWARD\n",
      "FIRST THERE WAS  \n",
      "BUSINESS INTELLIGENCE\n",
      "Deductive Reasoning\n",
      "Backward Looking\n",
      "Slice and Dice Data\n",
      "Warehoused and Siloed Data\n",
      "Analyze the Past, Guess the Future\n",
      "Creates Reports\n",
      "Analytic OutputNOW WE'VE ADDED  \n",
      "DATA SCIENCE\n",
      "Inductive and Deductive Reasoning\n",
      "Forward Looking\n",
      "Interact with Data\n",
      "Distributed, Real Time Data\n",
      "Predict and Advise\n",
      "Creates Data  Products\n",
      "Answer Questions and Create New Ones\n",
      "Actionable Answer\n",
      "Business Intelligence and Data Science - A Comparison  (adapted in part from [6])\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"What is the Impact of Data Science?\n",
      "As we move into the data economy, Data Science is the competitive \n",
      "advantage for organizations interested in winning – in whatever way \n",
      "winning is defined. The manner in which the advantage is defined \n",
      "is through improved decision-making. A former colleague liked to \n",
      "describe data-informed decision making like this: If you have perfect \n",
      "information or zero information then your task is easy – it is in between \n",
      "those two extremes that the trouble begins.  What he was highlighting is \n",
      "the stark reality that whether or not information is available, decisions \n",
      "must be made.\n",
      "The way organizations make decisions has been evolving for half a \n",
      "century. Before the introduction of Business Intelligence, the only \n",
      "options were gut instinct, loudest voice, and best argument. Sadly, this \n",
      "method still exists today, and in some pockets it is the predominant \n",
      "means by which the organization acts. Take our advice and never, ever \n",
      "work for such a company! \n",
      "Fortunately for our economy, most organizations began to inform \n",
      "their decisions with real information through the application of \n",
      "simple statistics. Those that did it well were rewarded; those that did \n",
      "not failed. We are outgrowing the ability of simple stats to keep pace \n",
      "with market demands, however. The rapid expansion of available data \n",
      "and the tools to access and make use of the data at scale are enabling \n",
      "fundamental changes to the way organizations make decisions. \n",
      "Data Science is required to maintain competitiveness in the \n",
      "increasingly data-rich environment. Much like the application of \n",
      "simple statistics, organizations that embrace Data Science will be \n",
      "rewarded while those that do not will be challenged to keep pace. As \n",
      "more complex, disparate datasets become available, the chasm between \n",
      "these groups will only continue to widen. The figure, The Business \n",
      "Impacts of Data Science, highlights the value awaiting organizations \n",
      "that embrace Data Science.\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"Source: Booz Allen Hamilton \n",
      "25 Start Here for the Basics 25 Start Here for the Basics\n",
      "DATA SCIENCE IS NECESSARY...\n",
      "17-49%  increase in productivity when organizations increase data \n",
      "usability by 10%\n",
      "11-42%   return on assets (ROA) when organizations increase data \n",
      "access by 10% \n",
      "241%   increase in ROI when or ganizations use big data to  \n",
      "improve competitiveness\n",
      "1000%  increase in ROI when deploying analytics across most of \n",
      "the organization, aligning daily operations with senior \n",
      "management's goals, and incorporating big data\n",
      "5-6%   performanc e improvement for organizations making  \n",
      "data-driven decisions. \n",
      "...TO COMPETE IN THE FUTURE\n",
      "The Business Impacts of Data Science  (adapted from [7], [8] and [9])\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"27 Start Here for the Basics 27 Start Here for the BasicsWhat is Different Now?\n",
      "For 20 years IT systems were built the same way. We separated \n",
      "the people who ran the business from the people who managed the \n",
      "infrastructure (and therefore saw data as simply another thing they \n",
      "had to manage). With the advent of new technologies and analytic \n",
      "techniques, this artificial – and highly ineffective – separation of \n",
      "critical skills is no longer necessary. For the first time, organizations \n",
      "can directly connect business decision makers to the data. This simple \n",
      "step transforms data from being ‘something to be managed’ into \n",
      "‘something to be valued.’\n",
      "In the wake of the transformation, organizations face a stark choice: \n",
      "you can continue to build data silos and piece together disparate \n",
      "information or you can consolidate your data and distill answers. \n",
      "From the Data Science perspective, this is a false choice: The siloed \n",
      "approach is untenable when you consider the (a) the opportunity \n",
      "cost of not making maximum use of all available data to help \n",
      "an organization succeed, and (b) the resource and time costs of \n",
      "continuing down the same path with outdated processes. The tangible \n",
      "benefits of data products include: \n",
      "››Opportunity Costs: Because Data Science is an emerging field, \n",
      "opportunity costs arise when a competitor implements and \n",
      "generates value from data before you. Failure to learn and account \n",
      "for changing customer demands will inevitably drive customers \n",
      "away from your current offerings. When competitors are able \n",
      "to successfully leverage Data Science to gain insights, they can \n",
      "drive differentiated customer value propositions and lead their \n",
      "industries as a result.\n",
      "››Enhanced Processes: As a result of the increasingly interconnected \n",
      "world, huge amounts of data are being generated and stored \n",
      "every instant. Data Science can be used to transform data into \n",
      "insights that help improve existing processes. Operating costs \n",
      "can be driven down dramatically by effectively incorporating the \n",
      "complex interrelationships in data like never before. This results  \n",
      "in better quality assurance, higher product yield and more \n",
      "effective operations.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"This appears to be the title page of a book titled \"Data Science to the Field Guide\" with the second edition, published in 2015 by Booz Allen Hamilton Inc.\n",
      "\n",
      "Here is a concise summary:\n",
      "\n",
      "Data Science is transforming every aspect of our lives, from healthcare to transportation to social media. With the vast amounts of digital data being generated, Data Science is unlocking secrets and making discoveries that will change how we live and interact with the world. As Data Science becomes a driving force behind technological advancements, businesses and organizations must adapt to stay ahead. The growing importance of Data Science requires a new class of practitioners and leaders to navigate its power and responsibility.\n",
      "\n",
      "The quote suggests that every person you encounter has knowledge or experiences that you are not aware of, emphasizing the importance of humility and openness to learning from others.\n",
      "\n",
      "Here is a concise summary:\n",
      "\n",
      "The Field Guide to Data Science is a comprehensive guide created by Booz Allen Hamilton, a leading data science team, to help organizations understand and apply data science concepts. The guide is based on the team's experience working with diverse clients across various domains, and it provides a broad perspective on the what, why, who, and how of data science. The second edition includes new concepts, technical depth, and richness to help practitioners and senior leaders deepen their understanding of data science.\n",
      "\n",
      "The Field Guide to Data Science is a living document that aims to capture the complexities of the field, acknowledging that it is a team sport that evolves rapidly. The guide is open to contributions from the community, inviting experts to share their knowledge, case studies, and perspectives. The authors encourage readers to add their expertise, submit ideas, and join the conversation to advance the science and art of Data Science.\n",
      "\n",
      "The authors express gratitude to the Data Science community for making their \"Field Guide to Data Science\" a success. They thank:\n",
      "\n",
      "* 15,000+ digital copy downloads and 100+ GitHub connections\n",
      "* Practitioners using the guide as a resource\n",
      "* Educators incorporating it into course work\n",
      "* Organizational leaders sharing feedback and success stories\n",
      "\n",
      "They acknowledge the guide's influence on shaping technical approaches, defining Data Science roles, and introducing students to the field. They invite continued feedback and participation in the community.\n",
      "\n",
      "The outline provides a comprehensive guide to data science, covering its core concepts, principles, and applications. The story is divided into four main sections:\n",
      "\n",
      "1. Introduction to data science, including its definition, how it works, and what it takes to create a data science capability.\n",
      "2. A practitioner's guide to data science, covering guiding principles, component parts, and a fractal analytic model.\n",
      "3. Navigating the trenches of data science, including machine learning, feature engineering, data veracity, and model validation.\n",
      "4. Case studies showcasing the application of data science in various fields, such as medicine, transportation, and customer response.\n",
      "\n",
      "The guide concludes with a look at the future of data science and parting thoughts.\n",
      "\n",
      "The \"Field Guide to Data Science\" introduces five guides who share their perspectives on the field. They emphasize the importance of:\n",
      "\n",
      "* Rapid evolution and innovation in data science\n",
      "* Asking big questions and exploring future possibilities\n",
      "* Blending art and science to advance data analytics\n",
      "* Investing time and energy in difficult-to-assemble data\n",
      "* The power of data science in understanding and describing the \"why\"\n",
      "\n",
      "These guides provide a glimpse into the exciting and dynamic world of data science, highlighting its potential for discovery, creativity, and impact.\n",
      "\n",
      "The summary is a collection of quotes from various data science professionals, offering advice and insights on how to approach data science. The quotes emphasize the importance of:\n",
      "\n",
      "* Curiosity and skepticism in data challenges\n",
      "* Seeking truth over facts\n",
      "* Focusing on value rather than volume\n",
      "* Developing grit and perseverance\n",
      "* Playing with tools, data, and algorithms to discover new solutions\n",
      "\n",
      "These quotes provide guidance for data scientists on how to approach their work and achieve success.\n",
      "\n",
      "The summary is a collection of quotes from various individuals in the data science field, highlighting their perspectives on the profession. The quotes emphasize the importance of:\n",
      "\n",
      "* Balancing the big picture (the forest) with the details (the trees)\n",
      "* Persistence and dedication in achieving incremental improvement\n",
      "* Satisfying curiosities about important problems through data exploration\n",
      "* The shift towards a more open, collaborative, and fast-paced corporate culture\n",
      "* The dual nature of data science as both an art and a science\n",
      "\n",
      "The quotes are followed by a thank-you note to contributors and editors who helped shape the \"Field Guide to Data Science\".\n",
      "\n",
      "The article introduces four community contributors from Kaggle, each sharing a brief quote or phrase that reflects their approach to data science. The quotes emphasize the importance of seeking truth, rigor, and insight, as well as the need to be data-driven and formal in analysis.\n",
      "\n",
      "Here is a concise summary:\n",
      "\n",
      "Data Science is the process of transforming data into actionable insights through tradecraft, creating data products that provide information without exposing underlying data or analytics. It involves shifting between deductive and inductive reasoning, constantly testing and improving models. Data Science is necessary for companies to stay competitive, and capabilities can be built over time through a series of stages. Effective Data Science teams require a broad view of the organization and strong leadership to drive success.\n",
      "\n",
      "The introduction emphasizes the importance of understanding Data Science, warning against simply renaming a Business Intelligence group as a solution. It encourages readers to start with the basics of Data Science.\n",
      "\n",
      "Data Science is a complex and multifaceted field that is difficult to describe, much like a sunset.\n",
      "\n",
      "Here is a concise summary:\n",
      "\n",
      "Data Science is the process of turning data into actionable information, creating data products that provide insights without exposing underlying data or analytics. It involves extracting timely and relevant information from diverse sources to drive decision-making. Data products can include movie recommendations, weather forecasts, and targeted advertising. The field of Data Science emerged in the late 1990s and was declared the \"sexiest job of the 21st century\" in 2010.\n",
      "\n",
      "Data Science differs from traditional analytics by combining both deductive (hypothesis-based) and inductive (pattern-based) reasoning. This allows for the discovery of new insights and the refinement of hypotheses through exploratory data analysis. Deductive reasoning involves testing hypotheses and models, while inductive reasoning involves discovering new relationships and insights from data. By combining both types of reasoning, Data Science creates an environment where models are constantly tested, updated, and improved, leading to better understanding of reality.\n",
      "\n",
      "Here is a concise summary:\n",
      "\n",
      "Data Science and Business Intelligence are two distinct capabilities that complement each other. While Business Intelligence focuses on analyzing historical data to answer pre-defined questions, Data Science involves discovering questions to ask and obtaining actionable information from data. Key differences include: Data Science involves a team effort, prospective analysis, and creating data products, whereas Business Intelligence is often done by one person, retrospective, and creates reports.\n",
      "\n",
      "Here is a concise summary:\n",
      "\n",
      "Data Science is a competitive advantage for organizations that want to make informed decisions. As the amount of available data grows, simple statistics are no longer enough to keep pace with market demands. Data Science is required to maintain competitiveness in the increasingly data-rich environment. Organizations that embrace Data Science will be rewarded, while those that don't will struggle to keep up.\n",
      "\n",
      "Here is a concise summary:\n",
      "\n",
      "According to Booz Allen Hamilton, data science can have significant business impacts, including:\n",
      "\n",
      "* 17-49% increase in productivity with 10% increase in data usability\n",
      "* 11-42% increase in ROA with 10% increase in data access\n",
      "* 241% increase in ROI from using big data to improve competitiveness\n",
      "* 1000% increase in ROI from deploying analytics across the organization\n",
      "* 5-6% performance improvement from making data-driven decisions\n",
      "\n",
      "Overall, data science is essential for organizations to compete in the future.\n",
      "\n",
      "The article discusses the shift in IT systems from separating business decision-makers from infrastructure managers to directly connecting them to data. This transformation allows organizations to value data rather than just manage it. The article highlights the importance of consolidating data and distilling answers, rather than building silos, to maximize the use of available data and gain a competitive edge. The benefits of data products include reduced opportunity costs, enhanced processes, and improved quality assurance, product yield, and operations.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here is a concise summary of the text:\\n\\nThe \"Field Guide to Data Science\" is a comprehensive guide published by Booz Allen Hamilton in 2015. The guide aims to help organizations understand and apply data science concepts, covering its core concepts, principles, and applications. The guide is divided into four main sections, including an introduction to data science, a practitioner\\'s guide, navigating the trenches of data science, and case studies. The guide emphasizes the importance of humility, openness to learning, and collaboration in data science. It also highlights the need for data science to be a team sport that evolves rapidly, and encourages contributions from the community. The guide concludes with a look at the future of data science and parting thoughts.'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(splitdocs[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gave good summarization for the huge data science book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching Relevant Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the good characteristics for a data science teams\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "relavantsearch = vembeddings.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='AN INTRODUCTION TO DATA SCIENCE\\nIf you haven’t heard of Data Science, you’re behind the \\ntimes. Just renaming your Business Intelligence group \\nthe Data Science group is not the solution. START HERE    for   THE BASICS', metadata={'page': 19.0, 'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf'}),\n",
       " Document(page_content='DATA SCIENCEtoTHE\\nFIEL D GUIDE\\n    \\n \\nSECOND  \\nEDITION\\n© COPYRIGHT 2015 BOOZ ALLEN HAMILTON INC. ALL RIGHTS RESERVED.', metadata={'page': 1.0, 'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf'}),\n",
       " Document(page_content='DATA SCIENCEtoTHE\\nFIEL D GUIDE\\n    \\n \\nSECOND  \\nEDITION\\n© COPYRIGHT 2015 BOOZ ALLEN HAMILTON INC. ALL RIGHTS RESERVED.', metadata={'page': 1.0, 'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf'}),\n",
       " Document(page_content='What do We Mean by  \\nData Science?\\nDescribing Data Science is like trying to describe a sunset – it \\nshould be easy, but somehow capturing the words is impossible.\\nTHE FIELD  GUIDE to  DATA  SCIENCE', metadata={'page': 20.0, 'source': 'C:\\\\Users\\\\USER\\\\Downloads\\\\field-guide-to-data-science.pdf'})]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relavantsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I haven't performed the vector embeddings for the full document, it is not that much effective. Once I loaded the document fully it will have the capabilities to provide the similar kind of results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "queschain = load_qa_chain(groqllm,chain_type=\"map_reduce\",verbose=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "DATA SCIENCEtoTHE\n",
      "FIEL D GUIDE\n",
      "    \n",
      " \n",
      "SECOND  \n",
      "EDITION\n",
      "© COPYRIGHT 2015 BOOZ ALLEN HAMILTON INC. ALL RIGHTS RESERVED.\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "FOREWORD\n",
      "Data Science touches every aspect of our lives on a \n",
      "daily basis. When we visit the doctor, drive our cars, \n",
      "get on an airplane, or shop for services, Data Science \n",
      "is changing the way we interact with and explore  \n",
      "our world.  \n",
      "Our world is now measured, \n",
      "mapped, and recorded in digital \n",
      "bits. Entire lives, from birth to \n",
      "death, are now catalogued in \n",
      "the digital realm. These data, \n",
      "originating from such diverse \n",
      "sources as connected vehicles, \n",
      "underwater microscopic cameras, \n",
      "and photos we post to social \n",
      "media, have propelled us into \n",
      "the greatest age of discovery \n",
      "humanity has ever known. It is \n",
      "through Data Science that we \n",
      "are unlocking the secrets hidden \n",
      "within these data. We are making \n",
      "discoveries that will forever \n",
      "change how we live and interact \n",
      "with the world around us. \n",
      "The impact of these changes \n",
      "is having a profound effect on \n",
      "humanity. We have propelled \n",
      "ourselves into this age of \n",
      "discovery through our incremental \n",
      "technological improvements. \n",
      "Data Science has become the \n",
      "catalyzing force behind our next \n",
      "evolutionary leap. Our own \n",
      "evolution is now inextricably \n",
      "linked to that of computers. The \n",
      "way we live our lives and the skills \n",
      "that are important to our very \n",
      "existence are directly dependent \n",
      "upon the functions Data Science \n",
      "can achieve on our behalf.   As we move into this new \n",
      "future, it is clearer than ever, that \n",
      "businesses must adjust to these \n",
      "changes or risk being left behind. \n",
      "From influencing retail markets, \n",
      "to setting public health and safety \n",
      "policies, or to addressing social \n",
      "unrest, organizations of all types \n",
      "are generating value through  \n",
      "Data Science. Data is our new \n",
      "currency and Data Science is  \n",
      "the mechanism by which we tap \n",
      "into it. \n",
      "Data Science is an auspicious and \n",
      "profound way of applying our \n",
      "curiosity and technical tradecraft \n",
      "to solve humanity’s toughest \n",
      "challenges. The growing power, \n",
      "importance, and responsibility \n",
      "of applying Data Science \n",
      "methodologies to these challenges \n",
      "is unimaginable. Our own \n",
      "biases and assumptions can have \n",
      "profound outcomes on business, \n",
      "national security, and our daily \n",
      "lives. A new class of practitioners \n",
      "and leaders are needed to navigate \n",
      "this new future. Data Scientists \n",
      "are our guides on this journey as \n",
      "they are creating radical new ways \n",
      "of thinking about data and the \n",
      "world around us.  \n",
      " \n",
      "We want to share our passion for  Data Science  and start a \n",
      "conversation with you. This is a journey worth taking.  ››\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Everyone you  \n",
      "will ever meet  \n",
      "knows something  \n",
      "you don’t.  [1]\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "THE STORY    \n",
      "    of    THE FIELD  \n",
      "GUIDE\n",
      "Several years ago we created The Field Guide to Data Science because \n",
      "we wanted to help organizations of all types and sizes.  There were \n",
      "countless industry and academic publications describing what  Data \n",
      "Science is and  why  we should care, but very little information was \n",
      "available to explain how to make use of data as a resource. We find \n",
      "that situation to be just as true today as we did two years ago, when \n",
      "we created the first edition of the field guide. \n",
      "At Booz Allen Hamilton, we built an industry-leading team of \n",
      "Data Scientists. Over the course of hundreds of analytic challenges \n",
      "for countless clients, we’ve unraveled the DNA of Data Science. \n",
      "Many people have put forth their thoughts on single aspects of \n",
      "Data Science. We believe we can offer a broad perspective on the \n",
      "conceptual models, tradecraft, processes and culture of Data Science \n",
      "– the what , the why, the who and the how.  Companies with strong \n",
      "Data Science teams often focus on a single class of problems – graph \n",
      "algorithms for social network analysis, and recommender models for \n",
      "online shopping are two notable examples. Booz Allen is different. \n",
      "In our role as consultants, we support a diverse set of government \n",
      "and commercial clients across a variety of domains. This allows us to \n",
      "uniquely understand the DNA of Data Science. \n",
      "Our goal in creating The Field Guide to Data Science was to  \n",
      "capture what we have learned and to share it broadly. The field  \n",
      "of Data Science has continued to advance since we first released  \n",
      "the field guide. As a result, we decided to release this second edition, \n",
      "incorporating a few new and important concepts. We also added \n",
      "technical depth and richness that we believe practitioners will  \n",
      "find useful. \n",
      "We want this effort to continue driving forward the science and \n",
      "art of Data Science.\n",
      "This field guide came from the passion our team feels for its \n",
      "work. It is not a textbook nor is it a superficial treatment. \n",
      "Senior leaders will walk away with a deeper understanding of \n",
      "the concepts at the heart of Data Science. Practitioners will \n",
      "add to their toolbox. We hope everyone will enjoy the journey.››\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "WE ARE ALL  \n",
      "AUTHORS   of    THIS   \n",
      "STORY\n",
      "We recognize that Data Science is a team sport. The Field Guide \n",
      "to Data Science  provides Booz Allen Hamilton’s perspective on the \n",
      "complex and sometimes mysterious field of Data Science. We cannot \n",
      "capture all that is Data Science. Nor can we keep up - the pace at \n",
      "which this field progresses outdates work as fast as it is produced.  \n",
      "As a result, we opened this field guide to the world as a living \n",
      "document to bend and grow with technology, expertise, and  \n",
      "evolving techniques. \n",
      "Thank you to all the people that have emailed us your ideas as \n",
      "well as the 100+ people who have watched, starred, or forked our \n",
      "GitHub repository. We truly value the input of the community, as \n",
      "we work together to advance the science and art of Data Science. \n",
      "This is why we have included authors from outside Booz Allen \n",
      "Hamilton on this second edition of The Field Guide to Data Science . \n",
      "If you find the guide to be useful, neat, or even lacking, then \n",
      "we encourage you to add your expertise, including:\n",
      "››Case studies from which you have learned \n",
      "››Citations from journal articles or papers that inspire you \n",
      "››Algorithms and techniques that you love \n",
      "››Your thoughts and comments on other people’s additions \n",
      " \n",
      "Email us your ideas and perspectives at data_science@bah.com  \n",
      "or submit them via a pull request on the GitHub repository .   \n",
      "Join our conversation and take the journey with us. Tell us and \n",
      "the world what you know. Become an author of this story.››\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "ACKNOWLEDGEMENTS\n",
      "We  w o u l d  l i k e  to  e x p r e s s  o u r  s i n c e r e s t  g ra t i t u d e  to  \n",
      "all those who have made The Field Guide to Data \n",
      "Science  such a success. \n",
      "Thank you to the nearly 15,000 \n",
      "people who have downloaded \n",
      "the digital copy from our website \n",
      "and the 100+ people who have \n",
      "connected with The Field Guide \n",
      "on our GitHub page . We have \n",
      "been overwhelmed by the \n",
      "popularity of the work within the \n",
      "Data Science community. \n",
      "Thank you to all of the \n",
      "practitioners who are using The \n",
      "Field Guide as a resource. We are \n",
      "excited to know that the work has \n",
      "had such a strong influence, from \n",
      "shaping technical approaches to \n",
      "serving as the foundation for the \n",
      "very definition and role of Data \n",
      "Science within major government \n",
      "and commercial organizations. Thank you to the educators and \n",
      "academics who have incorporated \n",
      "The Field Guide into your course \n",
      "work. We appreciate your trusting \n",
      "this guide as a way to introduce \n",
      "your students to Data Science.   \n",
      "It is an honor to know that we are \n",
      "shaping the next generation of \n",
      "Data Scientists.\n",
      "Thank you to the organizational \n",
      "leaders who have shared your \n",
      "feedback, encouragement, and \n",
      "success stories. We are thrilled  \n",
      "to know that The Field Guide  \n",
      "has helped so many organizations, \n",
      "from energy, to life sciences,  \n",
      "to retail, to begin their Data \n",
      "Science journeys.  \n",
      "We hope you will all continue to find value from The Field \n",
      "Guide to Data Science and to share in our excitement around the \n",
      "release of this second edition. Please continue to be part of the \n",
      "conversation and take this journey with us. ››\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "THE OUTLINE    \n",
      "                                of   OUR STORY\n",
      "12    ›› Meet Your Guides\n",
      "17    ›› The Short Version – The Core Concepts of Data Science\n",
      "18    ›› Start Here for the Basics –  An Introduction to Data Science\n",
      "What Do We Mean by Data Science?\n",
      "How Does Data Science Actually Work?\n",
      "What Does It Take to Create a Data Science Capability?\n",
      "46    ›› Take off the Training W heels –  The Practitioner’s Guide to Data Science\n",
      "Guiding Principles\n",
      "The Importance of Reason\n",
      "Component Parts of Data Science\n",
      "Fractal Analytic Model\n",
      "The Analytic Selection Process\n",
      "Guide to Analytic Selection  \n",
      "Detailed Table of Analytics\n",
      "84    ›› Life in the Trenches – Navigating Neck Deep in Data\n",
      "Going Deep into Machine Learning\n",
      "Feature Engineering\n",
      "Feature Selection\n",
      "Ensemble Models\n",
      "Data Veracity\n",
      "Application of Domain Knowledge\n",
      "The Curse of Dimensionality \n",
      "Model Validation\n",
      "102    ›› Putting it all T ogether –  Our Case Studies\n",
      "Streamlining Medication Review\n",
      "Reducing Flight Delays\n",
      "Making Vaccines Safer\n",
      "Forecasting the Relative Risk for the Onset of\n",
      " Mass Killings to Help Pr event Future Atrocities \n",
      "Predicting Customer Response\n",
      "114   ›› Closing Time  \n",
      "The Future of Data Science\n",
      "Parting Thoughts\n",
      "References\n",
      "About Booz Allen Hamilton››\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "MEET  your GUIDES\n",
      "Fred Blackburn\n",
      "(@boozallen)\n",
      "Data Science is a field that is  \n",
      "evolving at a very rapid pace…be  \n",
      "part of the journey.  \n",
      "Angela Zutavern\n",
      "(@angelazutavern)\n",
      "Data Science is about asking bigger \n",
      "questions, seeing future possibilities, \n",
      "and creating outcomes you desire.  Josh Sullivan \n",
      "(@joshdsullivan)\n",
      "Leading our Data Science team \n",
      "shows me every day the incredible \n",
      "power of discovery and human \n",
      "curiosity. Don’t be afraid to blend \n",
      "art and science to advance your \n",
      "own view of data analytics – it \n",
      "can be a powerful mixture.\n",
      "Steve Escaravage\n",
      "(@sescarav)\n",
      "Invest your time and energy \n",
      "in data that is difficult to \n",
      "assemble.  If it doesn’t exist, \n",
      "find a way to make it exist.Peter Guerra \n",
      "(@petrguerra)\n",
      "Data Science is the most fascinating \n",
      "blend of art and math and code \n",
      "and sweat and tears. It can take \n",
      "you to the highest heights and the \n",
      "lowest depths in an instant, but it \n",
      "is the only way we will be able to \n",
      "understand and describe the why.\n",
      "Ezmeralda Khalil\n",
      "(@ezmeraldakhalil)\n",
      "The power of data science \n",
      "lies in the execution.››\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Steven Mills \n",
      "(@stevndmills)\n",
      "Data Science truly can \n",
      "change the world.\n",
      "Stephanie Beben\n",
      "(@boozallen)\n",
      "Begin every new data challenge \n",
      "with deep curiosity along with \n",
      "a healthy dose of skepticism.Alex Cosmas \n",
      "(@boozallen)\n",
      "Data scientists should be truth-\n",
      "seekers, not fact-seekers.\n",
      "Kirk Borne\n",
      "(@KirkDBorne)\n",
      "Focus on value, not volume.Brian Keller \n",
      "(@boozallen)\n",
      "Grit will get you farther than talent.\n",
      "Drew Farris \n",
      "(@drewfarris)\n",
      "Don’t forget to play. Play with \n",
      "tools, play with data, and play with \n",
      "algorithms. You just might discover \n",
      "something that will help you solve \n",
      "that next nagging problem. \n",
      "13 Meet Your Guides\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Paul Yacci\n",
      "(@paulyacci)\n",
      "In the jungle of data, don't \n",
      "miss the forest for the trees, \n",
      "or the trees for the forest.\n",
      " \n",
      "Stephanie Rivera \n",
      "(@boozallen)\n",
      "I treat Data Science like I do rock \n",
      "climbing: awesome dedication \n",
      "leads to incremental improvement. \n",
      "Persistence leads to the top.Charles Glover\n",
      "(@MindAfterMath)\n",
      "The beauty of data science lies \n",
      "in satisfying curiosities about \n",
      "important problems by playing \n",
      "with data and algorithms.\n",
      "Aaron Sander \n",
      "(@ajsander) \n",
      "Data science is changing corporate \n",
      "culture to be more like the open \n",
      "source environment. More open, \n",
      "more collaborative, and faster paced.Michael Kim \n",
      "(@boozallen)\n",
      "Data science is both an art  \n",
      "and science. \n",
      "We would like to thank the following people for their \n",
      "contributions and edits: \n",
      "Tim Andrews, Mike Delurey, Greg Dupier, Jason Escaravage, \n",
      "Christine Fantaskey, Juergen Klenk, Dan Liebermann, Mark \n",
      "Rockley and Katie Wilks.\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "COMMUNITY  CONTRIBUTORS\n",
      "Will Cukierski, kaggle\n",
      "(@kaggle)\n",
      " \n",
      "I took the one in the direction  \n",
      "of the negative gradient,   \n",
      "And that has made all the difference.\n",
      "Armen Kherlopian \n",
      "(@akherlopian)\n",
      "A Data Scientist must \n",
      "continuously seek truth in spite \n",
      "of ambiguity; therein rests the \n",
      "basis of rigor and insight.Mark Herman\n",
      "(@cloudEBITDA)\n",
      "End every analysis with…  \n",
      "‘and therefore.’Ed Kohlwey \n",
      "(@ekohlwey)\n",
      "Data Science is about formally \n",
      "analyzing everything around you \n",
      "and becoming data driven.››\n",
      "Two roads diverged in a wood, and I—\n",
      "15 Meet Your Guides\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "TheSHORT                  \n",
      "  VERSION\n",
      "››Data Science is the art of turning data into actions.  \n",
      "It’s all about the tradecraft. Tradecraft is the process, tools and \n",
      "technologies for humans and computers to work together to \n",
      "transform data into insights.\n",
      "››Data Science tradecraft creates data products .  \n",
      "Data products provide actionable information without exposing \n",
      "decision makers to the underlying data or analytics (e.g., buy/sell \n",
      "strategies for financial instruments, a set of actions to improve \n",
      "product yield, or steps to improve product marketing).\n",
      "››Data Science supports and encourages shifting between \n",
      "deductive (hypothesis-based) and inductive (pattern-\n",
      "based) reasoning.  \n",
      "This is a fundamental change from traditional analysis approaches. \n",
      "Inductive reasoning and exploratory data analysis provide a means \n",
      "to form or refine hypotheses and discover new analytic paths. \n",
      "Models of reality no longer need to be static. They are constantly \n",
      "tested, updated and improved until better models are found. \n",
      "››Data Science is necessary for companies to stay with the \n",
      "pack and compete in the future.   \n",
      "Organizations are constantly making decisions based on gut \n",
      "instinct, loudest voice and best argument – sometimes they are \n",
      "even informed by real information. The winners and the losers in \n",
      "the emerging data economy are going to be determined by their \n",
      "Data Science teams. \n",
      "››Data Science capabilities can be built over time.  \n",
      "Organizations mature through a series of stages – Collect, \n",
      "Describe, Discover, Predict, Advise – as they move from data \n",
      "deluge to full Data Science maturity. At each stage, they can \n",
      "tackle increasingly complex analytic goals with a wider breadth \n",
      "of analytic capabilities. However, organizations need not reach \n",
      "maximum Data Science maturity to achieve success. Significant \n",
      "gains can be found in every stage.\n",
      "››Data Science is a different kind of team sport.   \n",
      "Data Science teams need a broad view of the organization. Leaders \n",
      "must be key advocates who meet with stakeholders to ferret out \n",
      "the hardest challenges, locate the data, connect disparate parts of \n",
      "the business, and gain widespread buy-in.››\n",
      "17 The Short Version 17\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "AN INTRODUCTION TO DATA SCIENCE\n",
      "If you haven’t heard of Data Science, you’re behind the \n",
      "times. Just renaming your Business Intelligence group \n",
      "the Data Science group is not the solution. START HERE    for   THE BASICS\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "What do We Mean by  \n",
      "Data Science?\n",
      "Describing Data Science is like trying to describe a sunset – it \n",
      "should be easy, but somehow capturing the words is impossible.\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "21 Start Here for the Basics 21 Start Here for the BasicsData Science Defined\n",
      "Data Science is the art of turning data into actions. This is \n",
      "accomplished through the creation of data products, which provide \n",
      "actionable information without exposing decision makers to the \n",
      "underlying data or analytics (e.g., buy/sell strategies for financial \n",
      "instruments, a set of actions to improve product yield, or steps to \n",
      "improve product marketing).\n",
      "Performing Data Science requires the extraction of timely, actionable \n",
      "information from diverse data sources to drive data products. \n",
      "Examples of data products include answers to questions such as: \n",
      "“Which of my products should I advertise more heavily to increase \n",
      "profit? How can I improve my compliance program, while reducing \n",
      "costs? What manufacturing process change will allow me to build a \n",
      "better product?” The key to answering these questions is: understand \n",
      "the data you have and what the data inductively tells you. » Data Product\n",
      "A data product provides actionable \n",
      "information without exposing \n",
      "decision makers to the underlying \n",
      "data or analytics. Examples include:\n",
      "• Movie Reco mmendations      \n",
      "• Weather F orecasts\n",
      "• Stock Market Predictions\n",
      "• Production Process \n",
      "Improvements\n",
      "• Health Diagnosis\n",
      "• Flu T rend Predictions\n",
      "• Targeted AdvertisingRead this for additional background:\n",
      "The term Data Science appeared \n",
      "in the computer science literature \n",
      "throughout the 1960s-1980s. \n",
      "It was not until the late 1990s \n",
      "however, that the field as we \n",
      "describe it here, began to  \n",
      "emerge from the statistics and \n",
      "data mining communities  \n",
      "(e.g., [2] and [3]). Data Science \n",
      "was first introduced as an \n",
      "independent discipline in 2001.[4] \n",
      "Since that time, there have been \n",
      "countless articles advancing the \n",
      "discipline, culminating with \n",
      "Data Scientist being declared the \n",
      "sexiest job of the 21st century.[5] \n",
      "We established our first Data \n",
      "Science team at Booz Allen \n",
      "in 2010. It began as a natural \n",
      "extension of our Business \n",
      "Intelligence and cloud infrastructure development  \n",
      "work. We saw the need for a  \n",
      "new approach to distill value \n",
      "from our clients’ data. We \n",
      "approached the problem \n",
      "with a multidisciplinary \n",
      "team of computer scientists, \n",
      "mathematicians and domain \n",
      "experts. They immediately \n",
      "produced new insights and \n",
      "analysis paths, solidifying the \n",
      "validity of the approach. Since \n",
      "that time, our Data Science  \n",
      "team has grown to 250 staff \n",
      "supporting dozens of clients \n",
      "across a variety of domains.  \n",
      "This breadth of experience \n",
      "provides a unique perspective  \n",
      "on the conceptual models, \n",
      "tradecraft, processes and  \n",
      "culture of Data Science.\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Source: Booz Allen Hamilton What makes Data Science Different?\n",
      "Data Science supports and encourages shifting between deductive \n",
      "(hypothesis-based) and inductive (pattern-based) reasoning.  This is \n",
      "a fundamental change from traditional analytic approaches. Inductive \n",
      "reasoning and exploratory data analysis provide a means to form or \n",
      "refine hypotheses and discover new analytic paths. In fact, to do the \n",
      "discovery of significant insights that are the hallmark of Data Science, \n",
      "you must have the tradecraft and the interplay between inductive \n",
      "and deductive reasoning. By actively combining the ability to reason \n",
      "deductively and inductively, Data Science creates an environment \n",
      "where models of reality no longer need to be static and empirically \n",
      "based. Instead, they are constantly tested, updated and improved until \n",
      "better models are found. These concepts are summarized in the figure, \n",
      "The Types of Reason and Their Role in Data Science Tradecraft .\n",
      "THE TYPES OF REASON…\n",
      "DEDUCTIVE REASONING:\n",
      " › Commonly associated \n",
      "with “formal logic.”\n",
      " › Involves reasoning from known \n",
      "premises, or premises presumed \n",
      "to be true, to a certain conclusion.\n",
      " › The conclusions reached are \n",
      "certain, inevitable, inescapable.INDUCTIVE REASONING\n",
      " › Commonly known as “informal \n",
      "logic,”  or “everyday argument.”\n",
      " › Involves drawing uncertain \n",
      "inferences, based on \n",
      "probabilistic reasoning.\n",
      " › The conclusions reached \n",
      "are probable, reasonable, \n",
      "plausible, believable.\n",
      "…AND THEIR ROLE IN DATA SCIENCE TRADECRAFT.\n",
      "DEDUCTIVE REASONING:\n",
      " › Formulate hypotheses about \n",
      "relationships and underlying models.\n",
      " › Carry out experiments with the data \n",
      "to test hypotheses and models.INDUCTIVE REASONING\n",
      " › Exploratory data analysis to \n",
      "discover or reﬁne hypotheses.\n",
      " › Discover new relationships, insights \n",
      "and analytic paths from the data.\n",
      "The Types of Reason and Their Role in Data Science Tradecraft\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Source: Booz Allen Hamilton \n",
      "23 Start Here for the Basics 23 Start Here for the Basics\n",
      "The differences between Data Science and traditional analytic \n",
      "approaches do not end at seamless shifting between deductive \n",
      "and inductive reasoning. Data Science offers a distinctly different \n",
      "perspective than capabilities such as Business Intelligence. Data \n",
      "Science should not replace Business Intelligence functions within \n",
      "an organization, however. The two capabilities are additive and \n",
      "complementary, each offering a necessary view of business operations \n",
      "and the operating environment. The figure, Business Intelligence and \n",
      "Data Science – A Comparison,  highlights the differences between the \n",
      "two capabilities. Key contrasts include:\n",
      "››Discovery vs. Pre-canned Questions: Data Science actually \n",
      "works on discovering the question to ask as opposed to just \n",
      "asking it.\n",
      "››Power of Many vs. Ability of One: An entire team provides \n",
      "a common forum for pulling together computer science, \n",
      "mathematics and domain expertise. \n",
      "››Prospective vs. Retrospective:  Data Science is focused on \n",
      "obtaining actionable information from data as opposed to \n",
      "reporting historical facts.\n",
      "LOOKING BACKWARD AND FORWARD\n",
      "FIRST THERE WAS  \n",
      "BUSINESS INTELLIGENCE\n",
      "Deductive Reasoning\n",
      "Backward Looking\n",
      "Slice and Dice Data\n",
      "Warehoused and Siloed Data\n",
      "Analyze the Past, Guess the Future\n",
      "Creates Reports\n",
      "Analytic OutputNOW WE'VE ADDED  \n",
      "DATA SCIENCE\n",
      "Inductive and Deductive Reasoning\n",
      "Forward Looking\n",
      "Interact with Data\n",
      "Distributed, Real Time Data\n",
      "Predict and Advise\n",
      "Creates Data  Products\n",
      "Answer Questions and Create New Ones\n",
      "Actionable Answer\n",
      "Business Intelligence and Data Science - A Comparison  (adapted in part from [6])\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "What is the Impact of Data Science?\n",
      "As we move into the data economy, Data Science is the competitive \n",
      "advantage for organizations interested in winning – in whatever way \n",
      "winning is defined. The manner in which the advantage is defined \n",
      "is through improved decision-making. A former colleague liked to \n",
      "describe data-informed decision making like this: If you have perfect \n",
      "information or zero information then your task is easy – it is in between \n",
      "those two extremes that the trouble begins.  What he was highlighting is \n",
      "the stark reality that whether or not information is available, decisions \n",
      "must be made.\n",
      "The way organizations make decisions has been evolving for half a \n",
      "century. Before the introduction of Business Intelligence, the only \n",
      "options were gut instinct, loudest voice, and best argument. Sadly, this \n",
      "method still exists today, and in some pockets it is the predominant \n",
      "means by which the organization acts. Take our advice and never, ever \n",
      "work for such a company! \n",
      "Fortunately for our economy, most organizations began to inform \n",
      "their decisions with real information through the application of \n",
      "simple statistics. Those that did it well were rewarded; those that did \n",
      "not failed. We are outgrowing the ability of simple stats to keep pace \n",
      "with market demands, however. The rapid expansion of available data \n",
      "and the tools to access and make use of the data at scale are enabling \n",
      "fundamental changes to the way organizations make decisions. \n",
      "Data Science is required to maintain competitiveness in the \n",
      "increasingly data-rich environment. Much like the application of \n",
      "simple statistics, organizations that embrace Data Science will be \n",
      "rewarded while those that do not will be challenged to keep pace. As \n",
      "more complex, disparate datasets become available, the chasm between \n",
      "these groups will only continue to widen. The figure, The Business \n",
      "Impacts of Data Science, highlights the value awaiting organizations \n",
      "that embrace Data Science.\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Source: Booz Allen Hamilton \n",
      "25 Start Here for the Basics 25 Start Here for the Basics\n",
      "DATA SCIENCE IS NECESSARY...\n",
      "17-49%  increase in productivity when organizations increase data \n",
      "usability by 10%\n",
      "11-42%   return on assets (ROA) when organizations increase data \n",
      "access by 10% \n",
      "241%   increase in ROI when or ganizations use big data to  \n",
      "improve competitiveness\n",
      "1000%  increase in ROI when deploying analytics across most of \n",
      "the organization, aligning daily operations with senior \n",
      "management's goals, and incorporating big data\n",
      "5-6%   performanc e improvement for organizations making  \n",
      "data-driven decisions. \n",
      "...TO COMPETE IN THE FUTURE\n",
      "The Business Impacts of Data Science  (adapted from [7], [8] and [9])\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "27 Start Here for the Basics 27 Start Here for the BasicsWhat is Different Now?\n",
      "For 20 years IT systems were built the same way. We separated \n",
      "the people who ran the business from the people who managed the \n",
      "infrastructure (and therefore saw data as simply another thing they \n",
      "had to manage). With the advent of new technologies and analytic \n",
      "techniques, this artificial – and highly ineffective – separation of \n",
      "critical skills is no longer necessary. For the first time, organizations \n",
      "can directly connect business decision makers to the data. This simple \n",
      "step transforms data from being ‘something to be managed’ into \n",
      "‘something to be valued.’\n",
      "In the wake of the transformation, organizations face a stark choice: \n",
      "you can continue to build data silos and piece together disparate \n",
      "information or you can consolidate your data and distill answers. \n",
      "From the Data Science perspective, this is a false choice: The siloed \n",
      "approach is untenable when you consider the (a) the opportunity \n",
      "cost of not making maximum use of all available data to help \n",
      "an organization succeed, and (b) the resource and time costs of \n",
      "continuing down the same path with outdated processes. The tangible \n",
      "benefits of data products include: \n",
      "››Opportunity Costs: Because Data Science is an emerging field, \n",
      "opportunity costs arise when a competitor implements and \n",
      "generates value from data before you. Failure to learn and account \n",
      "for changing customer demands will inevitably drive customers \n",
      "away from your current offerings. When competitors are able \n",
      "to successfully leverage Data Science to gain insights, they can \n",
      "drive differentiated customer value propositions and lead their \n",
      "industries as a result.\n",
      "››Enhanced Processes: As a result of the increasingly interconnected \n",
      "world, huge amounts of data are being generated and stored \n",
      "every instant. Data Science can be used to transform data into \n",
      "insights that help improve existing processes. Operating costs \n",
      "can be driven down dramatically by effectively incorporating the \n",
      "complex interrelationships in data like never before. This results  \n",
      "in better quality assurance, higher product yield and more \n",
      "effective operations.\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "How does Data Science  \n",
      "Actually Work?\n",
      "It’s not rocket science… it’s something better - Data Science\n",
      "Let’s not kid ourselves - Data Science is a complex field. It is difficult, \n",
      "intellectually taxing work, which requires the sophisticated integration \n",
      "of talent, tools and techniques. But as a field guide, we need to cut \n",
      "through the complexity and provide a clear, yet effective way to \n",
      "understand this new world. \n",
      "To do this, we will transform the field of Data Science into a set of \n",
      "simplified activities as shown in the figure, The Four Key Activities of a \n",
      "Data Science Endeavor . Data Science purists will likely disagree with \n",
      "this approach, but then again, they probably don’t need a field guide, \n",
      "sitting as they do in their ivory towers! In the real world, we need \n",
      "clear and simple operating models to help drive us forward. \n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Source: Booz Allen Hamilton \n",
      "1 2 3 4\n",
      "Acquire\n",
      "Prepare\n",
      "Analyze\n",
      "ActLowHigh\n",
      "Degree\n",
      "of \n",
      "Effort\n",
      "Data Science ActivitiesTry\n",
      "Evaluate\n",
      "Setup Do\n",
      "Evaluate\n",
      "29 Start Here for the Basics 29 Start Here for the Basics\n",
      "Activity 1: Acquire  \n",
      "This activity focuses \n",
      "on obtaining the \n",
      "data you need. \n",
      "Given the nature of \n",
      "data, the details of \n",
      "this activity depend \n",
      "heavily on who you \n",
      "are and what you \n",
      "do. As a result, we \n",
      "will not spend a \n",
      "lot of time on this \n",
      "activity other than \n",
      "to emphasize its \n",
      "importance and \n",
      "to encourage an \n",
      "expansive view on \n",
      "which data can and \n",
      "should be used. Activity 2: Prepare \n",
      "Great outcomes \n",
      "don’t just happen \n",
      "by themselves. \n",
      "A lot depends on \n",
      "preparation, and \n",
      "in Data Science, \n",
      "that means \n",
      "manipulating the \n",
      "data to ﬁt your \n",
      "analytic needs.  \n",
      "This stage can \n",
      "consume a great \n",
      "deal of time, but \n",
      "it is an excellent \n",
      "investment. The \n",
      "beneﬁts are \n",
      "immediate and \n",
      "long term. Activity 3: Analyze \n",
      "This is the activity \n",
      "that consumes the \n",
      "lion’s share of the \n",
      "team’s attention. \n",
      "It is also the most \n",
      "challenging and \n",
      "exciting (you will \n",
      "see a lot of ‘aha \n",
      "moments’  occur in \n",
      "this space). As the \n",
      "most challenging \n",
      "and vexing of the \n",
      "four activities, \n",
      "this ﬁeld guide \n",
      "focuses on helping \n",
      "you do this better \n",
      "and faster.Activity 4: Act \n",
      "Every effective \n",
      "Data Science team \n",
      "analyzes its data \n",
      "with a purpose \n",
      "– that is, to turn \n",
      "data into actions. \n",
      "Actionable and \n",
      "impactful insights \n",
      "are the holy grail \n",
      "of Data Science. \n",
      "Converting insights \n",
      "into action can be a \n",
      "politically charged \n",
      "activity, however. \n",
      "This activity \n",
      "depends heavily \n",
      "on the culture and \n",
      "character of your \n",
      "organization, so \n",
      "we will leave you \n",
      "to ﬁgure out those \n",
      "details for yourself .\n",
      "The Four Key Activities of a Data Science Endeavor\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Acquire\n",
      "All analysis starts with access to data, and for the Data Scientist \n",
      "this axiom holds true. But there are some significant differences – \n",
      "particularly with respect to the question of who stores, maintains and \n",
      "owns the data in an organization.\n",
      "But before we go there, lets look at what is changing. Traditionally, \n",
      "rigid data silos artificially define the data to be acquired. Stated \n",
      "another way, the silos create a filter that lets in a very small amount of \n",
      "data and ignores the rest. These filtered processes give us an artificial \n",
      "view of the world based on the ‘surviving data,’ rather than one that \n",
      "shows full reality and meaning. Without a broad and expansive \n",
      "dataset, we can never immerse ourselves in the diversity of the \n",
      "data. We instead make decisions based on limited and constrained \n",
      "information. \n",
      "Eliminating the need for silos gives us access to all the data at once – \n",
      "including data from multiple outside sources. It embraces the reality \n",
      "that diversity is good and complexity is okay . This mindset creates a \n",
      "completely different way of thinking about data in an organization by \n",
      "giving it a new and differentiated role. Data represents a significant \n",
      "new profit and mission-enhancement opportunity for organizations. \n",
      "But as mentioned earlier, this first activity is heavily dependent upon \n",
      "the situation and circumstances. We can’t leave you with anything \n",
      "more than general guidance to help ensure maximum value: \n",
      "››Look inside first: What data do you have current access  \n",
      "to that you are not using? This is in large part the data  \n",
      "being left behind by the filtering process, and may be \n",
      "incredibly valuable.\n",
      "››Remove the format constraints: Stop limiting your data \n",
      "acquisition mindset to the realm of structured databases. \n",
      "Instead, think about unstructured and semi-structured data \n",
      "as viable sources.\n",
      "››Figure out what’s missing: Ask yourself what data would \n",
      "make a big difference to your processes if you had access to it. \n",
      "Then go find it!\n",
      "››Embrace diversity: Try to engage and connect to publicly \n",
      "available sources of data that may have relevance to your \n",
      "domain area.  » Not All Data Is Created Equal\n",
      "As you begin to aggregate data, \n",
      "remember that not all data is  \n",
      "created equally. Organizations have  \n",
      "a tendency to collect any data that  \n",
      "is available. Data that is nearby \n",
      "(readily accessible and easily \n",
      "obtained) may be cheap to collect, \n",
      "but there is no guarantee it is the \n",
      "right data to collect.  Focus on the \n",
      "data with the highest ROI for your \n",
      "organization.  Your Data Science \n",
      "team can help identify that data. \n",
      "Also remember that you need to \n",
      "strike a balance between the data \n",
      "that you need and the data that you \n",
      "have. Collecting huge volumes of \n",
      "data is useless and costly if it is not \n",
      "the data that you need. \n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "31 Start Here for the Basics 31 Start Here for the Basics  Prepare\n",
      "Once you have the data, you need to prepare it for analysis. \n",
      "Organizations often make decisions based on inexact data. Data \n",
      "stovepipes mean that organizations may have blind spots. They are \n",
      "not able to see the whole picture and fail to look at their data and \n",
      "challenges holistically. The end result is that valuable information is \n",
      "withheld from decision makers. Research has shown almost 33% of \n",
      "decisions are made without good data or information. [10] \n",
      "When Data Scientists are able to explore and analyze all the data, new \n",
      "opportunities arise for analysis and data-driven decision making. The \n",
      "insights gained from these new opportunities will significantly change \n",
      "the course of action and decisions within an organization. Gaining \n",
      "access to an organization’s complete repository of data, however, \n",
      "requires preparation.\n",
      "Our experience shows time and time again that the best tool for \n",
      "Data Scientists to prepare for analysis is a lake – specifically, the Data \n",
      "Lake.[11] This is a new approach to collecting, storing and integrating \n",
      "data that helps organizations maximize the utility of their data. \n",
      "Instead of storing information in discrete data structures, the Data \n",
      "Lake consolidates an organization’s complete repository of data in \n",
      "a single, large view. It eliminates the expensive and cumbersome \n",
      "data-preparation process, known as Extract/Transform/Load (ETL), \n",
      "necessary with data silos. The entire body of information in the Data \n",
      "Lake is available for every inquiry – and all at once.\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Source: Booz Allen Hamilton \n",
      "  Analyze\n",
      "We have acquired the data… we have prepared it… now it is time to \n",
      "analyze it. \n",
      "The Analyze activity requires the greatest effort of all the activities \n",
      "in a Data Science endeavor. The Data Scientist actually builds the \n",
      "analytics that create value from data. Analytics in this context is \n",
      "an iterative application of specialized and scalable computational \n",
      "resources and tools to provide relevant insights from exponentially \n",
      "growing data. This type of analysis enables real-time understanding \n",
      "of risks and opportunities by evaluating situational, operational and \n",
      "behavioral data.\n",
      "With the totality of data fully accessible in the Data Lake, \n",
      "organizations can use analytics to find the kinds of connections and \n",
      "patterns that point to promising opportunities. This high-speed \n",
      "analytic connection is done within the Data Lake, as opposed to \n",
      "older style sampling methods that could only make use of a narrow \n",
      "slice of the data. In order to understand what was in the lake, you had \n",
      "to bring the data out and study it. Now you can dive into the lake, \n",
      "bringing your analytics to the data. The figure, Analytic Connection in \n",
      "the Data Lake,  highlights the concept of diving into the Data Lake to \n",
      "discover new connections and patterns . \n",
      "Analytic Connection in the Data Lake\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "33 Start Here for the Basics 33 Start Here for the BasicsData Scientists work across the spectrum of analytic goals – Describe, \n",
      "Discover, Predict and Advise. The maturity of an analytic capability \n",
      "determines the analytic goals encompassed. Many variables play key \n",
      "roles in determining the difficulty and suitability of each goal for an \n",
      "organization. Some of these variables are the size and budget of an \n",
      "organization and the type of data products needed by the decision \n",
      "makers. A detailed discussion on analytic maturity can be found in \n",
      "Data Science Maturity within an Organization .\n",
      "In addition to consuming the greatest effort, the Analyze activity \n",
      "is by far the most complex. The tradecraft of Data Science is an \n",
      "art. While we cannot teach you how to be an artist, we can share \n",
      "foundational tools and techniques that can help you be successful. \n",
      "The entirety of Take Off the Training Wheels  is dedicated to sharing \n",
      "insights we have learned over time while serving countless clients. \n",
      "This includes descriptions of a Data Science product lifecycle and \n",
      "the Fractal Analytic Model  (FAM). The Analytic Selection Process and \n",
      "accompanying Guide to Analytic Selection  provide key insights into one \n",
      "of the most challenging tasks in all of Data Science – selecting the \n",
      "right technique for the job.\n",
      "  Act\n",
      "Now that we have analyzed the data, it’s time to take action. \n",
      "The ability to make use of the analysis is critical. It is also very \n",
      "situational. Like the Acquire activity, the best we can hope for is to \n",
      "provide some guiding principles to help you frame the output for \n",
      "maximum impact. Here are some key points to keep in mind when \n",
      "presenting your results:\n",
      "1. The finding must make sense with relatively little up-front \n",
      "training or preparation on the part of the decision maker.\n",
      "2. The finding must make the most meaningful patterns, trends \n",
      "and exceptions easy to see and interpret.\n",
      "3. Every effort must be made to encode quantitative data \n",
      "accurately so the decision maker can accurately interpret and \n",
      "compare the data.\n",
      "4. The logic used to arrive at the finding must be clear and \n",
      "compelling as well as traceable back through the data.\n",
      "5. The findings must answer real business questions.\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Source: Booz Allen Hamilton \n",
      "Proportion\n",
      "of \n",
      "EffortMaturity\n",
      "Stages of Maturity\n",
      "Collect\n",
      "Describe\n",
      "DiscoverPredictAdviseData Silos\n",
      "35 Start Here for the Basics 35 Start Here for the BasicsData Science Maturity within  \n",
      "an Organization\n",
      "The four activities discussed thus far provide a simplified view of Data \n",
      "Science. Organizations will repeat these activities with each new Data \n",
      "Science endeavor. Over time, however, the level of effort necessary \n",
      "for each activity will change. As more data is Acquired and Prepared \n",
      "in the Data Lake, for example, significantly less effort will need to \n",
      "be expended on these activities. This is indicative of a maturing Data \n",
      "Science capability.\n",
      "Assessing the maturity of your Data Science capability calls for a \n",
      "slightly different view. We use The Data Science Maturity Model  as \n",
      "a common framework for describing the maturity progression and \n",
      "components that make up a Data Science capability. This framework \n",
      "can be applied to an organization’s Data Science capability or even \n",
      "to the maturity of a specific solution, namely a data product. At each \n",
      "stage of maturity, powerful insight can be gained. \n",
      "The Data Science Maturity Model\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Source: Booz Allen Hamilton When organizations start out, they have Data Silos . At this stage, \n",
      "they have not carried out any broad Aggregate activities. They may \n",
      "not have a sense of all the data they have or the data they need. The \n",
      "decision to create a Data Science capability signals the transition into \n",
      "the Collect  stage. \n",
      "All of your initial effort will be focused on identifying and aggregating \n",
      "data. Over time, you will have the data you need and a smaller \n",
      "proportion of your effort can focus on Collect . You can now begin to \n",
      "Describe  your data. Note, however, that while the proportion of time \n",
      "spent on Collect  goes down dramatically, it never goes away entirely. \n",
      "This is indicative of the four activities outlined earlier – you will \n",
      "continue to Aggregate and Prepare data as new analytic questions \n",
      "arise, additional data is needed and new data sources become available.\n",
      "Organizations continue to advance in maturity as they move through \n",
      "the stages from Describe to Advise . At each stage they can tackle \n",
      "increasingly complex analytic goals with a wider breadth of analytic \n",
      "capabilities. As described for Collect , each stage never goes away \n",
      "entirely. Instead, the proportion of time spent focused on it goes  \n",
      "down and new, more mature activities begin. A brief description  \n",
      "of each stage of maturity is shown in the table The Stages of Data \n",
      "Science Maturity.\n",
      "The Stages of Data Science Maturity\n",
      "Stage Description Example\n",
      "CollectFocuses on collecting internal \n",
      "or external datasets.Gathering sales records and \n",
      "corresponding weather data.\n",
      "DescribeSeeks to enhance or \n",
      "reﬁne raw data as well \n",
      "as leverage basic analytic \n",
      "functions such as counts.How are my customers \n",
      "distributed with respect to \n",
      "location, namely zip code?  \n",
      "DiscoverIdentiﬁes hidden relationships \n",
      "or patterns.Are there groups within \n",
      "my regular customers that \n",
      "purchase similarly?\n",
      "PredictUtilizes past observations to \n",
      "predict future observations.Can we predict which products \n",
      "that certain customer groups \n",
      "are more likely to purchase?\n",
      "AdviseDeﬁnes your possible decisions, \n",
      "optimizes over those decisions, \n",
      "and advises to use the decision \n",
      "that gives the best outcome.Your advice is to target advertise \n",
      "to speciﬁc groups for certain \n",
      "products to maximize revenue.\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Source: Booz Allen Hamilton \n",
      "37 Start Here for the Basics 37 Start Here for the BasicsThe maturity model provides a powerful tool for understanding  \n",
      "and appreciating the maturity of a Data Science capability. \n",
      "Organizations need not reach maximum maturity to achieve  \n",
      "success. Significant gains can be found in every stage. We believe \n",
      "strongly that one does not engage in a Data Science effort, however, \n",
      "unless it is intended to produce an output – that is, you have the \n",
      "intent to Advise . This means simply that each step forward in  \n",
      "maturity drives you to the right in the model diagram. Moving  \n",
      "to the right requires the correct processes, people, culture and \n",
      "operating model – a robust Data Science capability. What Does it  \n",
      "Take to Create a Data Science Capability?  addresses this topic. \n",
      "We have observed very few organizations actually operating at  \n",
      "the highest levels of maturity, the Predict  and Advise  stages. The \n",
      "tradecraft of Discover  is only now maturing to the point that \n",
      "organizations can focus on advanced Predict and Advise activities.  \n",
      "This is the new frontier of Data Science. This is the space in which \n",
      "we will begin to understand how to close the cognitive gap between \n",
      "humans and computers. Organizations that reach Advise  will be  \n",
      "met with true insights and real competitive advantage. »  Where does your organization \n",
      "fall in analytic maturity? \n",
      " Take the quiz!\n",
      "1.   How many data sources do  \n",
      "you collect?\n",
      "a.  Why do we need a bunch of dat a? \n",
      " – 0 points, end here.\n",
      "b.  I don’t know the e xact number.  \n",
      "– 5 points\n",
      "c.  We identiﬁed the required data and \n",
      "collect it. – 10 points\n",
      "2. Do you know what questions  \n",
      "your Data Science team is trying  \n",
      "to answer?\n",
      "a.  Why do we need ques tions?   \n",
      "- 0 points\n",
      "b.  No, they ﬁgure it out for themselves. \n",
      "– 5 points\n",
      "c.  Yes, we evaluated the questions that \n",
      "will have the largest impact to the \n",
      "business. – 10 points\n",
      "3. Do you know the important factors \n",
      "driving your business?\n",
      "a. I have no idea.  – 0 points\n",
      "b.  Our quants help me ﬁgure it out.  \n",
      "– 5 points\n",
      "c.  We have a data product for that.  \n",
      "– 10 points\n",
      "4. Do you have an understanding of \n",
      "future conditions?\n",
      "a. I look at the current conditions and \n",
      "read the tea leaves. – 0 points\n",
      "b.  We have a data product for that.   \n",
      "– 5 points\n",
      "5. Do you know the best course \n",
      "of action to take for your key \n",
      "decisions?\n",
      "a.  I look at the projections and plan a \n",
      "course. – 0 points\n",
      "b.  We have a data product for that.  \n",
      "– 5 points\n",
      "Check your score: \n",
      "0 – Data Silos, 5-10 – Collect,  \n",
      "10-20 – Describe, 20-30 – Discover, \n",
      "30-35 – Predict, 35-40 - Advise\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "What Does it Take to Create \n",
      "a Data Science Capability?\n",
      "Data Science is all about building teams and culture.\n",
      "Many organizations (both commercial and government) see the \n",
      "potential in capitalizing on data to unlock operational efficiencies, \n",
      "to create new services and experiences, and to propel innovation. \n",
      "Unfortunately, too many business leaders invest in one-off technical \n",
      "solutions— with a big price tag and mixed results— instead of \n",
      "investing in building a strategic Data Science capability. A Data \n",
      "Science capability embeds and operationalizes Data Science across \n",
      "an enterprise such that it can deliver the next level of organizational \n",
      "performance and return on investment. A Data Science capability \n",
      "moves an organization beyond performing pockets of analytics to an \n",
      "enterprise approach that uses analytical insights as part of the normal \n",
      "course of business. When building a capability, it is important for an \n",
      "organization to first identify its analytic goals (i.e., what it is trying \n",
      "to achieve through analytics) and then assess its readiness to achieve \n",
      "those goals – examining both technical readiness and organizational \n",
      "readiness. An organization can then make strategic choices on how to \n",
      "address gaps and begin to build their capability. \n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Source: Booz Allen Hamilton \n",
      "COMPUTER SCIENCE\n",
      "Provides the environment \n",
      "in which data products \n",
      "are created.DOMAIN EXPERTISE\n",
      "Provides understanding \n",
      "of the reality in which a \n",
      "problem space exists.\n",
      "MATHEMATICS\n",
      "Provides the theoretical \n",
      "structure in which Data \n",
      "Science problems \n",
      "are examined.\n",
      "The Data Science Venn Diagram  (inspired by [12])\n",
      "39 Start Here for the Basics 39 Start Here for the BasicsBuilding Y our Data Science Team\n",
      "A critical component to any Data Science capability is having the  \n",
      "right team. Data Science depends on a diverse set of skills as shown  \n",
      "in The Data Science Venn Diagram. Computers provide the \n",
      "environment in which data-driven hypotheses are tested, and as such, \n",
      "computer science is necessary for data manipulation and processing. \n",
      "Mathematics provides the theoretical structure in which Data Science \n",
      "problems are examined. A rich background in statistics, geometry, \n",
      "linear algebra, and calculus are all important to understand the basis \n",
      "for many algorithms and tools. Finally, domain expertise contributes  \n",
      "to an understanding of what problems actually need to be solved,  \n",
      "what kind of data exists in the domain, and how the problem space \n",
      "may be instrumented and measured.\n",
      "Remember that Data Science is a team sport. Most of the time, you \n",
      "will not be able to find the rare “unicorns” - people with expertise \n",
      "across all three of the skill areas. Therefore, it is important to build a \n",
      "blended team that covers all three elements of the Data Science  \n",
      "Venn Diagram.\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Source: Booz Allen Hamilton BALANCING THE DATA  \n",
      "SCIENCE TEAM EQUATION\n",
      "Balancing the composition of a Data Science team \n",
      "is much like balancing the reactants and products in \n",
      "a chemical reaction. Each side of the equation must \n",
      "represent the same quantity of any particular element. \n",
      "In the case of Data Science, these elements are the \n",
      "foundational technical skills Computer Science (CS), \n",
      "Mathematics (M) and Domain Expertise (DE). The \n",
      "reactants, your Data Scientists, each have their own \n",
      "unique skills compositions. You must balance the staff \n",
      "mix to meet the skill requirements of the Data Science \n",
      "team, the product in the reaction. If you don’t correctly \n",
      "balance the equation, your Data Science team will not \n",
      "have the desired impact on the organization.\n",
      "2 CS M2 + 2 CS + M DE → CS4 M5 DE\n",
      "In the example above, your project requires four parts \n",
      "computer science, ﬁve parts mathematics and one part \n",
      "domain expertise. Given the skills mix of the staff, ﬁve \n",
      "people are needed to balance the equation. Throughout \n",
      "your Data Science project, the skills requirements of \n",
      "the team will change. You will need to re-balance the \n",
      "equation to ensure the reactants balance with  \n",
      "the products.\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "41 Start Here for the Basics 41 Start Here for the BasicsUnder standing What Makes  \n",
      "a Data Scientist \n",
      "Data Science often requires a significant investment of time across \n",
      "a variety of tasks. Hypotheses must be generated and data must be \n",
      "acquired, prepared, analyzed, and acted upon. Multiple techniques \n",
      "are often applied before one yields interesting results. If that seems \n",
      "daunting, it is because it is. Data Science is difficult, intellectually \n",
      "taxing work, which requires lots of talent: both tangible technical \n",
      "skills as well as the intangible “x-factors.”\n",
      "There are four independent yet comprehensive foundational Data \n",
      "Science competency clusters that, when considered together, convey \n",
      "the essence of what it means to be a successful Data Scientist. There \n",
      "are also reach back competencies that complement the foundational \n",
      "clusters but do not define the core tradecraft or attributes of the Data \n",
      "Science team. \n",
      "Data Science Competency Framework  \n",
      "(see [13] for complete framework) \n",
      "Clusters Competencies Description\n",
      "Technical: \n",
      "“Knows How and \n",
      "What to do”Advanced Mathematics; \n",
      "Computer Science; Data \n",
      "Mining and Integration; \n",
      "Database Science; Research \n",
      "Design; Statistical Modeling; \n",
      "Machine Learning; \n",
      "Operations Research; \n",
      "Programming and ScriptingThe technical competency \n",
      "cluster depicts the \n",
      "foundational technical \n",
      "and specialty knowledge \n",
      "and skills needed for \n",
      "successful performance \n",
      "in each job or role.\n",
      "Data Science \n",
      "Consulting:  \n",
      "“Can Do in \n",
      "a Client and \n",
      "Customer \n",
      "Environment”Collaboration and Teamwork; \n",
      "Communications; Data \n",
      "Science Consulting; Ethics \n",
      "and IntegrityThe characteristics in the \n",
      "consulting competency \n",
      "cluster can help Data \n",
      "Scientists easily integrate \n",
      "into various market or \n",
      "domain contexts and partner \n",
      "with business units to \n",
      "understand the environment \n",
      "and solve complex problems.\n",
      "Cognitive:  \n",
      "“Able to Do or \n",
      "Learn to Do”Critical Thinking; Inductive \n",
      "and Deductive Reasoning; \n",
      "Problem SolvingThe cognitive competency \n",
      "cluster represents the type \n",
      "of critical thinking and \n",
      "reasoning abilities (both \n",
      "inductive and deductive) a \n",
      "Data Scientist should have to \n",
      "perform their job.\n",
      "Personality:  \n",
      "“Willing or \n",
      "Motivated to Do”Adaptability/Flexibility; \n",
      "Ambiguity Tolerance; Detail \n",
      "Orientation; Innovation and \n",
      "Creativity; Inquisitiveness; \n",
      "Perseverance; Resilience \n",
      "and Hardiness; Self-\n",
      "Conﬁdence; Work EthicThe personality competency \n",
      "cluster describes the \n",
      "personality traits that drive \n",
      "behaviors that are beneﬁcial \n",
      "to Data Scientists, such as \n",
      "inquisitiveness, creativity, \n",
      "and perseverance.\n",
      "Reach Back Competencies for Data Science Teams\n",
      "Business Acumen; Data Visualization; Domain Expertise; Program Management » The Triple Threat Unicorn \n",
      "Individuals who are great at \n",
      "all three of the Data Science \n",
      "foundational technical skills are \n",
      "like unicorns – very rare and if \n",
      "you’re ever lucky enough to find \n",
      "one they should be treated carefully. \n",
      "When you manage these people:\n",
      " ›Encourag e them to lead your \n",
      "team, but not manage it. \n",
      "Don’t bog them down with \n",
      "responsibilities of management \n",
      "that could be done by other staff.\n",
      " ›Put extr a effort into managing \n",
      "their careers and interests \n",
      "within your organization. Build \n",
      "opportunities for promotion into \n",
      "your organization that allow \n",
      "them to focus on mentoring other \n",
      "Data Scientists and progressing \n",
      "the state of the art while also \n",
      "advancing their careers.\n",
      " ›Make sure that the y have the \n",
      "opportunity to present and \n",
      "spread their ideas in many \n",
      "different forums, but also be \n",
      "sensitive to their time.\n",
      " Source: Booz Allen Hamilton\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "The most important qualities of Data Scientists tend to be the \n",
      "intangible aspects of their personalities. Data Scientists are by nature \n",
      "curious, creative, focused, and detail-oriented.\n",
      "›› Curiosity  is necessary to peel apart a problem and examine the \n",
      "interrelationships between data that may appear superficially \n",
      "unrelated.\n",
      "›› Creativity  is required to invent and try new approaches to \n",
      "solving a problem, which often times have never been applied in \n",
      "such a context before.\n",
      "›› Focus  is required to design and test a technique over days and \n",
      "weeks, find it doesn’t work, learn from the failure, and try again.\n",
      "›› Attention to Detail is needed to maintain rigor, and to detect and \n",
      "avoid over-reliance on intuition when examining data.\n",
      "We have found the single most important attribute is flexibility in \n",
      "overcoming setbacks - the willingness to abandon one idea and try \n",
      "a new approach. Often, Data Science is a series of dead ends before, \n",
      "at last, the way forward is identified. It requires a unique set of \n",
      "personality attributes to succeed in such an environment. Technical \n",
      "skills can be developed over time: the ability to be flexible – and \n",
      "patient, and persistent – cannot.\n",
      "Finding the Athletes for Y our T eam\n",
      "Building a Data Science team is complex. Organizations must \n",
      "simultaneously engage existing internal staff to create an “anchor” who \n",
      "can be used to recruit and grow the team, while at the same time \n",
      "undergo organizational change and transformation to meaningfully \n",
      "incorporate this new class of employee. Building a team starts with \n",
      "identifying existing staff within an organization who have a high \n",
      "aptitude for Data Science. Good candidates will have a formal \n",
      "background in any of the three foundational technical skills we \n",
      "mentioned, and will most importantly have the personality traits \n",
      "necessary for Data Science. They may often have advanced (masters or \n",
      "higher) degrees, but not always. The very first staff you identify should \n",
      "also have good leadership traits and a sense of purpose for the \n",
      "organization, as they will lead subsequent staffing and recruiting \n",
      "efforts. Don’t discount anyone – you will find Data Scientists in the \n",
      "strangest places with the oddest combinations of backgrounds. » Don’t judge a book by its \n",
      "cover, or a Data Scientist by \n",
      "his or her degree in this case. \n",
      "Amazing Data Scientists can \n",
      "be found anywhere. Just look \n",
      "at the diverse and surprising \n",
      "sampling of degrees held by \n",
      "Our Experts:\n",
      " ›Bioinformatics\n",
      " ›Biomedic al Engineering\n",
      " ›Bioph ysics\n",
      " ›Business\n",
      " ›Computer Gr aphics\n",
      " ›Computer S cience\n",
      " ›English\n",
      " ›Forest Management\n",
      " ›History\n",
      " ›Industrial Engineer ing\n",
      " ›Infor mation Technology\n",
      " ›Mathematics\n",
      " ›Natio nal Security Studies\n",
      " ›Operatio ns Research\n",
      " ›Physics\n",
      " ›Wild life & Fisheries \n",
      "Management\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "43 Start Here for the Basics 43 Start Here for the BasicsShaping the Culture\n",
      "It is no surprise—building a culture is hard and there is just as \n",
      "much art to it as there is science. It is about deliberately creating the \n",
      "conditions for Data Science to flourish (for both Data Scientists and \n",
      "the average employee). You can then step back to empower collective \n",
      "ownership of an organic transformation. \n",
      "Data Scientists are fundamentally curious and imaginative. We have \n",
      "a saying on our team, “We’re not nosy, we’re Data Scientists.” These \n",
      "qualities are fundamental to the success of the project and to gaining \n",
      "new dimensions on challenges and questions. Often Data Science \n",
      "projects are hampered by the lack of the ability to imagine something \n",
      "new and different. Fundamentally, organizations must foster trust and \n",
      "transparent communication across all levels, instead of deference to \n",
      "authority, in order to establish a strong Data Science team. Managers \n",
      "should be prepared to invite participation more frequently, and offer \n",
      "explanation or apology less frequently.\n",
      "It is important to provide a path into the Data Science “club” and  \n",
      "to empower the average employee to feel comfortable and conversant \n",
      "with Data Science. For something to be part of organizational  \n",
      "culture, it must be part of the fabric of the employee behavior.  \n",
      "That means employees must interact with and use data products \n",
      "in their daily routines. Another key ingredient to shaping the \n",
      "right culture is that all employees need a baseline of Data Science \n",
      "knowledge, starting with a common lexicon, to facilitate productive \n",
      "collaboration and instill confidence. While not everyone will be \n",
      "Data Scientists, employees need to identify with Data Science and \n",
      "be equipped with the knowledge, skills, and abilities to work with \n",
      "Data Scientists to drive smarter decisions and deliver exponential \n",
      "organizational performance. »  “I'm not nosey, I'm a Data    \n",
      "Scientist” \n",
      " ›Always remember that \n",
      "unrelenting curiosity and \n",
      "imagination should be the \n",
      "hallmarks of Data Science. They \n",
      "are fundamental to the success \n",
      "of every Data Science project.\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Source: Booz Allen Hamilton \n",
      "Data Science Operating Models  \n",
      "(see [13] for complete descriptions)Selecting Y our Operating Model\n",
      "Depending on the size, complexity, and the business drivers, \n",
      "organizations should consider one of three Data Science operating \n",
      "models: Centralized, Deployed, or Diffused. These three models are \n",
      "shown in the figure, Data Science Operating Models.\n",
      "Centralized Data Science teams serve the organization across all business \n",
      "units. The team is centralized under a Chief Data Scientist and they all \n",
      "co-locate together. The domain experts come to this organization for \n",
      "brief rotational stints to solve challenges around the business. This model \n",
      "provides greater efficiency with limited Data Science resources but can also \n",
      "create the perceived need to compete with other business units for Data \n",
      "Science talent. To address this challenge, it is important to place emphasis \n",
      "on portfolio management and creating transparency on how organizations \n",
      "will identify and select Data Science projects. \n",
      "Deployed Data Science  teams go to the business unit and reside there for \n",
      "short- or long-term assignments. They are their own entity and they work \n",
      "with the domain experts within the group to solve hard problems. In \n",
      "the deployed model, Data Science teams collectively develop knowledge \n",
      "across business units, with central leadership as a bridging mechanism for \n",
      "addressing organization-wide issues. However, Data Science teams are \n",
      "accountable to business unit leadership and their centralized leadership, \n",
      "which could cause confusion and conflict. In this model, it is important  \n",
      "to emphasize conflict management to avoid competing priorities. \n",
      "The Diffused Data Science  team is one that is fully embedded with each \n",
      "group and becomes part of the long-term organization. These teams work \n",
      "best when the nature of the domain or business unit is already one focused \n",
      "on analytics. In the Diffused Model, teams can quickly react to high-\n",
      "priority business unit needs. However, the lack of central management can \n",
      "result in duplicate software and tools. Additionally, business units with the \n",
      "most money will often have full access to analytics while other units have \n",
      "none—this may not translate to the greatest organizational impact. In this \n",
      "model, it is important to establish cross-functional groups that promote \n",
      "organization-wide governance and peer collaboration. \n",
      "Full descriptions of each operating model can be found in Booz Allen’s Tips for \n",
      "Building a Data Science Capability [13].\n",
      "CENTRALIZED\n",
      "Business units bring their \n",
      "problems to a centralized \n",
      "Data Science team.\n",
      "DIFFUSED\n",
      "Data Scientists are fully \n",
      "embedded within the  \n",
      "business units.\n",
      "DEPLOYED\n",
      "Small Data Science teams \n",
      "are forward deployed to \n",
      "business units.\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "45 Start Here for the Basics 45 Start Here for the BasicsHow to Generate Momentum\n",
      "A Data Science effort can start at the grass roots level by a few folks \n",
      "tackling hard problems, or as directed by the Chief Executive Officer, \n",
      "Chief Data Officer, or Chief Analytics Officer. Regardless of how an \n",
      "effort starts, political headwinds often present more of a challenge \n",
      "than solving any technical hurdles. To help battle the headwinds, it is \n",
      "important to generate momentum and prove the value a Data Science \n",
      "team can provide. The best way to achieve this is usually through \n",
      "a Data Science prototype or proof of concept. Proofs of concepts \n",
      "can generate the critical momentum needed to jump start any Data \n",
      "Science Capability Four qualities, in particular, are essential for every \n",
      "Data Science prototype:\n",
      "1. Organizational Buy-in: A prototype will only succeed if the \n",
      "individuals involved believe in it and are willing to do what \n",
      "they can to make it successful. A good way to gauge interest \n",
      "is to meet with the middle managers; their views are usually \n",
      "indicative of the larger group. \n",
      "2. Clear ROI:  Before choosing a prototype problem, ensure that \n",
      "the ROI of the analytic output can be clearly and convincingly \n",
      "demonstrated for both the project and the organization as a \n",
      "whole. This outcome typically requires first reaching consensus \n",
      "on how the ROI will be determined and measured, so that the \n",
      "benefit can be quantified.\n",
      "3. Necessary Data: Before selecting a prototype, you must first \n",
      "determine exactly what data is needed, whether it will actually \n",
      "be available, and what it will cost in terms of time and expense. \n",
      "It is important to note that organizations do not need all the \n",
      "possible data – they can still create successful analytics even \n",
      "with some gaps.\n",
      "4. Limited Complexity and Duration:  The problem addressed \n",
      "by the prototype should achieve a balance between being too \n",
      "complex and too easy. Organizations new to Data Science often \n",
      "try to show its value with highly complex projects. However, \n",
      "the greater the complexity, the greater the risk of failure. At the \n",
      "same time, if the problem is too easy to solve, senior leaders \n",
      "and others in the organization may not see the need for Data \n",
      "Science. Look for efforts that could benefit from large datasets, \n",
      "or bringing together disparate datasets that have never been \n",
      "combined before, as opposed to those that require complex \n",
      "analytic approaches. In these cases, there is often low-hanging \n",
      "fruit that can lead to significant value for the organization.\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "TAKE OFF   the  TRAINING WHEELS\n",
      "THE PRACTITIONER’S GUIDE  \n",
      "TO DATA SCIENCE\n",
      "Read this section to get beyond the hype and \n",
      "learn the secrets of being a Data Scientist.\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Guiding Principles\n",
      "Failing is good; failing quickly is even better.\n",
      "The set of guiding principles that govern how we conduct the \n",
      "tradecraft of Data Science are based loosely on the central tenets  \n",
      "of innovation, as the two areas are highly connected. These principles \n",
      "are not hard and fast rules to strictly follow, but rather key tenets  \n",
      "that have emerged in our collective consciousness. You should use \n",
      "these to guide your decisions, from problem decomposition  \n",
      "through implementation.\n",
      " ›Be willing to fail.  At the core of Data Science is the idea of \n",
      "experimentation. Truly innovative solutions only emerge when \n",
      "you experiment with new ideas and applications. Failure is an \n",
      "acceptable byproduct of experimentation. Failures locate regions \n",
      "that no longer need to be considered as you search for a solution.  \n",
      " ›Fail often and learn quickly. In addition to a willingness to fail, be \n",
      "ready to fail repeatedly. There are times when a dozen approaches \n",
      "must be explored in order to find the one that works. While you \n",
      "shouldn’t be concerned with failing, you should strive to learn from \n",
      "the attempt quickly. The only way you can explore a large number \n",
      "of solutions is to do so quickly. \n",
      " ›Keep the goal in mind.  You can often get lost in the details and \n",
      "challenges of an implementation. When this happens, you lose \n",
      "sight of your goal and begin to drift off the path from data to \n",
      "analytic action. Periodically step back, contemplate your goal, and \n",
      "evaluate whether your current approach can really lead you where \n",
      "you want to go.  \n",
      " ›Dedication and focus lead to success. You must of ten explore \n",
      "many approaches before finding the one that works. It’s easy to \n",
      "become discouraged. You must remain dedicated to your analytic \n",
      "goal. Focus on the details and the insights revealed by the data. \n",
      "Sometimes seemingly small observations lead to big successes.  \n",
      " ›Complicated does not equal better. As technical practitioners, we \n",
      "have a tendency to explore highly complex, advanced approaches. \n",
      "While there are times where this is necessary, a simpler approach \n",
      "can often provide the same insight. Simpler means easier and \n",
      "faster to prototype, implement and verify.  » Tips From the Pros\n",
      " It can be easier to rule out a solution \n",
      "than conﬁrm its correctness. As a \n",
      "result, focus on exploring obvious \n",
      "shortcomings that can quickly \n",
      "disqualify an approach. This will allow \n",
      "you to focus your time on exploring \n",
      "truly viable approaches as opposed to \n",
      "dead ends.\n",
      " » Tips From the Pros\n",
      "If the ﬁrst thing you try to do is to \n",
      "create the ultimate solution, you will \n",
      "fail, but only after banging your head \n",
      "against a wall for several weeks.\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "The Importance of Reason\n",
      "Beware: in the world of Data Science, if it walks like a duck \n",
      "and quacks like a duck, it might just be a moose.\n",
      "Data Science supports and encourages shifting between deductive \n",
      "(hypothesis-based) and inductive (pattern-based) reasoning.  \n",
      "Inductive reasoning and exploratory data analysis provide a means  \n",
      "to form or refine hypotheses and discover new analytic paths.  \n",
      "Models of reality no longer need to be static. They are constantly \n",
      "tested, updated and improved until better models are found.\n",
      "The analysis of big data has brought inductive reasoning to the \n",
      "forefront. Massive amounts of data are analyzed to identify \n",
      "correlations. However, a common pitfall to this approach is confusing \n",
      "correlation with causation. Correlation implies but does not prove \n",
      "causation. Conclusions cannot be drawn from correlations until the \n",
      "underlying mechanisms that relate the data elements are understood. \n",
      "Without a suitable model relating the data, a correlation may simply \n",
      "be a coincidence.  »  Correlation without \n",
      "Causat ion\n",
      "A common example of this \n",
      "phenomenon is the high correlation \n",
      "between ice cream consumption and \n",
      "the murder rate during the summer \n",
      "months. Does this mean ice cream \n",
      "consumption causes murder or, \n",
      "conversely, murder causes ice cream \n",
      "consumption? Most likely not, but \n",
      "you can see the danger in mistaking \n",
      "correlation for causation. Our job as \n",
      "Data Scientists is making sure we \n",
      "understand the difference. \n",
      "49 Take off the Training Wheels\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "››\n",
      "Paul Yacci\n",
      "The Dangers of Rejection\n",
      "In the era of big \n",
      "data, one piece \n",
      "of analysis that \n",
      "is frequently \n",
      "overlooked is \n",
      "the problem of \n",
      "ﬁnding patterns \n",
      "when there \n",
      "are actually no \n",
      "apparent patterns. In statistics \n",
      "this is referred to as Type I error. \n",
      "As scientists, we are always \n",
      "on the lookout for a new or \n",
      "interesting breakthrough that \n",
      "could explain a phenomenon. \n",
      "We hope to see a pattern in our \n",
      "data that explains something \n",
      "or that can give us an answer. \n",
      "The primary goal of hypothesis \n",
      "testing is to limit Type I error. \n",
      "This is accomplished by using \n",
      "small α values. For example, \n",
      "a α value of 0.05 states that \n",
      "there is a 1 in 20 chance that \n",
      "the test will show that there \n",
      "is something signiﬁcant when \n",
      "in actuality there isn’t. This \n",
      "problem compounds when \n",
      "testing multiple hypotheses. \n",
      "When running multiple \n",
      "hypothesis tests, we are likely \n",
      "to encounter Type I error. As \n",
      "more data becomes available \n",
      "for analysis, Type I error \n",
      "needs to be controlled. \n",
      "One of my projects required \n",
      "testing the difference between \n",
      "the means of two microarray \n",
      "data samples. Microarray \n",
      "data contains thousands of \n",
      "measurements but is limited \n",
      "in the number of observations. \n",
      "A common analysis approach \n",
      "is to measure the same genes \n",
      "under different conditions. If \n",
      "there is a signiﬁcant enough \n",
      "difference in the amount of \n",
      "gene expression between the \n",
      "two samples, we can say that \n",
      "the gene is correlated with a \n",
      "particular phenotype. One way \n",
      "to do this is to take the mean of \n",
      "each phenotype for a particular gene and formulate a hypothesis \n",
      "to test whether there is a \n",
      "signiﬁcant difference between \n",
      "the means. Given that we were \n",
      "running thousands of these tests \n",
      "at α = 0.05, we found several \n",
      "differences that were signiﬁcant. \n",
      "The problem was that some \n",
      "of these could be caused by \n",
      "random chance. \n",
      "Many corrections exist to \n",
      "control for false indications of \n",
      "signiﬁcance. The Bonferroni \n",
      "correction is one of the most \n",
      "conservative. This calculation \n",
      "lowers the level below which you \n",
      "will reject the null hypothesis \n",
      "(your p value). The formula is \n",
      "alpha/n , where n equals the \n",
      "number of hypothesis tests \n",
      "that you are running. Thus, if \n",
      "you were to run 1,000 tests of \n",
      "signiﬁcance at α = 0.05, your \n",
      "p value should be less than \n",
      "0.00005 (0.05/1,000) to reject the \n",
      "null hypothesis. This is obviously \n",
      "a much more stringent value.  \n",
      "A large number of the previously \n",
      "signiﬁcant values were no longer \n",
      "signiﬁcant, revealing the true \n",
      "relationships within the data.\n",
      "The corrected signiﬁcance gave \n",
      "us conﬁdence that the observed \n",
      "expression levels were due to \n",
      "differences in the cellular gene \n",
      "expression rather than noise. We \n",
      "were able to use this information \n",
      "to begin investigating what \n",
      "proteins and pathways were \n",
      "active in the genes expressing \n",
      "the phenotype of interest. By \n",
      "solidifying our understanding \n",
      "of the causal relationships, we \n",
      "focused our research on the \n",
      "areas that could lead to new \n",
      "discoveries about gene function \n",
      "and, ultimately to improved \n",
      "medical treatments.\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Reason and common sense are foundational to Data Science. Without these, data is \n",
      "simply a collection of bits. Context, inferences and models are created by humans and \n",
      "carry with them biases and assumptions. Blindly trusting your analyses is a dangerous \n",
      "thing that can lead to erroneous conclusions. When you approach an analytic \n",
      "challenge, you should always pause to ask yourself the following questions:\n",
      " ›What problem are we trying  \n",
      "to solve? Articulate the answer \n",
      "as a sentence, especially when \n",
      "communicating with the end-\n",
      "user. Make sure that it sounds \n",
      "like an answer. For example, \n",
      "“Given a fixed amount of \n",
      "human capital, deploying \n",
      "people with these priorities \n",
      "will generate the best return \n",
      "on their time.”\n",
      " ›Does the approach make sense? \n",
      "Write out your analytic plan. \n",
      "Embrace the discipline of \n",
      "writing, as it brings structure \n",
      "to your thinking. Back of \n",
      "the envelope calculations are \n",
      "an existence proof of your \n",
      "approach. Without this kind \n",
      "of preparation, computers are \n",
      "power tools that can produce \n",
      "lots of bad answers really fast. \n",
      " ›Does the answer make sense? \n",
      "Can you explain the answer? \n",
      "Computers, unlike children, \n",
      "do what they are told. Make \n",
      "sure you spoke to it clearly by \n",
      "validating that the instructions \n",
      "you provided are the ones you \n",
      "intended. Document your \n",
      "assumptions and make sure \n",
      "they have not introduced bias \n",
      "in your work.\n",
      " ›Is it a finding or a mistake?   \n",
      "Be skeptical of surprise \n",
      "findings. Experience says that \n",
      "it if seems wrong, it probably \n",
      "is wrong. Before you accept \n",
      "that conclusion, however, \n",
      "make sure you understand  \n",
      "and can clearly explain why  \n",
      "it is wrong.  ›Does the analysis address the \n",
      "original intent? Make sure \n",
      "that you are not aligning the \n",
      "answer with the expectations \n",
      "of the client. Always speak \n",
      "the truth, but remember that \n",
      "answers of “your baby is ugly” \n",
      "require more, not less, analysis.\n",
      " ›Is the story complete? The goal \n",
      "of your analysis is to tell an \n",
      "actionable story. You cannot \n",
      "rely on the audience to stitch \n",
      "the pieces together. Identify \n",
      "potential holes in your \n",
      "story and fill them to avoid \n",
      "surprises. Grammar, spelling \n",
      "and graphics matter; your \n",
      "audience will lose confidence \n",
      "in your analysis if your results \n",
      "look sloppy.\n",
      " ›Where would we head next? \n",
      "No analysis is ever finished, \n",
      "you just run out of resources. \n",
      "Understand and explain what \n",
      "additional measures could  \n",
      "be taken if more resources  \n",
      "are found. » Tips From the Pros\n",
      "Better a short pencil than a \n",
      "long memory. End every day by \n",
      "documenting where you are; you \n",
      "may learn something along the way. \n",
      "Document what you learned and why \n",
      "you changed your plan.\n",
      " » Tips From the Pros\n",
      "Test your answers with a friendly \n",
      "audience to make sure your ﬁndings \n",
      "hold water. \n",
      "51 Take off the Training Wheels\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Component Parts of  \n",
      "Data Science\n",
      "There is a web of components that interact to create your \n",
      "solution space. Understanding how they are connected  \n",
      "is critical to your ability to engineer solutions to Data  \n",
      "Science problems.\n",
      "The components involved in any Data Science project fall into a \n",
      "number of different categories including the data types analyzed, the \n",
      "analytic classes used, the learning models employed and the execution \n",
      "models used to run the analytics. The interconnection across these \n",
      "components, shown in the figure, Interconnection Among the Component \n",
      "Parts of Data Science , speaks to the complexity of engineering Data \n",
      "Science solutions. A choice made for one component exerts influence \n",
      "over choices made for others categories. For example, data types \n",
      "lead the choices in analytic class and learning models, while latency, \n",
      "timeliness and algorithmic parallelization strategy inform the \n",
      "execution model. As we dive deeper into the technical aspects of  \n",
      "Data Science, we will begin with an exploration of these components \n",
      "and touch on examples of each. \n",
      "  Read this to get the quick and dirty:\n",
      "When engineering a Data \n",
      "Science solution, work from an \n",
      "understanding of the components \n",
      "that define the solution space. \n",
      "Regardless of your analytic goal, \n",
      "you must consider the data types  \n",
      "with which you will be working,  \n",
      "the classes of analytics  you will use \n",
      "to generate your data product, how the learning models  embodied \n",
      "will operate and evolve, and the \n",
      "execution models that will govern \n",
      "how the analytic will be run. \n",
      "You will be able to articulate a \n",
      "complete Data Science solution \n",
      "only after considering each of \n",
      "these aspects. \n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Source: Booz Allen Hamilton \n",
      "data\n",
      "streaming\n",
      "data\n",
      "batch\n",
      "data\n",
      "structured\n",
      "data\n",
      "unstructured\n",
      "analytics\n",
      "transforming\n",
      "analytics\n",
      "learning\n",
      "analytics\n",
      "predictive\n",
      "learning\n",
      "supervised\n",
      "learning\n",
      "unsupervised\n",
      "learning\n",
      "online\n",
      "learning\n",
      "ofﬂine\n",
      "execution\n",
      "batch\n",
      "execution\n",
      "streaming\n",
      "execution\n",
      "parallel\n",
      "execution\n",
      "serial\n",
      "EXECUTION  \n",
      "MODELSDATA TYPES\n",
      "ANALYTIC   \n",
      "CLASSESLEARNING  \n",
      "MODELS\n",
      "Interconnection Among the Component Parts of Data Science\n",
      "53 Take off the Training Wheels\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Data Types\n",
      "Data types and analytic goals go hand-in-hand much like the chicken \n",
      "and the egg; it is not always clear which comes first. Analytic goals are \n",
      "derived from business objectives, but the data type also influences the \n",
      "goals. For example, the business objective of understanding consumer \n",
      "product perception drives the analytic goal of sentiment analysis. \n",
      "Similarly, the goal of sentiment analysis drives the selection of a  \n",
      "text-like data type such as social media content. Data type also  \n",
      "drives many other choices when engineering your solutions. \n",
      "There are a number of ways to classify data. It is common to \n",
      "characterize data as structured  or unstructured . Structured data exists \n",
      "when information is clearly broken out into fields that have an  \n",
      "explicit meaning and are highly categorical, ordinal or numeric. \n",
      "A related category, semi-structured, is sometimes used to describe \n",
      "structured data that does not conform to the formal structure of  \n",
      "data models associated with relational databases or other forms  \n",
      "of data tables, but nonetheless contains tags or other markers. \n",
      "Unstructured data, such as natural language text, has less clearly \n",
      "delineated meaning. Still images, video and audio often fall under  \n",
      "the category of unstructured data. Data in this form requires \n",
      "preprocessing to identify and extract relevant ‘features.’ The features \n",
      "are structured information that are used for indexing and retrieval,  \n",
      "or training classification, or clustering models. \n",
      "Data may also be classified by the rate at which it is generated, \n",
      "collected or processed. The distinction is drawn between streaming \n",
      "data that arrives constantly like a torrent of water from a fire \n",
      "hose, and batch data, which arrives in buckets. While there is \n",
      "rarely a connection between data type and data rate, data rate has \n",
      "significant influence over the execution model chosen for analytic \n",
      "implementation and may also inform a decision of analytic class or \n",
      "learning model.\n",
      "55 Take off the Training Wheels\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Source: Booz Allen Hamilton Classes of Analytic T echniques\n",
      "As a means for helping conceptualize the universe of possible analytic \n",
      "techniques, we grouped them into nine basic classes. Note that \n",
      "techniques from a given class may be applied in multiple ways to \n",
      "achieve various analytic goals. Membership in a class simply indicates \n",
      "a similar analytic function. The nine analytic classes are shown in the \n",
      "figure, Classes of Analytic Techniques .\n",
      "›» Transforming Analytics\n",
      " ›Aggregation : Techniques to summarize the data. These \n",
      "include basic statistics (e.g., mean, standard deviation), \n",
      "distribution fitting, and graphical plotting.\n",
      " ›Enrichment : Techniques for adding additional information \n",
      "to the data, such as source information or other labels.\n",
      " ›Processing : Techniques that address data cleaning, \n",
      "preparation, and separation. This group also includes \n",
      "common algorithm pre-processing activities such as \n",
      "transformations and feature extraction.\n",
      "›» Learning Analytics\n",
      " ›Regression : Techniques for estimating relationships among \n",
      "variables, including understanding which variables are \n",
      "important in predicting future values.\n",
      " ›Clustering : Techniques to segment the data into naturally \n",
      "similar groups.\n",
      " ›Classification : Techniques to identify data element  \n",
      "group membership.\n",
      " ›Recommendation : Techniques to predict the rating or \n",
      "preference for a new entity, based on historic preference  \n",
      "or behavior.\n",
      "›» Predictive Analytics\n",
      " ›Simulation : Techniques to imitate the operation of a real-\n",
      "world process or system. These are useful for predicting \n",
      "behavior under new conditions.\n",
      " ›Optimization : Operations Research techniques focused on \n",
      "selecting the best element from a set of available alternatives \n",
      "to maximize a utility function.\n",
      "Aggregation Enrichment Processing Simulation Optimization Regression Clustering Classiﬁcation RecommendTRANSFORMING LEARNINGANALYTIC CLASSESPREDICTIVE\n",
      "Classes of Analytic Techniques\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Source: Booz Allen Hamilton Learning Models\n",
      "Analytic classes that perform predictions, such as regression, \n",
      "clustering, classification and recommendation employ learning \n",
      "models. These models characterize how the analytic is trained to \n",
      "perform judgments on new data based on historic observation. \n",
      "Aspects of learning models describe both the types of judgments \n",
      "performed and how the models evolve over time, as shown in the \n",
      "figure, Analytic Learning Models .\n",
      "Learning models are typically described as belonging to the categories \n",
      "of unsupervised or supervised learning. Supervised learning takes \n",
      "place when a model is trained using a labeled dataset that has a known \n",
      "class or category associated with each data element. The model relates \n",
      "features found in training instances with labels so that predictions \n",
      "can be made for unlabeled instances. Unsupervised learning involves \n",
      "no a-priori knowledge about the classes into which data can be \n",
      "placed. Unsupervised learning uses the features in the dataset to \n",
      "form groupings based on feature similarity. Semi-supervised learning \n",
      "is a hybrid between these two approaches, using a small amount of \n",
      "labeled data in conjunction with a large amount of unlabeled data. \n",
      "This is done to improve learning accuracy in cases where only a \n",
      "small number of labeled observations are available for learning.\n",
      "There are a variety of ways to train learning models. A useful \n",
      "distinction is between those that are trained in a single pass, which are \n",
      "known as offline models, and those that are trained incrementally over \n",
      "time, known as online models. Many learning approaches have online \n",
      "or offline variants. The decision to use one or another is based on the \n",
      "analytic goals and execution models chosen.\n",
      "Generating an offline model requires taking a pass over the entire \n",
      "training dataset. Improving the model requires making separate \n",
      "passes over the data. These models are static in that once trained, their \n",
      "predictions will not change until a new model is created through a \n",
      "subsequent training stage. Offline model performance is easier to \n",
      "evaluate due to this deterministic behavior. Deployment of the model \n",
      "into a production environment involves swapping out the old model \n",
      "for the new.\n",
      "Online models dynamically evolve over time, meaning they only \n",
      "require a single deployment into a production setting. The fact that Analytic Learning Models\n",
      " »Reinforcement Learning  \n",
      "in Action\n",
      "The possibilities of Reinforcement \n",
      "Learning captured significant \n",
      "attention with the publication of a \n",
      "study in the journal Nature in which \n",
      "a computer agent learned to play 49 \n",
      "different video games with accuracy \n",
      "rivaling a professional game tester [14]. \n",
      "The agent was able to achieve these \n",
      "results using only the raw screen \n",
      "pixels and game score as input. This \n",
      "approach represents the first artificial \n",
      "intelligence agent that is capable \n",
      "of learning complex tasks while \n",
      "bridging between high-dimensional \n",
      "sensory inputs and actions.\n",
      "UnsupervisedSemi-\n",
      "SupervisedSupervised\n",
      "Ofﬂine Reinforcement OnlineLEARNING STYLE TRAINING STYLE\n",
      "57 Take off the Training Wheels\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "these models do not have the entire dataset available when being \n",
      "trained is a challenge. They must make assumptions about the data \n",
      "based on the examples observed; these assumptions may be sub-\n",
      "optimal. The impact of sub-optimal predictions can be mitigated in \n",
      "cases where feedback on the model’s predictions is available. Online \n",
      "models can rapidly incorporate feedback to improve performance.\n",
      "One such training style is known as Reinforcement Learning. Under \n",
      "this approach, an algorithm takes action in an environment and \n",
      "incrementally learns how to achieve goals based on the response to a \n",
      "function used to determine the quality of its results. Reinforcement \n",
      "learning is generally applicable to complex, real-world tasks that \n",
      "involve optimization, such as navigation or trading. Due to the \n",
      "publication of many promising results from Reinforcement Learning \n",
      "algorithms, the popularity of this technique has risen dramatically in \n",
      "recent years along with Deep Learning. \n",
      "Execution Models\n",
      "Execution models describe how data is manipulated to perform \n",
      "an analytic function. They may be categorized across a number \n",
      "of dimensions. Execution Models are embodied by an execution \n",
      "framework, which orchestrates the sequencing of analytic \n",
      "computation. In this sense, a framework might be as simple as a \n",
      "programming language runtime, such as the Python interpreter, or \n",
      "a distributed computing framework that provides a specific API for \n",
      "one or more programming languages such as Hadoop, MapReduce \n",
      "or Spark. Grouping execution models based on how they handle data \n",
      "is common, classifying them as either batch or streaming execution \n",
      "models. The categories of execution model are shown in the figure, \n",
      "Analytic Execution Models.\n",
      "Analytic Execution Models\n",
      "A batch execution model implies that data is analyzed in large \n",
      "segments, that the analytic has a state where it is running and a state \n",
      "where it is not running and that little state is maintained in memory \n",
      "between executions. Batch execution may also imply that the analytic \n",
      "produces results with a frequency on the order of several minutes or \n",
      "more. Batch workloads tend to be fairly easy to conceptualize because \n",
      "SEQUENCING\n",
      "Serial Parallel Batch StreamingSCHEDULING\n",
      " Source: Booz Allen Hamilton \n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "they represent discrete units of work. As such, it is easy to identify \n",
      "a specific series of execution steps as well as the proper execution \n",
      "frequency and time bounds based on the rate at which data arrives. \n",
      "Depending on the algorithm choice, batch execution models are  \n",
      "easily scalable through parallelism. There are a number of frameworks \n",
      "that support parallel batch analytic execution. Most famously,  \n",
      "Hadoop provides a distributed batch execution model in its \n",
      "MapReduce framework.\n",
      "Conversely, a streaming model analyzes data as it arrives. Streaming \n",
      "execution models imply that under normal operation, the analytic \n",
      "is always executing. The analytic can hold state in memory and \n",
      "constantly deliver results as new data arrives, on the order of seconds \n",
      "or less. Many of the concepts in streaming are inherent in the Unix-\n",
      "pipeline design philosophy; processes are chained together by linking \n",
      "the output of one process to the input of the next. As a result, many \n",
      "developers are already familiar with the basic concepts of streaming. \n",
      "A number of frameworks are available that support the parallel \n",
      "execution of streaming analytics such as Storm, S4 and Samza. \n",
      "The choice between batch and streaming execution models often \n",
      "hinges on analytic latency and timeliness requirements. Latency refers \n",
      "to the amount of time required to analyze a piece of data once it \n",
      "arrives at the system, while timeliness refers to the average age of an \n",
      "answer or result generated by the analytic system. For many analytic \n",
      "goals, a latency of hours and timeliness of days is acceptable and \n",
      "thus lend themselves to the implementation enabled by the batch \n",
      "approach. Some analytic goals have up-to-the-second requirements \n",
      "where a result that is minutes old has little worth. The streaming \n",
      "execution model better supports such goals.\n",
      "Batch and streaming execution models are not the only dimensions \n",
      "within which to categorize analytic execution methods. Another \n",
      "distinction is drawn when thinking about scalability. In many cases, \n",
      "scale can be achieved by spreading computation over a number of \n",
      "computers. In this context, certain algorithms require a large shared \n",
      "memory state, while others are easily parallelizable in a context \n",
      "where no shared state exists between machines. This distinction has \n",
      "significant impacts on both software and hardware selection when \n",
      "building out a parallel analytic execution environment. » Tips From the Pros\n",
      "In order to understand system capacity \n",
      "in the context of streaming analytic \n",
      "execution, collect metrics including: \n",
      "the amount of data consumed, data \n",
      "emitted, and latency. This will help  \n",
      "you understand when scale limits  \n",
      "are reached.\n",
      "59 Take off the Training Wheels\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Fractal Analytic Model\n",
      "Data Science analytics are a lot like broccoli. \n",
      "Fractals are mathematical sets that display self-similar patterns. As \n",
      "you zoom in on a fractal, the same patterns reappear. Imagine a stalk \n",
      "of broccoli. Rip off a piece of broccoli and the piece looks much like \n",
      "the original stalk. Progressively smaller pieces of broccoli still look like \n",
      "the original stalk.\n",
      "Data Science analytics are a lot like broccoli – fractal in nature in \n",
      "both time and construction. Early versions of an analytic follow the \n",
      "same development process as later versions. At any given iteration, the \n",
      "analytic itself is a collection of smaller analytics that often decompose \n",
      "into yet smaller analytics.\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Setup Try\n",
      "EvaluateDo\n",
      "EvaluateIterative by Nature\n",
      "Good Data Science is fractal in time  — an iterativ e process. Getting \n",
      "an imperfect solution out the door quickly will gain more interest \n",
      "from stakeholders than a perfect solution that is never completed. The \n",
      "figure, The Data Science Product Lifecycle,  summarizes the lifecycle of \n",
      "the Data Science product. \n",
      "Set up  the infrastructure, aggregate and prepare the data, and \n",
      "incorporate domain expert knowledge. Try different analytic \n",
      "techniques and models on subsets of the data. Evaluate  the models, \n",
      "refine, evaluate again, and select a model. Do something with your \n",
      "models and results – deploy the models to inform, inspire action, and \n",
      "act. Evaluate  the business results to improve the overall product.The Data Science Product Lifecycle  Source: Booz Allen Hamilton \n",
      "61 Take off the Training Wheels\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Smaller Pieces of Broccoli: A Data  \n",
      "Science Product\n",
      "Components inside and outside of the Data Science product will \n",
      "change with each iteration. Let’s take a look under the hood of a  \n",
      "Data Science product and examine the components during one  \n",
      "such iteration.\n",
      "In order to achieve a greater analytic goal, you need to first decompose \n",
      "the problem into sub-components to divide and conquer. The figure, \n",
      "The Fractal Analytic Model , shows a decomposition of the Data Science \n",
      "product into four component pieces.\n",
      "GOAL\n",
      "›  Describe\n",
      "›  Discover\n",
      "›  Predict\n",
      "›  Advise\n",
      "ACTION\n",
      "›  Productization\n",
      "›  Data Monetization\n",
      "›  Insights & RelationshipsDATA\n",
      "›  Text\n",
      "›  Imagery\n",
      "›  Waveform\n",
      "›  Geo\n",
      "›  Time Series\n",
      "COMPUTATIONAggregation\n",
      "Enrichment\n",
      "Clustering\n",
      "ClassificationCLASSES OF ANALYTICS\n",
      "The Fractal Analytic Model Source: Booz Allen Hamilton \n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "GOAL\n",
      "You must first have some idea of your analytic goal and the end state \n",
      "of the analysis. Is it to Discover, Describe, Predict, or Advise? It is \n",
      "probably a combination of several of those. Be sure that before you \n",
      "start, you define the business value of the data and how you plan to \n",
      "use the insights to drive decisions, or risk ending up with interesting \n",
      "but non-actionable trivia.\n",
      "DATA\n",
      "Data dictates the potential insights that analytics can provide. Data \n",
      "Science is about finding patterns in variable data and comparing those \n",
      "patterns. If the data is not representative of the universe of events you \n",
      "wish to analyze, you will want to collect that data through carefully \n",
      "planned variations in events or processes through A/B testing or \n",
      "design of experiments. Datasets are never perfect so don’t wait for \n",
      "perfect data to get started. A good Data Scientist is adept at handling \n",
      "messy data with missing or erroneous values. Just make sure to spend \n",
      "the time upfront to clean the data or risk generating garbage results.\n",
      "COMPUTATION\n",
      "Computation aligns the data to goals through the process of creating \n",
      "insights. Through divide and conquer, computation decomposes \n",
      "into several smaller analytic capabilities with their own goals, data, \n",
      "computation and resulting actions, just like a smaller piece of broccoli \n",
      "maintains the structure of the original stalk. In this way, computation \n",
      "itself is fractal. Capability building blocks may utilize different \n",
      "types of execution models such as batch computation or streaming, \n",
      "that individually accomplish small tasks. When properly combined \n",
      "together, the small tasks produce complex, actionable results.\n",
      "ACTION\n",
      "How should engineers change the manufacturing process to generate \n",
      "higher product yield? How should an insurance company choose \n",
      "which policies to offer to whom and at what price? The output of \n",
      "computation should enable actions that align to the goals of the data \n",
      "product. Results that do not support or inspire action are nothing but \n",
      "interesting trivia.\n",
      "Given the fractal nature of Data Science analytics in time and \n",
      "construction, there are many opportunities to choose fantastic or \n",
      "shoddy analytic building blocks. The Analytic Selection Process offers \n",
      "some guidance.\n",
      "63 Take off the Training Wheels\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "The Analytic  \n",
      "Selection Process\n",
      "If you focus only on the science aspect of Data Science you will \n",
      "never become a data artist.\n",
      "A critical step in Data Science is to identify an analytic technique that \n",
      "will produce the desired action. Sometimes it is clear; a characteristic \n",
      "of the problem (e.g., data type) points to the technique you should \n",
      "implement. Other times, however, it can be difficult to know where \n",
      "to begin. The universe of possible analytic techniques is large. Finding \n",
      "your way through this universe is an art that must be practiced. We \n",
      "are going to guide you on the next portion of your journey - becoming \n",
      "a data artist.\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Decomposing the Problem\n",
      "Decomposing the problem into manageable pieces is the first step \n",
      "in the analytic selection process. Achieving a desired analytic action \n",
      "often requires combining multiple analytic techniques into a holistic, \n",
      "end-to-end solution. Engineering the complete solution requires that \n",
      "the problem be decomposed into progressively smaller sub-problems. \n",
      "The Fractal Analytic Model  embodies this approach. At any given \n",
      "stage, the analytic itself is a collection of smaller computations that \n",
      "decompose into yet smaller computations. When the problem is \n",
      "decomposed far enough, only a single analytic technique is needed \n",
      "to achieve the analytic goal. Problem decomposition creates multiple \n",
      "sub-problems, each with their own goals, data, computations, and \n",
      "actions. The concept behind problem decomposition is shown in the \n",
      "figure, Problem Decomposition Using the Fractal Analytic Model .\n",
      "GOAL\n",
      "›  Describe\n",
      "›  Discover\n",
      "›  Predict\n",
      "›  Advise\n",
      "ACTION\n",
      "›  Productization\n",
      "›  Data Monetization\n",
      "›  Insights & RelationshipsDATA\n",
      "› Text\n",
      "›  Imagery\n",
      "›  Waveform\n",
      "›  Geo\n",
      "›  Time Series\n",
      "DATAGOAL\n",
      "ACTION\n",
      "DATAGOAL\n",
      "ACTIONAggregation\n",
      "Enrichment\n",
      "Clustering\n",
      "ClassificationCLASSES OF ANALYTICS\n",
      "Problem Decomposition Using the Fractal Analytic Model Source: Booz Allen Hamilton \n",
      "65 Take off the Training Wheels\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "On the surface, problem decomposition appears to be a mechanical, \n",
      "repeatable process. While this may be true conceptually, it is \n",
      "really the performance of an art as opposed to the solving of an \n",
      "engineering problem. There may be many valid ways to decompose \n",
      "the problem, each leading to a different solution. There may be \n",
      "hidden dependencies or constraints that only emerge after you begin \n",
      "developing a solution. This is where art meets science. Although the \n",
      "art behind problem decomposition cannot be taught, we have distilled \n",
      "some helpful hints to help guide you. When you begin to think about \n",
      "decomposing your problem, look for:\n",
      " ›Compound analytic goals that create natural segmentation . \n",
      "For example, many problems focused on predicting future \n",
      "conditions include both Discover and Predict goals.\n",
      " ›Natural orderings of analytic goals. For example, when extracting \n",
      "features you must first identify candidate features and then \n",
      "select the features set with the highest information value. These \n",
      "two activities form distinct analytic goals.  \n",
      " ›Data types that dictate processing activities. For example, text or \n",
      "imagery both require feature extraction.\n",
      " ›Requirements for human-in-the-loop feedback.  For example, \n",
      "when developing alerting thresholds, you might need to solicit \n",
      "analyst feedback and update the threshold based on their \n",
      "assessment.\n",
      " ›The need to combine multiple data sources.  For example, you may \n",
      "need to correlate two datasets to achieve your broader goal. \n",
      "Often this indicates the presence of a Discover goal. \n",
      "In addition to problem decomposition providing a tractable approach \n",
      "to analytic selection, it has the added benefit of simplifying a highly \n",
      "complex problem. Rather than being faced with understanding the \n",
      "entire end-to-end solution, the computations are discrete segments \n",
      "that can be explored. Note, however, that while this technique helps \n",
      "the Data Scientist approach the problem, it is the complete end-to-\n",
      "end solution that must be evaluated.  » Tips From the Pros\n",
      "One of your ﬁrst steps should be to \n",
      "explore available data sources that \n",
      "have not been previously combined. \n",
      "Emerging relationships between data \n",
      "sources often allow you to pick low \n",
      "hanging fruit.\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Compare \n",
      "DatasetsList of \n",
      "recently \n",
      "registered \n",
      "company \n",
      "domains\n",
      "List of \n",
      "candidate \n",
      "spoofed \n",
      "domains\n",
      "List of \n",
      "recently \n",
      "registered \n",
      "company \n",
      "domainsDiscover spoofed \n",
      "domains\n",
      "Test &\n",
      "Evaluation\n",
      "Test &\n",
      "Evaluation\n",
      "Test &\n",
      "EvaluationCalculate\n",
      "MetricSet\n",
      "ThresholdData\n",
      "CollectionSimulate\n",
      "Spoofed\n",
      "Data\n",
      "Store\n",
      "Generated\n",
      "Domains\n",
      "Generate\n",
      "Candidate\n",
      "DomainsAlert on spoofed domains to \n",
      "provide opportuinity to \n",
      "minimize brand image and \n",
      "consumer conﬁdence damageDiscover likely \n",
      "candidates for \n",
      "spoofed domains\n",
      "List of candidate \n",
      "spoofed domainsList of recently \n",
      "registered \n",
      "company domainsDescribe closeness of \n",
      "spoof to valid domains\n",
      "Quantitative \n",
      "measure of feature \n",
      "information valueThreshold that balances \n",
      "false positive and false \n",
      "negative rate\n",
      "Quantitative threshold for \n",
      "automated result ranking› \n",
      "› \n",
      "List of candidate spoofed \n",
      "domains\n",
      "List of recently registered \n",
      "company domains\n",
      "Quantitative measure of \n",
      "feature information value› \n",
      "› \n",
      "› Stephanie \n",
      "Rivera\n",
      "Identifying Spoofed Domains\n",
      "Identifying spoofed domains is important for an organization \n",
      "to preserve their brand image and to avoid eroded customer \n",
      "conﬁdence. Spoofed domains occur when a malicious actor  \n",
      "creates a website, URL or email address that users believe is \n",
      "associated with a valid organization. When users click the link,  \n",
      "visit the website or receive emails, they are subjected to some  \n",
      "type of nefarious activity.\n",
      "Our team was faced with the problem of \n",
      "identifying spoofed domains for a commercial \n",
      "company. On the surface, the problem sounded \n",
      "easy; take a recently registered domain, check \n",
      "to see if it is similar to the company’s domain \n",
      "and alert when the similarity is sufﬁciently high. \n",
      "Upon decomposing the problem, however, the \n",
      "main computation quickly became complicated.\n",
      "We needed a computation that determined \n",
      "similarity between two domains. As we \n",
      "decomposed the similarity computation, \n",
      "complexity and speed became a concern.  \n",
      "As with many security-related problems, fast alert speeds are vital. Result speed created \n",
      "an implementation constraint that forced us to \n",
      "re-evaluate how we decomposed the problem.\n",
      "Revisiting the decomposition process led us \n",
      "to a completely new approach. In the end, \n",
      "we derived a list of domains similar to those \n",
      "registered by the company. We then compared \n",
      "that list against a list of recently registered \n",
      "domains. The ﬁgure, Spoofed Domain Problem \n",
      "Decomposition,  illustrates our approach. Upon \n",
      "testing and initial deployment, our analytic \n",
      "discovered a spoofed domain within 48 hours.  ››\n",
      "Spoofed Domain Problem Decomposition Source: Booz Allen Hamilton \n",
      "67 Take off the Training Wheels\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "SPEED:  The speed at which an \n",
      "analytic outcome must be produced \n",
      "(e.g., near real-time, hourly, daily) or the time \n",
      "it takes to develop and implement the \n",
      "analytic solution\n",
      "ANALYTIC COMPLEXITY:  \n",
      "Algorithmic complexity (e.g., complexity class \n",
      "and execution resources) \n",
      "ACCURACY & PRECISION:  The ability \n",
      "to produce exact versus approximate  \n",
      "solutions as well as the ability to provide a \n",
      "measure of conﬁdence\n",
      "DATA SIZE: The size of the dataset \n",
      "(e.g., number of rows)\n",
      "DATA COMPLEXITY:  The data \n",
      "type, formal complexity measures \n",
      "including measures of overlap and \n",
      "linear separability, number of \n",
      "dimensions /columns, and linkages \n",
      "between datasets\n",
      "SPEED\n",
      "ANALYTIC\n",
      "COMPLEXITYDATA\n",
      "COMPLEXITY\n",
      "ACCURACY\n",
      "&\n",
      "PRECISIONDATA SIZEImplementation Constraints\n",
      "In the spoofed domains case study, the emergence of an \n",
      "implementation constraint caused the team to revisit its approach. \n",
      "This demonstrates that analytic selection does not simply mean \n",
      "choosing an analytic technique to achieve a desired outcome. It also \n",
      "means ensuring that the solution is feasible to implement. \n",
      "The Data Scientist may encounter a wide variety of implementation \n",
      "constraints. They can be conceptualized, however, in the context of \n",
      "five dimensions that compete for your attention: analytic complexity, \n",
      "speed, accuracy & precision, data size, and data complexity. Balancing \n",
      "these dimensions is a zero sum game - an analytic solution cannot \n",
      "simultaneously exhibit all five dimensions, but instead must make \n",
      "trades between them. The figure, Balancing the Five Analytic \n",
      "Dimensions,  illustrates this relationship. \n",
      " \n",
      "Implementation constraints occur when an aspect of the problem \n",
      "dictates the value for one or more of these dimensions. As soon as  \n",
      "one dimension is fixed, the Data Scientist is forced to make trades \n",
      "among the others. For example, if the analytic problem requires \n",
      "actions to be produced in near real-time, the speed dimension is  \n",
      "fixed and trades must be made among the other four dimensions. \n",
      "Understanding which trades will achieve the right balance among  \n",
      "the five dimensions is an art that must be learned over time.As we compiled this section, we \n",
      "talked extensively about ways to \n",
      "group and classify implementation \n",
      "constraints. After much discussion \n",
      "we settled on these five dimensions. \n",
      "We present this model in hopes  \n",
      "that others weigh in and offer  \n",
      "their own perspectives.Balancing the Five Analytic Dimensions Source: Booz Allen Hamilton \n",
      "69 Take off the Training Wheels\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Some common examples of implementation  \n",
      "constraints include:\n",
      "• Computation frequency.  The solution may need to run on a regular \n",
      "basis (e.g., hourly), requiring that computations be completed \n",
      "within a specified window of time. The best analytic is useless if it \n",
      "cannot solve the problem within the required time. \n",
      "• Solution timeliness.  Some applications require near real-time \n",
      "results, pointing toward streaming approaches. While some \n",
      "algorithms can be implemented within streaming frameworks, \n",
      "many others cannot.  \n",
      "• Implementation speed. A project may require that you rapidly \n",
      "develop and implement a solution to quickly produce analytic \n",
      "insights. In these cases, you may need to focus on less complex \n",
      "techniques that can be quickly implemented and verified.\n",
      "• Computational resource limitations.  Although you may be able \n",
      "to store and analyze your data, data size may be sufficiently large \n",
      "that algorithms requiring multiple computations across the full \n",
      "dataset are too resource intensive. This may point toward needing \n",
      "approaches that only require a single pass on the data (e.g., canopy \n",
      "cluster as opposed to k-means clustering).  \n",
      "• Data storage limitations . There are times when big data becomes  \n",
      "so big it cannot be stored or only a short time horizon can be \n",
      "stored. Analytic approaches that require long time horizons may \n",
      "not be possible. \n",
      "Organizational policies and regulatory requirements are a major \n",
      "source of implicit constraints that merit a brief discussion. Policies \n",
      "are often established around specific classes of data such as Personally \n",
      "Identifiable Information (PII) or Personal Health Information (PHI). \n",
      "While the technologies available today can safely house information \n",
      "with a variety of security controls in a single system, these policies \n",
      "force special data handling considerations including limited retention \n",
      "periods and data access. Data restrictions impact the data size and \n",
      "complexity dimensions outlined earlier, creating yet another layer of \n",
      "constraints that must be considered.  » Tips From the Pros\n",
      "When possible, consider approaches \n",
      "that make use of previously computed \n",
      "results. Your algorithm will run  \n",
      "much faster if you can avoid  \n",
      "re-computing values across  \n",
      "the full time horizon of data.\n",
      " » Tips From the Pros\n",
      "Our Data Science Product Lifecycle  \n",
      "has evolved to produce results quickly \n",
      "and then incrementally improve  \n",
      "the solution.\n",
      " » Tips From the Pros\n",
      "Streaming approaches may be useful \n",
      "for overcoming storage limitations.\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "4\n",
      " Data \n",
      "Science\n",
      "3DESCRIBE  \n",
      "DISCOVER  \n",
      "PREDICT \n",
      "ADVISE 21\n",
      "Guide to Analytic Selection\n",
      "Your senses are incapable of perceiving the entire universe, so \n",
      "we drew you a map.\n",
      "The universe of analytic techniques is vast and hard to comprehend. \n",
      "We created this diagram to aid you in finding your way from data  \n",
      "and goal to analytic action. Begin at the center of the universe  \n",
      "(Data Science) and answer questions about your analytic goals and \n",
      "problem characteristics. The answers to your questions will guide you \n",
      "through the diagram to the appropriate class of analytic techniques \n",
      "and provide recommendations for a few techniques to consider.\n",
      "n  TIP: There are several situations where dimensionality reduction may be needed:\n",
      " ›Models fail to converge\n",
      " ›Models produce results equivalent to  \n",
      "random chance\n",
      " ›You lack the computational power to \n",
      "perform operations across the  feature space\n",
      " ›You do not know which aspects of the \n",
      "data are\n",
      " › the most important\n",
      "o  Feature Extraction  is a broad topic and is highly dependent upon the domain area.  \n",
      "This topic could be the subject of an entire book. As a result, a detailed exploration  \n",
      "has been omitted from this diagram. See the Featuring Engineering  and Feature \n",
      "Selection sections in the Life in the Trenches  chapter for additional information.\n",
      "p  TIP: Always check data labels for correctness. This is particularly true for time stamps, \n",
      "which may have reverted to system default values.\n",
      "q  TIP: Smart enrichment can greatly speed-up computational time. It can also be a huge \n",
      "differentiator between the accuracy of different end-to-end analytic solutions.\n",
      " Source: Booz Allen Hamilton \n",
      "71 Take off the Training Wheels\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Data \n",
      "Science\n",
      "FILTERING \n",
      "How do I identify \n",
      "data based on \n",
      "its absolute or \n",
      "relative values?\n",
      "IMPUTATION \n",
      "How do I ﬁll in \n",
      "missing values \n",
      "in my data?\n",
      "DIMENSIONALITY \n",
      "REDUCTION  n  \n",
      "How do I reduce \n",
      "the number of \n",
      "dimensions \n",
      "in my data?\n",
      "NORMALIZATION & \n",
      "TRANSFORMATION \n",
      "How do I reconcile \n",
      "duplication \n",
      "representations \n",
      "in the data?\n",
      "FEATURE \n",
      "EXTRACTION o  \n",
      "PROCESSING p  \n",
      "How do I clean \n",
      "and separate \n",
      "my data?If you want to add or remove data based on its value, start with:\n",
      "› Relational algebra projection and selection \n",
      "If early results are uninformative and duplicative, start with:\n",
      "› Outlier removal  › Gaussian ﬁlter\n",
      "› Exponential smoothing › Median ﬁlter \n",
      "If you are unfamiliar with the dataset, start with \n",
      "basic statistics: \n",
      "› Count › Standard deviation › Box plots\n",
      "› Mean › Range  › Scatter plots \n",
      "If your approach assumes the data follows a \n",
      "distribution, start with:\n",
      "› Distribution ﬁtting\n",
      "If you want to understand all the information \n",
      "available on an entity, start with:\n",
      "› “Baseball card” aggregation    \n",
      "If you need to keep track of source information or other \n",
      "user-deﬁned parameters, start with:\n",
      "› Annotation\n",
      "If you often process certain data ﬁelds together or use \n",
      "one ﬁeld to compute the value of another, start with:\n",
      "› Relational algebra rename,  \n",
      "› Feature addition (e.g., Geography, Technology, Weather)If you want to generate values from other observations in your dataset, start with:\n",
      "› Random sampling\n",
      "› Markov Chain Monte Carlo (MC)\n",
      "If you want to generate values without using other observations in your dataset, \n",
      "start with:\n",
      "› Mean   › Regression models\n",
      "› Statistical distributions\n",
      "If you need to determine whether there is multi-dimensional correlation, \n",
      "start with:\n",
      "› PCA and other factor analysis\n",
      "If you can represent individual observations by membership in a group, start with:\n",
      "› K-means clustering\n",
      "› Canopy clustering\n",
      "If you have unstructured text data, start with:\n",
      "› Term Frequency/Inverse Document Frequency (TF IDF) \n",
      "If you have a variable number of features but your \n",
      "algorithm requires a ﬁxed number, start with:\n",
      "› Feature hashing\n",
      "If you are not sure which features are the most important, start with: \n",
      "› Wrapper methods\n",
      "› Sensitivity analysis\n",
      "If you need to facilitate understanding of the \n",
      "probability distribution of the space, start with: \n",
      "› Self organizing maps\n",
      "If you suspect duplicate data elements, start with:\n",
      "› Deduplication\n",
      "If you want your data to fall within a speciﬁed range, start with:\n",
      "› Normalization  \n",
      "If your data is stored in a binary format, start with:\n",
      "› Format Conversion \n",
      "If you are operating in frequency space, start with:\n",
      "› Fast Fourier Transform (FFT),\n",
      "› Discrete wavelet transform \n",
      "If you are operating in Euclidian space, start with:\n",
      "› Coordinate transform\n",
      "DESCRIBE  \n",
      "How do I develop \n",
      "an understanding \n",
      "of the content of \n",
      "my data?\n",
      "ENRICHMENT q \n",
      "How do I add \n",
      "new information \n",
      "to my data?AGGREGATION \n",
      "How do I collect \n",
      "and summarize \n",
      "my data?1\n",
      "2\n",
      "4\n",
      "3\n",
      "PREDICT\n",
      "DISCOVER\n",
      "ADVISE\n",
      " \n",
      " Source: Booz Allen Hamilton \n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "If you are unfamiliar with the dataset, start with If you want to generate values from other observations in your dataset, start with:\n",
      "If you want to generate values without using other observations in your dataset, \n",
      "If you need to determine whether there is multi-dimensional correlation, \n",
      "If you can represent individual observations by membership in a group, start with:\n",
      "CLASSIFICATION\n",
      "How do I \n",
      "predict group \n",
      "membership?\n",
      "If you want an ordered set of clusters with variable precision, start with:  \n",
      "› Hierarchical\n",
      "r If you have a known number of clusters, start with:     \n",
      "› X-means\n",
      "› Canopy\n",
      "› Apriori\n",
      "If you have text data, start with:   \n",
      "› Topic modeling\n",
      "If you have non-elliptical clusters, start with:    \n",
      "› Fractal\n",
      "› DB Scan\n",
      "If you want soft membership in the clusters, start with:   \n",
      "› Gaussian mixture models\n",
      "s If you have an known number of clusters, start with:   \n",
      "› K-means\n",
      "If your data has unknown  structure, start with:   \n",
      "› Tree-based methods\n",
      "If statistical measures of importance are \n",
      "needed, start with:   \n",
      "› Generalized linear models\n",
      "If statistical measures of importance are not \n",
      "needed, start with:   \n",
      "› Regression with shrinkage (e.g., LASSO, Elastic net)\n",
      "› Stepwise regression\n",
      "If you want to compare two groups\n",
      "› T-test\n",
      "If you want to compare multiple groups\n",
      "› ANOVA\n",
      "2\n",
      "DISCOVER  \n",
      "What are the \n",
      "key relationships \n",
      "in the data?REGRESSION \n",
      "How do I \n",
      "determine which \n",
      "variables may \n",
      "be important?\n",
      "HYPOTHESIS \n",
      "TESTING\n",
      "How do I \n",
      "test ideas?CLUSTERING \n",
      "How do I segment \n",
      "the data to \n",
      "ﬁnd natural \n",
      "groupings?\n",
      "DESCRIBE\n",
      " Data \n",
      "Science\n",
      "3\n",
      "PREDICT\n",
      "ADVISE\n",
      "1\n",
      "4\n",
      "r  TIP:  Canopy clustering is good when you only want to make a single pass over the data.\n",
      "s   TIP:  Use canopy or hierarchical clustering to estimate the number of clusters you \n",
      "should generate.\n",
      " Source: Booz Allen Hamilton\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "If you have known dependent relationships between variables\n",
      "› Bayesian network\n",
      "If you are unsure of feature importance, start with:  \n",
      "› Neural nets,\n",
      "› Random forests\n",
      "› Deep learning\n",
      "If you require a highly transparent model, start with:   \n",
      "› Decision trees\n",
      "If you have <20 data dimensions, start with:   \n",
      "› K-nearest neighbors\n",
      "If you have a large dataset with an unknown classiﬁcation \n",
      "signal, start with:    \n",
      "› Naive bayes\n",
      "If you want to estimate an unobservable state based on \n",
      "observable variables, start with:    \n",
      "› Hidden markov model\n",
      "u If you don't know where else to begin, start with:   \n",
      "› Support vector machines (SVM)\n",
      "› Random forests\n",
      "If the data structure is unknown, \n",
      "start with:    \n",
      "› Tree-based methods\n",
      "If you require a highly \n",
      "transparent model, start with:  \n",
      " › Generalized linear models\n",
      "If you have <20 data dimensions, \n",
      "start with:   \n",
      "› K-nearest neighbors\n",
      "PREDICT \n",
      "What are the \n",
      "likely future \n",
      "outcomes?REGRESSION \n",
      "How do I predict \n",
      "a future value?\n",
      "If you only have knowledge of how people interact with items, \n",
      "start with:    \n",
      " › Collaborative ﬁltering\n",
      "If you have a feature vector of item characteristics, start with:    \n",
      " › Content-based methods\n",
      "If you only have knowledge of how items are connected to one \n",
      "another, start with:   \n",
      " › Graph-based methods\n",
      "RECOMMENDATION  vw  \n",
      "How do I predict relevant \n",
      "conditions?CLASSIFICATION  t \n",
      "How do I \n",
      "predict group \n",
      "membership?\n",
      "3\n",
      "2\n",
      "DISCOVER\n",
      "1\n",
      "DESCRIBE\n",
      " Data \n",
      "Science\n",
      "4\n",
      "ADVISE\n",
      "If you want an ordered set of clusters with variable precision, start with:  \n",
      "If your data has unknown  structure, start with:   \n",
      "If statistical measures of importance are \n",
      "If statistical measures of importance are not \n",
      "› Regression with shrinkage (e.g., LASSO, Elastic net)\n",
      "t  TIP: It can be difﬁcult to predict which classiﬁer will work best on your dataset.  \n",
      "Always try multiple classiﬁers. Pick the one or two that work the best to reﬁne and \n",
      "explore further.\n",
      "u TIP:  These are our favorite, go-to classiﬁcation algorithms. \n",
      "v  TIP:  Be careful of the “recommendation bubble”, the tendency of recommenders to \n",
      "recommend only what has been seen in the past.  \n",
      "You must ensure you add diversity to avoid this phenomenon. \n",
      "w  TIP:  SVD and PCA are good tools for creating better features for recommenders.\n",
      " Source: Booz Allen Hamilton\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "If the data structure is unknown, \n",
      "transparent model, start with:  \n",
      "If you have <20 data dimensions, \n",
      "If you only have knowledge of how people interact with items, \n",
      "If you have a feature vector of item characteristics, start with:    \n",
      "If you only have knowledge of how items are connected to one \n",
      "ADVISE \n",
      "What course \n",
      "of action \n",
      "should I take?If you have expert knowledge to capture\n",
      " › Expert systems\n",
      "If you're looking for basic facts\n",
      " › Logical reasoning\n",
      "LOGICAL \n",
      "REASONING\n",
      "How do I sort \n",
      "through different \n",
      "evidence?\n",
      "If you must model discrete entities, start with:   \n",
      " › Discrete event simulation (DES)\n",
      "If there are a discrete set of possible states, start with:   \n",
      " › Markov models\n",
      "If there are actions and interactions among autonomous \n",
      "entities, start with:    \n",
      " › Agent-based simulation\n",
      "If you do not need to model discrete entities, start with:    \n",
      " › Monte Carlo simulation\n",
      "If you are modeling a complex system with feedback \n",
      "mechanisms between actions, start with:    \n",
      "› Systems dynamics\n",
      "If you require continuous tracking of system behavior, \n",
      "start with:   \n",
      " › Activity-based simulation\n",
      "If you already have an understanding of what factors \n",
      "govern the system, start with:   \n",
      " › ODES\n",
      " › PDES\n",
      "If you have imprecise categories\n",
      " › Fuzzy logic\n",
      "SIMULATION\n",
      "How do I characterize\n",
      "a system that does not\n",
      "have a closed-form\n",
      "representation?\n",
      "If your problem is represented by a \n",
      "non-deterministic utility function, start with:   \n",
      " › Stochastic search\n",
      "If approximate solutions are acceptable, \n",
      "start with:   \n",
      " › Genetic algorithms\n",
      " › Simulated annealing\n",
      " › Gradient search\n",
      "If your problem is represented by a \n",
      "deterministic utility function, start with:   \n",
      " › Linear programming\n",
      " › Integer programming\n",
      " › Non-linear programming\n",
      "If you have limited resources to search with\n",
      " › Active learning\n",
      "If you want to try multiple models\n",
      " › Ensemble learning\n",
      "OPTIMIZATION \n",
      "How do I identify the \n",
      "best course of action \n",
      "when my objective \n",
      "can be expressed as \n",
      "a utility function?4\n",
      "2\n",
      "DISCOVER\n",
      "DESCRIBE\n",
      " Data \n",
      "Science\n",
      "3\n",
      "PREDICT\n",
      "1\n",
      " Source: Booz Allen Hamilton\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Compiled by: Booz Allen Hamilton\n",
      "Technique Description Tips From the ProsReferences we  \n",
      "love to read\n",
      "Active \n",
      "LearningIntelligent sample selection \n",
      "to improve performance \n",
      "of model.  Samples are \n",
      "selected to provide the \n",
      "greatest information \n",
      "to a learning model.Can be paired with a human in-the-loop \n",
      "to help capture domain knowledge.Burr, Settles B. “Active \n",
      "Learning: Synthesis Lectures \n",
      "on Artiﬁcial Intelligence and \n",
      "Machine Learning.” Morgan \n",
      "& Claypool, 2012. Print.\n",
      "Agent Based \n",
      "SimulationSimulates the actions \n",
      "and interactions of \n",
      "autonomous agents.In many systems, complex behavior \n",
      "results from surprisingly simple rules. \n",
      "Keep the logic of your agents simple \n",
      "and gradually build in sophistication.Macal, Charles, and Michael \n",
      "North. “Agent-based Modeling and \n",
      "Simulation.” Winter Simulation \n",
      "Conference . Austin, TX. 2009. \n",
      "Conference Presentation. \n",
      "ANOVAHypothesis testing for \n",
      "differences between \n",
      "more than two groups.Check model assumptions before \n",
      "utilizing, and watch out for Family Wise \n",
      "error when running multiple tests.Bhattacharyya, Gouri K., \n",
      "and Richard A. Johnson. \n",
      "Statistical Concepts and \n",
      "Models . Wiley, 1977. Print.\n",
      "Association \n",
      "Rule Mining \n",
      "(Apriori)Data mining technique \n",
      "to identify the common \n",
      "co-occurances of items.Utilize when you have a need to understand \n",
      "potential relationships between elements.Agrawal, Rakesh, and \n",
      "Ramakrishnan Srikant. \n",
      "“Fast Algorithms for Mining \n",
      "Association Rules.” Proc. Of \n",
      "20th Intl. Conf. on VLDB . 1994. \n",
      "Conference Presentation.\n",
      "Bayesian \n",
      "NetworkModels conditional \n",
      "probabilities amongst \n",
      "elements, visualized as a \n",
      "Directed Acyclic Graph.Calculate by hand before using larger \n",
      "models to ensure understanding.Russel, Stuart, and Peter \n",
      "Norvig. “Artiﬁcial Intelligence: \n",
      "A Modern Approach.” Prentice \n",
      "Hall, 2009 Print. Detailed Table of Analytics\n",
      "Getting you to the right starting point isn’t enough. We also \n",
      "provide a translator so you understand what you’ve been told.\n",
      "Identifying several analytic techniques that can be applied to your \n",
      "problem is useful, but their name alone will not be much help. The \n",
      "Detailed Table of Analytics translates the names into something more \n",
      "meaningful. Once you’ve identified a technique in the Guide to \n",
      "Analytic Selection, find the corresponding row in the table. There you \n",
      "will find a brief description of the techniques, tips we’ve learned and a \n",
      "few references we’ve found helpful. \n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Compiled by: Booz Allen HamiltonTechnique Description Tips From the ProsReferences we  \n",
      "love to read\n",
      "Collaborative \n",
      "FilteringAlso known as \n",
      "'Recommendation,' suggest \n",
      "or eliminate items from a \n",
      "set by comparing a history \n",
      "of actions against items \n",
      "performed by users. Finds \n",
      "similar items based on who \n",
      "used them or similar users \n",
      "based on the items they use.Use Singular Value Decomposition \n",
      "based Recommendation for cases \n",
      "where there are latent factors in your \n",
      "domain, e.g., genres in movies.Owen, Sean, Robin Anil, Ted \n",
      "Dunning, and Ellen Friedman. \n",
      "Mahout in Action.  New Jersey: \n",
      "Manning, 2012. Print.\n",
      "Coordinate \n",
      "Transforma -\n",
      "tionProvides a different \n",
      "perspective on data.Changing the coordinate system for data, for \n",
      "example, using polar or cylindrical coordinates, \n",
      "may more readily highlight key structure in the \n",
      "data. A key step in coordinate transformations \n",
      "is to appreciate multidimensionality and to \n",
      "systematically analyze subspaces of the data.Abbott, Edwin A., Flatland: A \n",
      "Romance of Many Dimensions. \n",
      "United Kingdom: Seely & Co., \n",
      "1884. Print.\n",
      "Deep LearningMethod that learns \n",
      "features that leads to \n",
      "higher concept learning.  \n",
      "Usually very deep neural \n",
      "network architectures.Utilize a GPU to efﬁciently train complex \n",
      "models.Bengio, Yoshua, and Yann \n",
      "LeCun. “Scaling Learning \n",
      "Algorithms towards AI.” Large-\n",
      "Scale Kernel Machines . New \n",
      "York: MIT Press, 2007. Print.\n",
      "Design of \n",
      "ExperimentsApplies controlled \n",
      "experiments to quantify \n",
      "effects on system output \n",
      "caused by changes to inputs.Fractional factorial designs can signiﬁcantly \n",
      "reduce the number of different types of \n",
      "experiments you must conduct.Montgomery, Douglas. Design \n",
      "and Analysis of Experiments. \n",
      "New Jersey: John Wiley \n",
      "& Sons, 2012. Print.\n",
      "Differential \n",
      "EquationsUsed to express \n",
      "relationships between \n",
      "functions and their \n",
      "derivatives, for example, \n",
      "change over time.Differential equations can be used to formalize \n",
      "models and make predictions. The equations \n",
      "themselves can be solved numerically and \n",
      "tested with different initial conditions to study \n",
      "system trajectories.Zill, Dennis, Warren Wright, \n",
      "and Michael Cullen. Differential \n",
      "Equations with Boundary-Value \n",
      "Problems.  Connecticut: Cengage \n",
      "Learning, 2012. Print.\n",
      "Discrete Event \n",
      "SimulationSimulates a discrete \n",
      "sequence of events where \n",
      "each event occurs at a \n",
      "particular instant in time. \n",
      "The model updates its state \n",
      "only at points in time when \n",
      "events occur.Discrete event simulation is useful when \n",
      "analyzing event based processes such as \n",
      "production lines and service centers to \n",
      "determine how system level behavior changes \n",
      "as different process parameters change. \n",
      "Optimization can integrate with simulation to \n",
      "gain efﬁciencies in a process.Burrus, C. Sidney, Ramesh A. \n",
      "Gopinath, Haitao Guo, Jan E. \n",
      "Odegard and Ivan W. Selesnick. \n",
      "Introduction to Wavelets and \n",
      "Wavelet Transforms: A Primer. \n",
      "New Jersey: Prentice Hall, 1998. \n",
      "Print. \n",
      "Discrete \n",
      "Wavelet \n",
      "TransformTransforms time series \n",
      "data into frequency \n",
      "domain preserving \n",
      "locality information.Offers very good time and frequency \n",
      "localization. The advantage over Fourier \n",
      "transforms is that it preserves both frequency \n",
      "and locality. Burrus, C.Sidney, Ramesh \n",
      "A. Gopinath, Haitao Guo, \n",
      "Jan E. Odegard, and Ivan W. \n",
      "Selesnick. Introduction to \n",
      "Wavelets and Wavelet Transforms: \n",
      "A Primer . New Jersey: \n",
      "Prentice Hall, 1998. Print.\n",
      "Ensemble \n",
      "LearningLearning multiple models \n",
      "and combining output to \n",
      "achieve better performance.Be careful not to overﬁt data by having too many \n",
      "model parameters and  overtraining.Dietterich, Thomas G. “Ensemble \n",
      "Methods in Machine Learning.” \n",
      "Lecture Notes in Computer \n",
      "Science. Springer, 2000. Print. \n",
      "Expert \n",
      "SystemsSystems that use symbolic \n",
      "logic to reason about facts.  \n",
      "Emulates human reasoning.Useful to have a human readable explanation of \n",
      "why a system came to a conclusion.Shortliffe, Edward H., and \n",
      "Bruce G. Buchanan. “A Model of \n",
      "Inexact Reasoning in Medicine.” \n",
      "Mathematical Biosciences. \n",
      "Elsevier B.V., 1975. Print. \n",
      "Exponential \n",
      "SmoothingUsed to remove artifacts \n",
      "expected from collection \n",
      "error or outliers.In comparison to a using moving average \n",
      "where past observations are weighted equally, \n",
      "exponential smoothing assigns exponentially \n",
      "decreasing weights over time.Chatﬁeld, Chris, Anne B. \n",
      "Koehler, J. Keith Ord, and \n",
      "Ralph D. Snyder. “A New Look \n",
      "at Models for Exponential \n",
      "Smoothing.” Journal of the Royal \n",
      "Statistical Society: Series D (The \n",
      "Statistician). Royal Statistical \n",
      "Society, 2001. Print.\n",
      "79 Take off the Training Wheels\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Compiled by: Booz Allen HamiltonTechnique Description Tips From the ProsReferences we  \n",
      "love to read\n",
      "Factor \n",
      "AnalysisDescribes variability among \n",
      "correlated variables with the \n",
      "goal of lowering the number \n",
      "of unobserved variables, \n",
      "namely, the factors.If you suspect there are inmeasurable \n",
      "inﬂuences on your data, then you may want to \n",
      "try factor analysis.Child, Dennis. The Essentials of \n",
      "Factor Analysis. United Kingdom: \n",
      "Cassell Educational, 1990. Print.\n",
      "Fast Fourier \n",
      "TransformTransforms time series from \n",
      "time to frequency domain \n",
      "efﬁciently. Can also be used \n",
      "for image improvement by \n",
      "spatial transforms.Filtering a time varying signal can be done \n",
      "more effectively in the frequency domain. Also, \n",
      "noise can often be identiﬁed in such signals by \n",
      "observing power at aberrant frequencies.Mitra, Partha P., and Hemant \n",
      "Bokil. Observed Brain Dynamics.  \n",
      "United Kingdom: Oxford \n",
      "University Press, 2008. Print.\n",
      "Format \n",
      "ConversionCreates a standard \n",
      "representation of data \n",
      "regardless of source format. \n",
      "For example, extracting raw \n",
      "UTF-8 encoded text from \n",
      "binary ﬁle formats such as \n",
      "Microsoft Word or PDFs.There are a number of open source software \n",
      "packages that support format conversion and \n",
      "can interpret a wide variety of formats. One \n",
      "notable package is Apache Tikia.Ingersoll, Grant S., Thomas S. \n",
      "Morton, and Andrew L. Farris. \n",
      "Taming Text: How to Find, \n",
      "Organize, and Manipulate It.  New \n",
      "Jersey: Manning, 2013. Print.\n",
      "Fuzzy LogicLogical reasoning that \n",
      "allows for degrees of truth \n",
      "for a statement.Utilize when categories are not clearly deﬁned.  \n",
      "Concepts such as \"warm\", \"cold\", and \"hot\" can \n",
      "mean different things at different temperatures \n",
      "and domains.Zadeh L.A., \"Fuzzy Sets.” \n",
      "Information and Control. \n",
      "California: University of \n",
      "California, Berkeley, 1965. Print.\n",
      "Gaussian \n",
      "FilteringActs to remove noise \n",
      "or blur data.Can be used to remove speckle \n",
      "noise from images.Parker, James R. Algorithms for \n",
      "Image Processing and Computer \n",
      "Vision.  New Jersey: John Wiley & \n",
      "Sons, 2010. Print.\n",
      "Generalized \n",
      "Linear ModelsExpands ordinary linear \n",
      "regression to allow \n",
      "for error distribution \n",
      "that is not normal.Use if the observed error in your system does \n",
      "not follow the normal distribution.MacCullagh, P., and John A. \n",
      "Nelder. Generalized Linear \n",
      "Models.  Florida: CRC Press, \n",
      "1989. Print.\n",
      "Genetic \n",
      "AlgorithmsEvolves candidate \n",
      "models over generations \n",
      "by evolutionary \n",
      "inspired operators of \n",
      "mutation and crossover \n",
      "of parameters.Increasing the generation size adds diversity \n",
      "in considering parameter combinations, but \n",
      "requires more objective function evaluation. \n",
      "Calculating individuals within a generation \n",
      "is strongly parallelizable. Representation of \n",
      "candidate solutions can impact performance.De Jong, Kenneth A. Evolutionary \n",
      "Computation - A Uniﬁed \n",
      "Approach. Massachusetts: \n",
      "MIT Press, 2002. Print.\n",
      "Grid SearchSystematic search across \n",
      "discrete parameter \n",
      "values for parameter \n",
      "exploration problems.A grid across the parameters is used to \n",
      "visualize the parameter landscape and assess \n",
      "whether multiple minima are present.Kolda, Tamara G., Robert M. \n",
      "Lewis, and Virginia Torczon. \n",
      "“Optimization by Direct \n",
      "Search: New Perspectives on \n",
      "Some Classical and Modern \n",
      "Methods.” SIAM Review. Society \n",
      "for Industrial and Applied \n",
      "Mathematics, 2003. Print.\n",
      "Hidden Markov \n",
      "ModelsModels sequential data by \n",
      "determining the discrete \n",
      "latent variables, but \n",
      "the observables may be \n",
      "continuous or discrete.One of the most powerful properties of Hidden \n",
      "Markov Models is their ability to exhibit \n",
      "some degree of invariance to local warping \n",
      "(compression and stretching) of the time axis. \n",
      "However, a signiﬁcant weakness of the Hidden \n",
      "Markov Model is the way in which it represents \n",
      "the distribution of times for which the system \n",
      "remains in a given state.Bishop, Christopher M. Pattern \n",
      "Recognition and Machine \n",
      "Learning.  New York: Springer, \n",
      "2006. Print.\n",
      "Hierarchical \n",
      "ClusteringConnectivity based \n",
      "clustering approach \n",
      "that sequentially builds \n",
      "bigger (agglomerative) \n",
      "or smaller (divisive) \n",
      "clusters in the data.Provides views of clusters at multiple \n",
      "resolutions of closeness. Algorithms \n",
      "begin to slow for larger datasets due \n",
      "to most implementations exhibiting \n",
      "O(N3) or O(N2) complexity.Rui Xu, and Don Wunsch. \n",
      "Clustering. New Jersey: Wiley-\n",
      "IEEE Press, 2008. Print.\n",
      "K-means \n",
      "and X-means \n",
      "ClusteringCentroid based clustering \n",
      "algorithms, where with \n",
      "K means the number \n",
      "of clusters is set and X \n",
      "means the number of \n",
      "clusters is unknown.When applying clustering techniques, make \n",
      "sure to understand the shape of your data. \n",
      "Clustering techniques will return poor results if \n",
      "your data is not circular or ellipsoidal shaped.Rui Xu, and Don Wunsch. \n",
      "Clustering. New Jersey: Wiley-\n",
      "IEEE Press, 2008. Print.\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Compiled by: Booz Allen HamiltonTechnique Description Tips From the ProsReferences we  \n",
      "love to read\n",
      "Linear, \n",
      "Non-linear, \n",
      "and Integer \n",
      "ProgrammingSet of techniques for \n",
      "minimizing or maximizing a \n",
      "function over a constrained \n",
      "set of input parameters.Start with linear programs because algorithms \n",
      "for integer and non-linear variables can take \n",
      "much longer to run.Winston, Wayne L. Operations \n",
      "Research: Applications and \n",
      "Algorithms.  Connecticut: \n",
      "Cengage Learning, 2003. Print.\n",
      "Markov Chain \n",
      "Monte Carlo \n",
      "(MCMC)A method of sampling \n",
      "typically used in Bayesian \n",
      "models to estimate the joint \n",
      "distribution of parameters \n",
      "given the data. Problems that are intractable using analytic \n",
      "approaches can become tractable using MCMC, \n",
      "when even considering high-dimensional \n",
      "problems. The tractability is a result of using \n",
      "statistics on the underlying distributions of \n",
      "interest, namely, sampling with Monte Carlo and \n",
      "considering the stochastic sequential process of \n",
      "Markov Chains.Andrieu, Christophe, Nando \n",
      "de Freitas, Amaud Doucet, \n",
      "and Michael I. Jordan. “An \n",
      "Introduction to MCMC for \n",
      "Machine Learning.” Machine \n",
      "Learning. Kluwer Academic \n",
      "Publishers, 2003. Print. \n",
      "Monte Carlo \n",
      "MethodsSet of computational \n",
      "techniques to generate \n",
      "random numbers.Particularly useful for numerical integration, \n",
      "solutions of differential equations, computing \n",
      "Bayesian posteriors, and high dimensional \n",
      "multivariate sampling.Fishman, George S. Monte \n",
      "Carlo: Concepts, Algorithms, and \n",
      "Applications. New York: Springer, \n",
      "2003. Print.\n",
      "Naïve BayesPredicts classes following \n",
      "Bayes Theorem that \n",
      "states the probability of \n",
      "an outcome given a set of \n",
      "features is based on the \n",
      "probability of features given \n",
      "an outcome.Assumes that all variables are independent, \n",
      "so it can have issues learning in the context of \n",
      "highly interdependent variables. The model can \n",
      "be learned on a single pass of data using simple \n",
      "counts and therefore is useful in determining \n",
      "whether exploitable patterns exist in large \n",
      "datasets with minimal development time.Ingersoll, Grant S., Thomas S. \n",
      "Morton, and Andrew L. Farris. \n",
      "Taming Text: How to Find, \n",
      "Organize, and Manipulate It.  New \n",
      "Jersey: Manning, 2013. Print.\n",
      "Neural \n",
      "NetworksLearns salient features in \n",
      "data by adjusting weights \n",
      "between nodes through a \n",
      "learning rule.Training a neural network takes substantially \n",
      "longer than evaluating new data with an already \n",
      "trained network. Sparser network connectivity \n",
      "can help to segment the input space and \n",
      "improve performance on classiﬁcation tasks.Haykin, Simon O. Neural \n",
      "Networks and Learning \n",
      "Machines. New Jersey: \n",
      "Prentice Hall, 2008. Print.\n",
      "Outlier \n",
      "RemovalMethod for identifying and \n",
      "removing noise or artifacts \n",
      "from data.Be cautious when removing outliers. Sometimes \n",
      "the most interesting behavior of a system is at \n",
      "times when there are aberrant data points.Maimon, Oded, and Lior \n",
      "Rockach. Data Mining and \n",
      "Knowledge Discovery Handbook:  \n",
      "A Complete Guide for Practitioners \n",
      "and Researchers.  The \n",
      "Netherlands: Kluwer Academic \n",
      "Publishers, 2005. Print.\n",
      "Principal \n",
      "Components \n",
      "AnalysisEnables dimensionality \n",
      "reduction by identifying \n",
      "highly correlated \n",
      "dimensions.Many large datasets contain correlations \n",
      "between dimensions; therefore part of the \n",
      "dataset is redundant. When analyzing the \n",
      "resulting principal components, rank order \n",
      "them by variance as this is the highest \n",
      "information view of your data. Use skree plots to \n",
      "infer the optimal number of components.Wallisch, Pascal, Michael E. \n",
      "Lusignan, Marc D. Benayoun, \n",
      "Tanya I. Baker, Adam Seth \n",
      "Dickey, and Nicholas G. \n",
      "Hatsopoulos. Matlab for \n",
      "Neuroscientists.  New Jersey: \n",
      "Prentice Hall, 2009. Print.\n",
      "Random \n",
      "SearchRandomly adjust \n",
      "parameters to ﬁnd a  \n",
      "better solution than \n",
      "currently found.Use as a benchmark for how well a search \n",
      "algorithm is performing. Be careful to use a \n",
      "good random number generator and new seed.Bergstra J. and Bengio Y. \n",
      "Random Search for Hyper-\n",
      "Parameter Optimization, \n",
      "Journal of Machine Learning \n",
      "Research 13, 2012.\n",
      "Regression \n",
      "with Shrinkage \n",
      "(Lasso)A method of variable \n",
      "selection and prediction \n",
      "combined into a possibly \n",
      "biased linear model. There are different methods to select the \n",
      "lambda parameter. A typical choice is cross \n",
      "validation with MSE as the metric. Tibshirani, Robert. “Regression \n",
      "Shrinkage and Selection via the \n",
      "Lasso.” Journal of the Royal \n",
      "Statistical Society. Series B \n",
      "(Methodological). Toronto: Royal \n",
      "Statistical Society, 1996. Print.\n",
      "Sensitivity \n",
      "AnalysisInvolves testing individual \n",
      "parameters in an analytic \n",
      "or model and observing the \n",
      "magnitude of the effect.Insensitive model parameters during an \n",
      "optimization are candidates for being set to \n",
      "constants. This reduces the dimensionality \n",
      "of optimization problems and provides an \n",
      "opportunity for speed up.Saltelli, A., Marco Ratto, Terry \n",
      "Andres, Francesca Campolongo, \n",
      "Jessica Cariboni, Debora Gatelli, \n",
      "Michaela Saisana, and Stefano \n",
      "Tarantola. Global Sensitivity \n",
      "Analysis: the Primer .  New Jersey: \n",
      "John Wiley & Sons, 2008. Print.\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "81 Take off the Training Wheels\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Compiled by: Booz Allen HamiltonTechnique Description Tips From the ProsReferences we  \n",
      "love to read\n",
      "Simulated \n",
      "AnnealingNamed after a controlled \n",
      "cooling process in \n",
      "metallurgy, and by \n",
      "analogy using a changing \n",
      "temperature or annealing \n",
      "schedule to vary \n",
      "algorithmic convergence.The standard annealing function allows for \n",
      "initial wide exploration of the parameter space \n",
      "followed by a narrower search. Depending on \n",
      "the search priority the annealing function can \n",
      "be modiﬁed to allow for longer explorative \n",
      "search at a high temperature.Bertsimas, Dimitris, and John \n",
      "Tsitsiklis. “Simulated Annealing.” \n",
      "Statistical Science. 1993. Print.\n",
      "Stepwise \n",
      "RegressionA method of variable \n",
      "selection and prediction. \n",
      "Akaike's information \n",
      "criterion AIC is used as \n",
      "the metric for selection. \n",
      "The resulting predictive \n",
      "model is based upon \n",
      "ordinary least squares, \n",
      "or a general linear model \n",
      "with parameter estimation \n",
      "via maximum likelihood. Caution must be used when considering \n",
      "Stepwise Regression, as over ﬁtting often \n",
      "occurs. To mitigate over ﬁtting try to limit the \n",
      "number of free variables used.Hocking, R.R. “The Analysis  \n",
      "and Selection of Variables in \n",
      "Linear Regression.” Biometrics. \n",
      "1976. Print.\n",
      "Stochastic \n",
      "Gradient \n",
      "DescentGeneral-purpose \n",
      "optimization for learning of \n",
      "neural networks, support \n",
      "vector machines, and \n",
      "logistic regression models.Applied in cases where the objective \n",
      "function is not completely differentiable \n",
      "when using sub-gradients.Witten, Ian H., Eibe Frank, \n",
      "and Mark A. Hall. Data Mining: \n",
      "Practical Machine Learning Tools \n",
      "and Techniques. Massachusetts: \n",
      "Morgan Kaufmann, 2011. Print.\n",
      "Support Vector \n",
      "MachinesProjection of feature vectors \n",
      "using a kernel function into \n",
      "a space where classes are \n",
      "more separable.Try multiple kernels and use k-fold cross \n",
      "validation to validate the choice of the best one.Hsu, Chih-Wei, Chih-Chung \n",
      "Chang, and Chih-Jen Lin. “A \n",
      "Practical Guide to Support Vector \n",
      "Classiﬁcation.” National Taiwan \n",
      "University Press, 2003. Print.\n",
      "Term \n",
      "Frequency \n",
      "Inverse \n",
      "Document \n",
      "FrequencyA statistic that measures \n",
      "the relative importance of a \n",
      "term from a corpus.Typically used in text mining. Assuming a \n",
      "corpus of news articles, a term that is very \n",
      "frequent such as “the” will likely appear many \n",
      "times in many documents, having a low value. A \n",
      "term that is infrequent such as a person’s last \n",
      "name that appears in a single article will have a \n",
      "higher TD IDF score.Ingersoll, Grant S., Thomas S. \n",
      "Morton, and Andrew L. Farris. \n",
      "Taming Text: How to Find, \n",
      "Organize, and Manipulate It. New \n",
      "Jersey: Manning, 2013. Print.\n",
      "Topic Modeling \n",
      "(Latent \n",
      "Dirichlet \n",
      "Allocation)Identiﬁes latent topics \n",
      "in text by examining \n",
      "word co-occurrence.Employ part-of-speech tagging to eliminate \n",
      "words other than nouns and verbs. Use raw \n",
      "term counts instead of TF/IDF weighted terms.Blei, David M., Andrew Y. Ng, \n",
      "and Michael I. Jordan. “Latent \n",
      "Dirichlet Allocation.” Journal \n",
      "of Machine Learning Research. \n",
      "2003. Print.\n",
      "Tree Based \n",
      "MethodsModels structured as graph \n",
      "trees where branches \n",
      "indicate decisions.Can be used to systematize a process or act as \n",
      "a classiﬁer.James, G., D. Witten, T. Hastie, \n",
      "and R. Tibshirani. “Tree Based \n",
      "Methods.” An Introduction to \n",
      "Statistical Learning. New York: \n",
      "Springer, 2013. Print.\n",
      "T-TestHypothesis test used to  \n",
      "test for differences between \n",
      "two groups.Make sure you meet the tests assumptions and \n",
      "watch out for Family Wise error when running \n",
      "multiple tests.Bhattacharyya, Gouri K., and \n",
      "Richard A. Johnson. Statistical \n",
      "Concepts and Models. Wiley, \n",
      "1977. Print.\n",
      "Wrapper \n",
      "MethodsFeature set reduction \n",
      "method that utilizes \n",
      "performance of a set of \n",
      "features on a model, as \n",
      "a measure of the feature \n",
      "set’s performance. Can \n",
      "help identify combinations \n",
      "of features in models that \n",
      "achieve high performance.Utilize k-fold cross validation \n",
      "to control over ﬁtting.John, George H., Ron \n",
      "Kohavi, and Karl Pﬂeger. \n",
      "“Irrelevant Features and the \n",
      "Subset Selection Problem.” \n",
      "Proceedings of ICML-94, 11th \n",
      "International Converence \n",
      "on Machine Learning. New \n",
      "Brunswick, New Jersey. 1994. \n",
      "Conference  Presentation.\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "LIFE in    THE TRENCHES\n",
      "NAVIGATING NECK DEEP IN DATA\n",
      "Our Data Science experts have learned \n",
      "and developed new solutions over the years \n",
      "from properly framing or reframing analytic \n",
      "questions. In this section, we list a few \n",
      "important topics to Data Science coupled \n",
      "with firsthand experience from our experts.\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Going Deep into  \n",
      "Machine Learning\n",
      "Machines are getting better at learning by mimicking the \n",
      "human brain.\n",
      "Think about where you were 10 years ago. Could computers understand \n",
      "and take action based upon your spoken word? Recently, speech-to-text \n",
      "quality has improved dramatically to nearly perfect accuracy, much to \n",
      "the delight of many mobile phone users. In other complex tasks, similar \n",
      "magic capabilities have emerged. The world-record high scores in 29 \n",
      "video games are now held by a machine learning algorithm with no \n",
      "specific knowledge of Atari or computer games in general.\n",
      "These impressive feats were made possible by deep learning, a different \n",
      "way of approaching machine learning problems. Most approaches to \n",
      "machine learning require humans to encode logic and rules to create \n",
      "features, which are then fed into machine learning models. In some \n",
      "domains, such as audio, text, image, and signal processing, effective \n",
      "feature engineering requires considerable human expertise to achieve \n",
      "decent model performance. Deep learning avoids the necessity \n",
      "of human-encoded features and instead incorporates the feature \n",
      "engineering, feature selection, and model fitting into one step.\n",
      "Deep learning is an extension of an idea originating in the \n",
      "1950s called neural networks, which are loosely inspired by our \n",
      "understanding of how neurons in our brains operate. Recent \n",
      "hardware developments, originally designed for faster renderings \n",
      "of graphics, birthed a renaissance in neural networks. The latest \n",
      "graphical processing units, or GPUs, have more than 3,000 processing \n",
      "cores that are well suited for parallel processing of complex matrix \n",
      "manipulations required for rendering graphics – and for executing \n",
      "computations on neural networks.\n",
      "In the late 2000s, the combination of GPUs, advances in algorithms, \n",
      "and collections of big data reignited interest in neural networks. GPUs \n",
      "enabled computers to process much larger networks in much less time, \n",
      "and clever advances in algorithms made the model fitting process more \n",
      "efficient. Large collections of image, video, and text data provided \n",
      "content for the deep learning algorithms to learn. The ability to train \n",
      "larger networks with more data drove the exploration of new neural \n",
      "network architectures featuring additional hidden layers and widening \n",
      "the breadth of the networks. \n",
      "Presently, deep learning has moved beyond academic applications and is \n",
      "finding its way into our daily lives. Deep learning powers speech-to-text \n",
      "on our mobile phones and smart devices, image search provided by major \n",
      "tech companies, language translation services for text and spoken word, \n",
      "and even drug discovery within advanced pharmaceutical companies. \n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "››\n",
      "Aaron Sander\n",
      "National Data Science Bowl\n",
      "The ﬁrst-ever National Data Science Bowl offered Data Scientists \n",
      "a platform through which individuals could harness their passion, \n",
      "unleash their curiosity and amplify their impact to affect change \n",
      "on a global scale. The competition presented participants with \n",
      "more than 100,000 underwater images provided by the Hatﬁeld \n",
      "Marine Science Center. Participants were challenged to develop a \n",
      "classiﬁcation algorithm that would enable researchers to monitor \n",
      "ocean health at a speed and scale never before possible. \n",
      "More than 1,000 teams submitted a  \n",
      "total of approximately 15,000 solutions \n",
      "over the 90 days of the competition.  \n",
      "A large proportion of the participants’ \n",
      "implemented solutions used deep \n",
      "learning-based approaches, speciﬁcally \n",
      "Convolutional Neural Nets (CNNs). \n",
      "The competition forum exploded \n",
      "with competitors collectively sharing \n",
      "knowledge and collaborating to advance \n",
      "the state-of-the-art in computer vision. \n",
      "Participants tested new techniques \n",
      "for developing CNNs and contributed \n",
      "to the development of open source \n",
      "software for creating CNN models. \n",
      "The top three competitors, Team Deep Sea , Happy Lantern Festival, \n",
      "and Poisson Process, all used CNNs \n",
      "in their solutions. Their results \n",
      "increased algorithm accuracy by 10% \n",
      "over the state of the art. Without their \n",
      "algorithms, it would have taken marine \n",
      "researchers more than two lifetimes to \n",
      "manually complete the classiﬁcation \n",
      "process. The work submitted by all \n",
      "the participants represents major \n",
      "advances for both the marine research \n",
      "and Data Science communities. \n",
      "INPUT LAYER HIDDEN LAYER\n",
      "OUTPUT\n",
      "LAYER\n",
      "A Representation of Deep Learning Source: Booz Allen Hamilton  »Visit www.DataScienceBowl.com \n",
      "to learn more about the first-ever \n",
      "National Data Science Bowl\n",
      "87 Life in the Trenches\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Feature Engineering\n",
      "Feature engineering is a lot like oxygen. You can’t do without \n",
      "it, but you rarely give it much thought. \n",
      "Feature engineering is the process by which one establishes the \n",
      "representation of data in the context of an analytic approach. It is the \n",
      "foundational skill in Data Science. Without feature engineering, it \n",
      "would not be possible to understand and represent the world through \n",
      "a mathematical model. Feature engineering is a challenging art. Like \n",
      "other arts, it is a creative process that manifests uniquely in each \n",
      "Data Scientist. It will be influenced substantially by the scientist’s \n",
      "experiences, tastes and understanding of the field. \n",
      "When faced with the problem of feature engineering, there are \n",
      "several paths that one may initially take. Generally speaking, better \n",
      "features can be developed with more knowledge of the domain. One \n",
      "approach to feature engineering is to begin by describing smaller \n",
      "elements of the domain and continuously constructing more intricate \n",
      "features as the model becomes more complex. These more complicated \n",
      "features can be defined by considering other attributes of the domain, \n",
      "aggregating features together into different groups or using advanced \n",
      "statistical and mathematical techniques to devise new features. The \n",
      "ultimate judge in this process is the performance of the machine \n",
      "learning algorithm which makes decisions based on this feature vector.\n",
      "Consider the example of email spam classification. Because the \n",
      "domain is a set of emails, one possible choice of an initial feature \n",
      "vector is the integer array that counts the number of times a \n",
      "given word appears in the email. This is called the \"bag of words\" \n",
      "assumption, where the order that words appear in a text is ignored.  \n",
      "If an algorithm with this feature vector does not adequately \n",
      "distinguish between spam and non-spam emails, a feature could  \n",
      "be added that counts the number of misspelled words in the text.  \n",
      "This new feature uses the spam recognition domain knowledge that \n",
      "asserts many spam emails misspell words. These misspelled words  \n",
      "alert filters saying that the existence of certain words automatically \n",
      "label an email as spam. If this new feature is not enough, there are  \n",
      "still additional features to be considered such as whether or not a  \n",
      "first or last name is used in the email.\n",
      "Feature engineering represents a complex, but crucial aspect of Data \n",
      "Science. The Learning Optimal Features sidebar goes into detail about \n",
      "feature learning – an automated approach to feature engineering that \n",
      "applies machine learning techniques.  »What differentiates a great \n",
      "model from a bad one? \n",
      "In most cases, the inputs to the model \n",
      "matter even more than the choice \n",
      "of the algorithm. The traditional \n",
      "approach has a two-step process \n",
      "where heuristics and subject-matter \n",
      "expertise are used to ﬁnd a good set of \n",
      "features, and then algorithms optimize \n",
      "model parameters. Deep learning \n",
      "combines these steps into one. \n",
      "Feature engineering, feature selection, \n",
      "and model parameter estimation \n",
      "are accomplished simultaneously. \n",
      "This reduces the need for highly-\n",
      "specialized domain knowledge and \n",
      "often results in better models.\n",
      "For example, in the context of images \n",
      "from the natural world, deep networks \n",
      "may learn low-level features such as \n",
      "lines at various angles and curved \n",
      "lines. Middle layers may combine the \n",
      "lower-level features into more complex \n",
      "geometric shapes and patterns. \n",
      "Higher-level layers combine the mid-\n",
      "level features into more complicated \n",
      "features that begin to resemble faces \n",
      "and shapes of animals. Applied to \n",
      "other types of data, such as audio \n",
      "and text, deep neural networks learn \n",
      "increasingly sophisticated features \n",
      "at each layer in a similar manner.\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "››\n",
      "Ed Kohlwey\n",
      "Chemoinformatic Search\n",
      "On one assignment, my \n",
      "team was confronted \n",
      "with the challenge of \n",
      "developing a search \n",
      "engine over chemical \n",
      "compounds. The goal \n",
      "of chemoinformatic \n",
      "search is to predict \n",
      "the properties that \n",
      "a molecule will exhibit as well as to \n",
      "provide indices over those predicted \n",
      "properties to facilitate data discovery \n",
      "in chemistry-based research. These \n",
      "properties may either be discreet (e.g., \n",
      "“a molecule treats disease x well”) \n",
      "or continuous (e.g., “a molecule may \n",
      "be dissolved up to 100.21 g/ml”).\n",
      "Molecules are complex 3D structures, \n",
      "which are typically represented as \n",
      "a list of atoms joined by chemical \n",
      "bonds of differing lengths with varying \n",
      "electron domain and molecular \n",
      "geometries. The structures are \n",
      "speciﬁed by the 3-space coordinates \n",
      "and the electrostatic potential \n",
      "surface of the atoms in the molecule. \n",
      "Searching this data is a daunting \n",
      "task when one considers that \n",
      "naïve approaches to the problem \n",
      "bear signiﬁcant semblance to the \n",
      "Graph Isomorphism Problem.[15]\n",
      "The solution we developed was \n",
      "based on previous work in molecular \n",
      "ﬁngerprinting (sometimes also called \n",
      "hashing or locality sensitive hashing). \n",
      "Fingerprinting is a dimensionality \n",
      "reduction technique that dramatically \n",
      "reduces the problem space by \n",
      "summarizing many features, often \n",
      "with relatively little regard to the \n",
      "importance of the feature. When \n",
      "an exact solution is likely to be \n",
      "infeasible, we often turn to heuristic \n",
      "approaches such as ﬁngerprinting.\n",
      "Our approach used a training set \n",
      "where all the measured properties of the molecules were available. We \n",
      "created a model of how molecular \n",
      "structural similarities might affect \n",
      "their properties. We began by \n",
      "ﬁnding all the sub-graphs of each \n",
      "molecule with length n, resulting \n",
      "in a representation similar to \n",
      "the bag-of-words approach from \n",
      "natural language processing. \n",
      "We summarized each molecule \n",
      "fragment in a type of ﬁngerprint \n",
      "called a “Counting Bloom Filter.”\n",
      "Next, we used several exemplars from \n",
      "the set to create new features. We \n",
      "found the distance from each member \n",
      "of the full training set to each of the \n",
      "exemplars. We fed these features into \n",
      "a non-linear regression algorithm \n",
      "to yield a model that could be used \n",
      "on data that was not in the original \n",
      "training set. This approach can be \n",
      "conceptualized as a “hidden manifold,” \n",
      "whereby a hidden surface or shape \n",
      "deﬁnes how a molecule will exhibit a \n",
      "property. We approximate this shape \n",
      "using a non-linear regression and a \n",
      "set of data with known properties. \n",
      "Once we have the approximate \n",
      "shape, we can use it to predict the \n",
      "properties of new molecules. \n",
      "Our approach was multi-staged and \n",
      "complex – we generated sub-graphs, \n",
      "created bloom ﬁlters, calculated \n",
      "distance metrics and ﬁt a linear-\n",
      "regression model. This example \n",
      "provides an illustration of how many \n",
      "stages may be involved in producing a \n",
      "sophisticated feature representation. \n",
      "By creatively combining and building \n",
      "“features on features,” we were able \n",
      "to create new representations of data \n",
      "that were richer and more descriptive, \n",
      "yet were able to execute faster and \n",
      "produce better results. \n",
      "89 Life in the Trenches\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Feature Selection\n",
      "Models are like honored guests; you should only feed them the \n",
      "good parts.\n",
      "Feature selection is the process of determining the set of features with \n",
      "the highest information value to the model. Two main approaches are \n",
      "filtering and wrapper methods. Filtering methods analyze features \n",
      "using a test statistic and eliminate redundant or non-informative \n",
      "features. As an example, a filtering method could eliminate features \n",
      "that have little correlation to the class labels. Wrapper methods \n",
      "utilize a classification model as part of feature selection. A model is \n",
      "trained on a set of features and the classification accuracy is used to \n",
      "measure the information value of the feature set. One example is that \n",
      "of training a neural network with a set of features and evaluating the \n",
      "accuracy of the model. If the model scores highly on the test set, then \n",
      "the features have high information value. All possible combinations of \n",
      "features are tested to find the best feature set. \n",
      "There are tradeoffs between these techniques. Filtering methods \n",
      "are faster to compute since each feature only needs to be compared \n",
      "against its class label. Wrapper methods, on the other hand, evaluate \n",
      "feature sets by constructing models and measuring performance.  \n",
      "This requires a large number of models to be trained and evaluated  \n",
      "(a quantity that grows exponentially in the number of features).  \n",
      "Why would anyone use a wrapper method? Feature sets may perform \n",
      "better than individual features.[16] With filter methods, a feature \n",
      "with weak correlation to its class labels is eliminated. Some of \n",
      "these eliminated features, however, may have performed well when \n",
      "combined with other features.\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "››\n",
      "Paul Yacci\n",
      "Cancer Cell Classiﬁcation\n",
      "On one project, \n",
      "our team was \n",
      "challenged \n",
      "to classify \n",
      "cancer cell \n",
      "proﬁles. The \n",
      "overarching \n",
      "goal was \n",
      "to classify different types \n",
      "of Leukemia, based on \n",
      "Microarray proﬁles from 72 \n",
      "samples[17] using a small \n",
      "set of features. We utilized \n",
      "a hybrid Artiﬁcial Neural \n",
      "Network (ANN)[18] and Genetic \n",
      "Algorithm[19] to identify subsets \n",
      "of 10 features selected from \n",
      "thousands.[20] We trained the \n",
      "ANN and tested performance \n",
      "using cross-fold validation. \n",
      "The performance measure was used as feedback into \n",
      "the Genetic Algorithm. When \n",
      "a set of features contained \n",
      "no useful information, the \n",
      "model performed poorly and \n",
      "a different feature set would \n",
      "be explored. Over time, this \n",
      "method selected a set of \n",
      "features that performed with \n",
      "high accuracy. The down-\n",
      "selected feature set increased \n",
      "speed and performance as \n",
      "well as allowed for better \n",
      "insight into the factors that \n",
      "may govern the system. This \n",
      "allowed our team to design \n",
      "a diagnostic test for only a \n",
      "few genetic markers instead \n",
      "of thousands, substantially \n",
      "reducing diagnostic test \n",
      "complexity and cost.\n",
      "91 Life in the Trenches\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Ensemble Models\n",
      "None of us is as smart as all of us, but some are smarter  \n",
      "than others.\n",
      "In 1906, Sir Francis Galton attended a fair at which there was a \n",
      "contest to guess the weight of an ox. Galton had the idea to collect the \n",
      "guesses of the 787 entrants and compute the mean. To his surprise, \n",
      "the mean was only one pound off from the ox’s real weight of 1,198 \n",
      "pounds. Together, the estimates made by many amateurs formed a \n",
      "prediction that was more accurate than that of individual experts. \n",
      "Galton’s “wisdom of crowds” extends to Data Science in the form of \n",
      "ensemble learning, which is colloquially and somewhat equivalently \n",
      "called ensembling, blending, or stacking. An ensemble takes the \n",
      "predictions of many individual models and combines them to \n",
      "make a single prediction. Like the people guessing the ox’s weight, \n",
      "Data Science models have unique strengths and weaknesses (i.e., \n",
      "determined by their design), and are influenced by varied perspectives \n",
      "based on past experience (i.e., the data they have observed). \n",
      "Ensembles overcome individual weaknesses to make predictions with \n",
      "more accuracy than their constituent models. These models need not \n",
      "stem from different methodologies; an ensemble might employ the \n",
      "same method with different parameters or weights (e.g., boosting), \n",
      "feature subsets (e.g., random forests), or sub-samples of data (e.g., \n",
      "bagging). The ensembling methodology may be as simple as averaging \n",
      "two outputs, or as complex as using a “meta model” to learn an \n",
      "optimal combination. \n",
      "An ensemble’s ability to reduce individual errors arises from the \n",
      "diversity of its members. If one model over fits the data, it is balanced \n",
      "by a different model that under fits the data. If one subset is skewed \n",
      "by outlier values, another subset is included without them. If one \n",
      "method is unstable to noisy inputs, it is bolstered by another method \n",
      "that is more robust. \n",
      "In practice, ensembling typically improves a model by a few percent. \n",
      "The price of this accuracy is paid in complexity. The accuracy vs. \n",
      "complexity tradeoff can make it difficult to know when ensembling \n",
      "is justified. On one hand, ensembles appear to be a fit for high-stakes \n",
      "problems—think detecting cancer in MRI images vs. detecting \n",
      "unripe blueberries on a conveyer belt. On the other hand, high-stakes \n",
      "problems mandate higher standards for auditing model functionality. \n",
      "The Data Scientist must manage a balance between ensemble \n",
      "interpretability and black-box complexity. If this seems easy, it isn’t! \n",
      "Put yourself in the driver’s seat of the machine learning code for a \n",
      "self-driving car. If a well-behaved regression model makes a right \n",
      "decision 99.5% of the time, but a complex, less-explainable ensemble \n",
      "is right 99.8% of the time, which would you pick? \n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "››\n",
      "Will Cukierski\n",
      "The Value of  \n",
      "Ensemble Models\n",
      "Several years ago, the Kaggle Photo Quality Prediction  \n",
      "competition posed the question “Given anonymized information \n",
      "on thousands of photo albums, predict whether a human \n",
      "evaluator would mark them as 'good'.” Participants were \n",
      "supplied a large collection of user-generated photos. The goal \n",
      "was to create an algorithm that could automatically pick out \n",
      "particularly enjoyable or impressive photos from the collection.Log likelihood (lower is better)Final Team Rank\n",
      "      Ensemble\n",
      "      Private Leaderboard\n",
      "Rank=1\n",
      "Value of Ensembling for the Kaggle Photo Quality Prediction Competition  \n",
      "(results courtesy of Ben Hamner, Kaggle CTO)\n",
      "The-blue line shows the individual scores \n",
      "for each of the top 50 teams. The orange \n",
      "line shows the ensembled score for the top \n",
      "n teams, where n ranges from 1 to the value \n",
      "on the axis. For example, the ensemble point \n",
      "for Final Team Rank 5 is an ensemble of the \n",
      "entries for teams 1 through 5. As shown in \n",
      "the graph, the ensembled score is lower than \n",
      "any single individual score. The diversity of \n",
      "models included within the ensemble causes \n",
      "the respective errors to cancel out, resulting \n",
      "in an overall lower score. This holds true for all points across the top 50 teams. However, \n",
      "after we increase the number of models in \n",
      "the ensemble beyond 15, we begin to see \n",
      "the ensembled score increase. This occurs \n",
      "because we are introducing less accurate (i.e., \n",
      "potentially overﬁt) models into the ensemble. \n",
      "The results of this simple experiment quantify \n",
      "the value of creating an ensemble model, while \n",
      "reinforcing the idea that we must be thoughtful \n",
      "when selecting the individual models contained \n",
      "within the ensemble.Over the course of the competition, 207 people submitted entries. The log likelihood metric was \n",
      "used to evaluate the accuracy of the entries. Scores for the top 50 teams ranged from 0.18434 to \n",
      "0.19884, where lower is better . Kaggle data scientist Ben Hamner used the results to illustrate the \n",
      "value of ensembling by means of averaging the top 50 scores. The ﬁgure below shows the results.\n",
      "93 Life in the Trenches\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Data Veracity\n",
      "We’re Data Scientists, not data alchemists. We can’t make \n",
      "analytic gold from the lead of data.\n",
      "While most people associate data volume, velocity, and variety with \n",
      "big data, there is an equally important yet often overlooked dimension \n",
      "– data veracity. Data veracity refers to the overall quality and \n",
      "correctness of the data. You must assess the truthfulness and accuracy \n",
      "of the data as well as identify missing or incomplete information. As \n",
      "the saying goes, “Garbage in, garbage out.” If your data is inaccurate or \n",
      "missing information, you can’t hope to make analytic gold.\n",
      "Assessing data truthfulness is often subjective. You must rely on your \n",
      "experience and an understanding of the data origins and context. \n",
      "Domain expertise is particularly critical for the latter. Although data \n",
      "accuracy assessment may also be subjective, there are times when \n",
      "quantitative methods may be used. You may be able to re-sample from \n",
      "the population and conduct a statistical comparison against the stored \n",
      "values, thereby providing measures of accuracy.\n",
      "The most common issues you will encounter are missing or \n",
      "incomplete information. There are two basic strategies for dealing \n",
      "with missing values – deletion and imputation. In the former, entire \n",
      "observations are excluded from analysis, reducing sample size and \n",
      "potentially introducing bias. Imputation, or replacement of missing \n",
      "or erroneous values, uses a variety of techniques such as random \n",
      "sampling (hot deck imputation) or replacement using the mean, \n",
      "statistical distributions or models. »Tips From the Pros\n",
      "Find an approach that works, \n",
      "implement it, and move on. You \n",
      "can worry about optimization and \n",
      "tuning your approaches later during \n",
      "incremental improvement.\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Brian Keller››\n",
      "Time Series Modeling \n",
      "On one of our projects, the team was faced with correlating the time \n",
      "series for various parameters. Our initial analysis revealed that the \n",
      "correlations were almost non-existent. We examined the data and \n",
      "quickly discovered data veracity issues. There were missing and \n",
      "null values, as well as negative-value observations, an impossibility \n",
      "given the context of the measurements (see the ﬁgure, Time Series \n",
      "Data Prior to Cleansing ). Garbage data meant garbage results. \n",
      "Because sample size was already small, deleting \n",
      "observations was undesirable. The volatile nature \n",
      "of the time series meant that imputation through \n",
      "sampling could not be trusted to produce values \n",
      "in which the team would be conﬁdent. As a result, \n",
      "we quickly realized that the best strategy was an \n",
      "approach that could ﬁlter and correct the noise in  \n",
      "the data. \n",
      "We initially tried a simplistic approach in which we \n",
      "replaced each observation with a moving average. \n",
      "While this corrected some noise, including the \n",
      "outlier values in our moving-average computation \n",
      "shifted the time series. This caused undesirable distortion in the underlying signal, and we quickly \n",
      "abandoned the approach.\n",
      "One of our team members who had experience in \n",
      "signal processing suggested a median ﬁlter. The \n",
      "median ﬁlter is a windowing technique that moves \n",
      "through the data point-by-point, and replaces it \n",
      "with the median value calculated for the current \n",
      "window. We experimented with various window \n",
      "sizes to achieve an acceptable tradeoff between \n",
      "smoothing noise and smoothing away signal. The \n",
      "ﬁgure, Time Series Data After Cleansing , shows the \n",
      "same two time series after median ﬁlter imputation. \n",
      "The application of the median ﬁlter approach was \n",
      "hugely successful. Visual inspection of the time \n",
      "series plots reveals smoothing of the outliers \n",
      "without dampening the naturally occurring peaks \n",
      "and troughs (no signal loss). Prior to smoothing, \n",
      "we saw no correlation in our data, but afterwards, \n",
      "Spearman’s Rho was ~0.5 for almost all parameters. By addressing our data veracity issues, we were \n",
      "able to create analytic gold. While other approaches \n",
      "may also have been effective, implementation speed \n",
      "constraints prevented us from doing any further \n",
      "analysis. We achieved the success we were after and \n",
      "moved on to address other aspects of the problem. Time Series Data Prior to Cleansing\n",
      "Time Series Data After Cleansing Source: Booz Allen Hamilton \n",
      " Source: Booz Allen Hamilton \n",
      "Brian Keller››\n",
      "Time Series Modeling \n",
      "On one of our projects, the team was faced with correlating the time \n",
      "series for various parameters. Our initial analysis revealed that the \n",
      "correlations were almost non-existent. We examined the data and \n",
      "quickly discovered data veracity issues. There were missing and \n",
      "null values, as well as negative-value observations, an impossibility \n",
      "given the context of the measurements (see the ﬁgure, Time Series \n",
      "Data Prior to Cleansing ). Garbage data meant garbage results. \n",
      "Because sample size was already small, deleting \n",
      "observations was undesirable. The volatile nature \n",
      "of the time series meant that imputation through \n",
      "sampling could not be trusted to produce values \n",
      "in which the team would be conﬁdent. As a result, \n",
      "we quickly realized that the best strategy was an \n",
      "approach that could ﬁlter and correct the noise in  \n",
      "the data. \n",
      "We initially tried a simplistic approach in which we \n",
      "replaced each observation with a moving average. \n",
      "While this corrected some noise, including the \n",
      "outlier values in our moving-average computation \n",
      "shifted the time series. This caused undesirable distortion in the underlying signal, and we quickly \n",
      "abandoned the approach.\n",
      "One of our team members who had experience in \n",
      "signal processing suggested a median ﬁlter. The \n",
      "median ﬁlter is a windowing technique that moves \n",
      "through the data point-by-point, and replaces it \n",
      "with the median value calculated for the current \n",
      "window. We experimented with various window \n",
      "sizes to achieve an acceptable tradeoff between \n",
      "smoothing noise and smoothing away signal. The \n",
      "ﬁgure, Time Series Data After Cleansing , shows the \n",
      "same two time series after median ﬁlter imputation. \n",
      "The application of the median ﬁlter approach was \n",
      "hugely successful. Visual inspection of the time \n",
      "series plots reveals smoothing of the outliers \n",
      "without dampening the naturally occurring peaks \n",
      "and troughs (no signal loss). Prior to smoothing, \n",
      "we saw no correlation in our data, but afterwards, \n",
      "Spearman’s Rho was ~0.5 for almost all parameters. By addressing our data veracity issues, we were \n",
      "able to create analytic gold. While other approaches \n",
      "may also have been effective, implementation speed \n",
      "constraints prevented us from doing any further \n",
      "analysis. We achieved the success we were after and \n",
      "moved on to address other aspects of the problem. Time Series Data Prior to Cleansing\n",
      "Time Series Data After Cleansing Source: Booz Allen Hamilton \n",
      " Source: Booz Allen Hamilton \n",
      "95 Life in the Trenches\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Application of  \n",
      "Domain Knowledge \n",
      "We are all special in our own way. Don’t discount what  \n",
      "you know.\n",
      "Knowledge of the domain in which a problem lies is immensely \n",
      "valuable and irreplaceable. It provides an in-depth understanding  \n",
      "of your data and the factors influencing your analytic goal. Many \n",
      "times domain knowledge is a key differentiator to a Data Science \n",
      "team’s success. Domain knowledge influences how we engineer and \n",
      "select features, impute data, choose an algorithm, and determine \n",
      "success. One person cannot possibly be a domain expert in every  \n",
      "field, however. We rely on our team, other analysts and domain  \n",
      "experts as well as consult research papers and publications to build  \n",
      "an understanding of the domain. \n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "››\n",
      "GEOSPATIAL HOTSPOTS\n",
      "TEMPORAL HOTSPOT\n",
      "Sun\n",
      "Sat\n",
      "Fri\n",
      "Thu\n",
      "Wed\n",
      "Tue\n",
      "Mon\n",
      "9pm 6pm 3pm Noon 9am 6am 3am9pm 6pm 3pm Noon 9am 6am 3am\n",
      "Armen \n",
      "Kherlopian\n",
      "Motor Vehicle Theft\n",
      "On one project, \n",
      "our team explored \n",
      "how Data Science \n",
      "could be applied to \n",
      "improve public safety. \n",
      "According to the \n",
      "FBI, approximately \n",
      "$8 Billion is lost \n",
      "annually due to \n",
      "automobile theft. Recovery of the \n",
      "one million vehicles stolen every \n",
      "year in the U.S. is less than 60%. \n",
      "Dealing with these crimes represents \n",
      "a signiﬁcant investment of law \n",
      "enforcement resources. We wanted \n",
      "to see if we could identify how to \n",
      "reduce auto theft while efﬁciently \n",
      "using law enforcement resources.Our team began by parsing and \n",
      "verifying San Francisco crime data. \n",
      "We enriched stolen car reporting with \n",
      "general city data. After conducting \n",
      "several data experiments across both \n",
      "space and time, three geospatial and \n",
      "one temporal hotspot emerged (see \n",
      "ﬁgure, Geospatial and Temporal Car \n",
      "Theft Hotspots ). The domain expert \n",
      "on the team was able to discern \n",
      "that the primary geospatial hotspot \n",
      "corresponded to an area surrounded \n",
      "by parks. The parks created an urban \n",
      "mountain with a number of over-foot \n",
      "access points that were conducive to \n",
      "car theft. \n",
      "Our team used the temporal hotspot information in tandem with the insights \n",
      "from the domain expert to develop a Monte Carlo model to predict the likelihood \n",
      "of a motor vehicle theft at particular city intersections. By prioritizing the \n",
      "intersections identiﬁed by the model, local governments would have the \n",
      "information necessary to efﬁciently deploy their patrols. Motor vehicle thefts \n",
      "could be reduced and law enforcement resources could be more efﬁciently \n",
      "deployed. The analysis, enabled by domain expertise, yielded actionable insights \n",
      "that could make the streets safer.Geospatial and Temporal Car Theft Hotspots Source: Booz Allen Hamilton \n",
      "97 Life in the Trenches\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "The Curse of \n",
      "Dimensionality\n",
      "There is no magical potion to cure the curse, but there is PCA.\n",
      "The “curse of dimensionality” is one of the most important results \n",
      "in machine learning. Most texts on machine learning mention this \n",
      "phenomenon in the first chapter or two, but it often takes many years \n",
      "of practice to understand its true implications.\n",
      "Classification methods, like most machine learning methods, are \n",
      "subject to the implications of the curse of dimensionality. The basic \n",
      "intuition in this case is that as the number of data dimensions \n",
      "increases, it becomes more difficult to create generalizable \n",
      "classification models (models that apply well over phenomena not \n",
      "observed in the training set). This difficulty is usually impossible to \n",
      "overcome in real world settings. There are some exceptions in domains \n",
      "where things happen to work out, but usually you must work to \n",
      "minimize the number of dimensions. This requires a combination \n",
      "of clever feature engineering and use of dimensionality reduction \n",
      "techniques (see Feature Engineering and Feature Selection  Life in the \n",
      "Trenches ). In our practical experience, the maximum  \n",
      "number of dimensions seems to be ~10 for linear model-based \n",
      "approaches. The limit seems to be in the tens of thousands for more \n",
      "sophisticated methods such as support vector machines, but the limit \n",
      "still exists nonetheless.\n",
      "A counterintuitive consequence of the curse of dimensionality is  \n",
      "that it limits the amount of data needed to train a classification  \n",
      "model. There are roughly two reasons for this phenomenon. In one \n",
      "case, the dimensionality is small enough that the model can be  \n",
      "trained on a single machine. In the other case, the exponentially \n",
      "expanding complexity of a high-dimensionality problem makes it \n",
      "(practically) computationally impossible to train a model. In our \n",
      "experience, it is quite rare for a problem to fall in a “sweet spot” \n",
      "between these two extremes. \n",
      "Rather than trying to create super-scalable algorithm \n",
      "implementations, focus your attention on solving your immediate \n",
      "problems with basic methods. Wait until you encounter a problem \n",
      "where an algorithm fails to converge or provides poor cross-validated \n",
      "results, and then seek new approaches. Only when you find that \n",
      "alternate approaches don’t already exist, should you begin building \n",
      "new implementations. The expected cost of this work pattern is lower \n",
      "than over-engineering right out of the gate. \n",
      "Put otherwise, “Keep it simple, stupid”.\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Baking the Cake \n",
      "I was once given a time series set of roughly \n",
      "1,600 predictor variables and 16 target variables \n",
      "and asked to implement a number of modeling \n",
      "techniques to predict the target variable \n",
      "values. The client was challenged to handle the \n",
      "complexity associated with the large number of \n",
      "variables and needed help. Not only did I have \n",
      "a case of the curse, but the predictor variables \n",
      "were also quite diverse. At ﬁrst glance, it looked \n",
      "like trying to bake a cake with everything in the cupboard.  \n",
      "That is not a good way to bake or to make predictions! \n",
      "The data diversity could be \n",
      "partially explained by the fact \n",
      "that the time series predictors \n",
      "did not all have the same \n",
      "periodicity. The target time \n",
      "series were all daily values \n",
      "whereas the predictors were \n",
      "daily, weekly, quarterly, and \n",
      "monthly. This was tricky to \n",
      "sort out, given that imputing \n",
      "zeros isn’t likely to produce \n",
      "good results. For this speciﬁc \n",
      "reason, I chose to use neural \n",
      "networks for evaluating the \n",
      "weekly variable contributions. Using this approach, I was \n",
      "able to condition upon week, \n",
      "without greatly increasing \n",
      "the dimensionality. For the \n",
      "other predictors, I used \n",
      "a variety of techniques, \n",
      "including projection and \n",
      "correlation, to make heads \n",
      "or tails of the predictors. My \n",
      "approach successfully reduced \n",
      "the number of variables, \n",
      "accomplishing the client’s goal \n",
      "of making the problem space \n",
      "tractable. As a result, the cake \n",
      "turned out just ﬁne.››\n",
      "Stephanie \n",
      "Rivera\n",
      "99 Life in the Trenches\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Model Validation\n",
      "Repeating what you just heard does not mean that you  \n",
      "learned anything. \n",
      "Model validation is central to construction of any model. This answers \n",
      "the question “How well did my hypothesis fit the observed data?”\n",
      "If we do not have enough data, our models cannot connect the dots. \n",
      "On the other hand, given too much data the model cannot think \n",
      "outside of the box. The model learns specific details about the training \n",
      "data that do not generalize to the population. This is the problem of \n",
      "model over fitting. \n",
      "Many techniques exist to combat model over fitting. The simplest \n",
      "method is to split your dataset into training, testing and validation \n",
      "sets. The training data is used to construct the model. The model \n",
      "constructed with the training data is then evaluated with the testing \n",
      "data. The performance of the model against the testing set is used to \n",
      "further reduce model error. This indirectly includes the testing data \n",
      "within model construction, helping to reduce model over fit. Finally, \n",
      "the model is evaluated on the validation data to assess how well the \n",
      "model generalizes.\n",
      "A few methods where the data is split into training and testing sets \n",
      "include: k-fold cross-validation, Leave-One-Out cross-validation, \n",
      "bootstrap methods, and resampling methods. Leave-One-Out cross-\n",
      "validation can be used to get a sense of ideal model performance \n",
      "over the training set. A sample is selected from the data to act as the \n",
      "testing sample and the model is trained on the rest of the data. The \n",
      "error on the test sample is calculated and saved, and the sample is \n",
      "returned to the dataset. A different sample is then selected and the \n",
      "process is repeated. This continues until all samples in the testing set \n",
      "have been used. The average error over the testing examples gives a \n",
      "measure of the model’s error.\n",
      "There are other approaches for testing how well your hypothesis \n",
      "reflects the data. Statistical methods such as calculating the coefficient \n",
      "of determination, commonly called the R-squared value are used to \n",
      "identify how much variation in the data your model explains. Note \n",
      "that as the dimensionality of your feature space grows, the R-squared \n",
      "value also grows. An adjusted R-squared value compensates for this \n",
      "phenomenon by including a penalty for model complexity. When \n",
      "testing the significance of the regression as a whole, the F-test \n",
      "compares the explained variance to unexplained variance. A regression \n",
      "result with a high F-statistic and an adjusted R-squared over 0.7 is \n",
      "almost surely significant. »Do we really need a case study \n",
      "to know that you should  \n",
      "check your work?\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "PUTTING  it    ALL TOGETHER\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Streamlining Medication Review \n",
      "Analytic Challenge\n",
      "The U.S. Food and Drug Administration (FDA) is responsible for advancing public \n",
      "health by supporting the delivery of new treatments to patients; assessing the safety, \n",
      "efﬁcacy and quality of regulated products; and conducting \n",
      "research to drive medical innovation. Although the FDA \n",
      "houses one of the world’s largest repositories of regulatory \n",
      "and scientiﬁc data, reviewers are not able to easily leverage \n",
      "data-driven approaches and analytics methods to extract \n",
      "information, detect signals and uncover trends to enhance \n",
      "regulatory decision-making and protect public health. In \n",
      "addition, a rapid increase in the volume, velocity and variety \n",
      "of data that must be analyzed to address and respond to \n",
      "regulatory challenges, combined with variances in data \n",
      "standards, formats, and quality, severely limit the ability \n",
      "of FDA Center for Drug Evaluation and Research (CDER) \n",
      "regulatory scientists to conduct cross-study, cross-product, \n",
      "retrospective, and meta-analysis during product reviews.\n",
      "Booz Allen Hamilton was engaged to research, develop, \n",
      "and evaluate emerging informatics tools, methods, and \n",
      "techniques to determine their ability to address regulatory \n",
      "challenges faced by the FDA Center for Drug Evaluation \n",
      "and Research (CDER). The main goal was to enable the CDER community to fully \n",
      "utilize the agency’s expansive data resources for efﬁcient and effective drug review \n",
      "through the design and development of informatics capabilities based on Natural \n",
      "Language Processing (NLP), data integration, and data visualization methodologies.\n",
      "Our Approach\n",
      "To support transformational change \n",
      "at CDER, we designed and developed \n",
      "a set of informatics prototypes for \n",
      "the analysis and modeling of complex \n",
      "structured, unstructured, and \n",
      "fragmented datasets. We developed \n",
      "multiple prototypes to enable the \n",
      "evaluation of emerging informatics \n",
      "tools, methods, and techniques and \n",
      "their ability to enable a critical-value \n",
      "driver – e.g., co-locate complex, \n",
      "heterogeneous data to identify patterns \n",
      "and foster development of strategies \n",
      "to protect public health. For example, \n",
      "we implemented NLP algorithms \n",
      "to compare adverse events across datasets, and geographic visualization \n",
      "capabilities to support the inspection of \n",
      "pharmaceutical manufacturing facilities. \n",
      "Product Safety Analytics. The review, \n",
      "surveillance, and analysis of adverse \n",
      "events throughout the product lifecycle \n",
      "require signiﬁcant resources. The ability \n",
      "to identify actionable insights that lead \n",
      "to informed decision-making requires \n",
      "signiﬁcant investment of effort, including \n",
      "the active and passive surveillance \n",
      "of adverse events. To address these \n",
      "challenges, we developed a Product \n",
      "Safety Dashboard that compares adverse \n",
      "events listed in the product label (i.e., ››\n",
      " » Our Case Studies\n",
      "Hey, we have given you a lot of \n",
      "really good technical content. We \n",
      "know that this section has the look \n",
      "and feel of marketing material, \n",
      "but there is still a really good story \n",
      "here. Remember, storytelling comes \n",
      "in many forms and styles, one of \n",
      "which is the marketing version. You \n",
      "should read this chapter for what it \n",
      "is – great information told with a \n",
      "marketing voice. \n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "package inserts) with data from the \n",
      "FDA Adverse Event Reporting System \n",
      "(FAERS). Using NLP, we extracted \n",
      "adverse events from the product label \n",
      "to create a structured table of label \n",
      "data out of unstructured text. This \n",
      "dashboard allows safety evaluators to \n",
      "view whether or not a reported adverse \n",
      "event is already known, without having \n",
      "to access an external data source \n",
      "and read through product labels.\n",
      "Product Quality Analytics.   \n",
      "To support CDER’s mission of reviewing \n",
      "and managing product quality, novel \n",
      "methodologies and tools are needed \n",
      "to improve the efﬁciency and efﬁcacy of the product quality-review process. \n",
      "Integration of disparate data sources is \n",
      "the ﬁrst step in building a comprehensive \n",
      "proﬁle of manufacturers, facilities, and \n",
      "the products associated with individual \n",
      "facilities. To address these challenges, \n",
      "we developed a Facility Inventory Report \n",
      "to show the geographic location of \n",
      "facilities and their associated metadata. \n",
      "This geovisualization tool processes and \n",
      "transforms raw data into a user-friendly \n",
      "visual interface with mapping features \n",
      "to enhance the surveillance capabilities \n",
      "of CDER and provide reviewers with the \n",
      "ability to establish connections between \n",
      "facility data and product quality.\n",
      "Our Impact\n",
      "Since the FDA is responsible for regulating 25 cents of every dollar that Americans \n",
      "spend, the agency’s ability to fully use regulatory datasets and meaningfully integrate \n",
      "previously incompatible data to rapidly detect product quality and safety issues is \n",
      "critical for safeguarding public health. NLP approaches provide CDER with the ability \n",
      "to more efﬁciently search a broader range of textual data and enhances the ability to \n",
      "gain insight from additional data forms that may seem unrelated. Data integration \n",
      "and visualization directly increase the efﬁciency of researchers by reducing their time \n",
      "spent on searching for frequently-performed aggregate or granular calculations, \n",
      "and by proactively presenting the most frequently desired data to the reviewer \n",
      "through thoughtful and contextual dashboards designed to reveal patterns and \n",
      "trends in disparate data sources. These new capabilities position the FDA to enhance \n",
      "regulatory decision-making, drive advances in personalized medicine, and enable \n",
      "earlier detection of safety signals in the general population. \n",
      "105 Putting it all Together\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Reducing Flight Delays\n",
      "Analytic Challenge\n",
      "Domestic airline departure delays are estimated to cost the U.S. economy $32.9 billion \n",
      "annually. The Federal Aviation Administration’s (FAA’s) Trafﬁc Flow Management \n",
      "System (TFMS) is used to strategically manage ﬂights and includes a ﬂight departure-\n",
      "delay prediction engine which applies simple heuristics to predict ﬂight delays.\n",
      "However , the limited predictive power of these heuristics constrains the FAA’s ability \n",
      "to act in accordance with its existing departure-delay management plan. In response, \n",
      "the FAA’s NextGen Advanced Concepts and Technology Development Group wanted to \n",
      "create a predictive probabilistic model to improve aircraft departure time predictions. \n",
      "This new model would help the FAA understand the causes of departure delays and \n",
      "develop policies and actions to improve the reliability of departure time predictions for \n",
      "real-time air trafﬁc ﬂow management.\n",
      "Our Approach\n",
      "The commercial aviation industry is rich \n",
      "in ﬂight operations data, much of which \n",
      "is publicly available through government \n",
      "websites and a few subscription \n",
      "vendors. Booz Allen Hamilton leveraged \n",
      "these sources to gather over 4 TB of \n",
      "data detailing tarmac and airspace \n",
      "congestion, weather conditions, network \n",
      "effects, Trafﬁc Management Initiatives, \n",
      "and airline and aircraft-speciﬁc \n",
      "attributes for every commercial ﬂight \n",
      "departing from U.S. airports between \n",
      "2008 and 2012. This data included over 50 \n",
      "million ﬂights and around 100 variables \n",
      "for each ﬂight. The data included \n",
      "composite variables (e.g. incoming ﬂight \n",
      "delay) that were constructed from the \n",
      "raw data to capture relevant dynamics \n",
      "of ﬂight operations. Data acquisition, \n",
      "processing, quality control, and accuracy \n",
      "between disparate datasets were \n",
      "important steps during this process. \n",
      "The team applied supervised learning \n",
      "algorithms to develop Bayesian Belief \n",
      "Network (BBN) models to predict ﬂight departure deviation. The most critical \n",
      "steps in model development were the \n",
      "selection of optimal algorithms to \n",
      "discretize model variables, and the \n",
      "selection of appropriate machine learning \n",
      "techniques to learn the model from the \n",
      "data. The team followed information \n",
      "theory principles to discretize model \n",
      "variables to maximize the model’s \n",
      "predictive power, and to represent the \n",
      "data as closely as possible with the \n",
      "least amount of network complexity. \n",
      "Booz Allen segmented the model \n",
      "variables into three different categories \n",
      "based on the time to ﬂight departure: \n",
      "24 hours, 11 hours, and one hour. \n",
      "Certain ﬂight variables could only \n",
      "be known for speciﬁc pre-departure \n",
      "times. For example, the tarmac and \n",
      "airspace congestion variables for \n",
      "a ﬂight are only known just before \n",
      "the ﬂight, and hence those variables \n",
      "feature only in the one hour category. \n",
      "Departure delays were predicted for \n",
      "each of the three time horizons. ››\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Our Impact\n",
      "For a typical airport, the model delivers a delay prediction improvement of between \n",
      "100,000 and 500,000 minutes annually over previous FAA predictions. The model can \n",
      "be used by a range of aviation stakeholders, such as airlines, to better understand \n",
      "and predict network ﬂight delays. This can improve the airlines’ operational decisions \n",
      "to include more proactive schedule adjustments during times of disruption (e.g. \n",
      "weather or sector load). The improved reliability of departure prediction will improve \n",
      "FAA's predictions for airports, sectors, and other resources, and has the potential to \n",
      "enable improved real-time trafﬁc ﬂow management, which can signiﬁcantly reduce \n",
      "airline departure, delays, and the associated economic costs. This means a more \n",
      "efﬁcient and effective air transportation network.\n",
      "107 Putting it all Together\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Making Vaccines Safer  \n",
      "Analytic Challenge\n",
      "The U.S. Food and Drug Administration (FDA) Center for Biologics Evaluation and \n",
      "Research (CBER) is responsible for protecting public health by assuring the safety \n",
      "and efﬁcacy of biologics, including vaccines, blood and blood products. CBER’s \n",
      "current surveillance process, which requires resource-intensive manual review by \n",
      "expert Medical Ofﬁcers, does not scale well to short-term workload variation and \n",
      "limits long-term improvements in review cycle-time. In addition, the large volume of \n",
      "Adverse Event (AE) reports received by the Agency makes it difﬁcult for reviewers to \n",
      "compare safety issues across products and patient populations. \n",
      "CBER engaged Booz Allen Hamilton to develop advanced analytics approaches for \n",
      "the triage and analysis of AE reports. The main goal was to leverage (1) Natural \n",
      "Language Processing (NLP) to alleviate resource pressures by semi-automating \n",
      "some of the manual review steps through techniques, such as text classiﬁcation \n",
      "and entity extraction, and (2) network visualizations to offer alternative interactions \n",
      "with datasets and support AE pattern recognition. By integrating NLP and network \n",
      "analysis capabilities into the Medical Ofﬁcer’s review process, Booz Allen successfully \n",
      "provided decision-makers with important information concerning product risks and \n",
      "possible mitigations that can reduce risk.\n",
      "Our Approach\n",
      "We designed and developed a set \n",
      "of prototypes for the analysis and \n",
      "visualization of complex structured \n",
      "and unstructured AE datasets. We \n",
      "developed tools that leverage NLP \n",
      "and network analysis to extend and \n",
      "enhance CBER’s efforts to monitor the \n",
      "safety of biologics and manage safety \n",
      "throughout the product lifecycle. \n",
      "Adverse Event Text Mining Analytics. \n",
      "Reviewing AE reports involves sorting \n",
      "based on the likelihood of a relationship \n",
      "between a product and reported adverse \n",
      "events. Since much of an AE report is \n",
      "unstructured text, and most reports \n",
      "are not directly related to the use of \n",
      "the implicated biologic, manual review \n",
      "is time consuming and inefﬁcient. To \n",
      "address these challenges, we enhanced \n",
      "and integrated tools for text mining \n",
      "and NLP of AE reports using open \n",
      "source tools, including Python and R. By extracting diagnosis, cause of death, and \n",
      "time to onset, and presenting relevant \n",
      "information for review, the text-mining \n",
      "tool streamlines and enhances the post \n",
      "market surveillance process.\n",
      "Adverse Event Network Analytics. \n",
      "Visualizing relationships between \n",
      "vaccines and AEs can reveal new \n",
      "patterns and trends in the data, leading \n",
      "reviewers to uncover safety issues. \n",
      "To assist CBER Medical Ofﬁcers and \n",
      "researchers in identifying instances \n",
      "where certain vaccines or combinations \n",
      "of vaccines might have harmful \n",
      "effects on patients, we developed an \n",
      "AE network analysis tool using open \n",
      "source tools. This network analyzer \n",
      "allows users to select partitions of the \n",
      "FDA Vaccine Adverse Event Reporting \n",
      "System (VAERS) database, generate a \n",
      "co-occurrence matrix, view networks \n",
      "and network metrics (e.g., betweenness, ››\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "closeness, degree, strength), and \n",
      "interact with network nodes to gain \n",
      "insights into product safety issues.\n",
      "Other Analytics Solutions.  In addition, \n",
      "Booz Allen refactored, modularized, \n",
      "and expended the capabilities of CBER’s \n",
      "computer simulation model of the Bovine \n",
      "Spongiform Encephalopathy (BSE) \n",
      "agent to improve estimates of variant \n",
      "Creutzfeldt-Jakob disease (vCJD) risk \n",
      "for blood products, developed code to handle large amounts of data generated \n",
      "by a Monte Carlo Markov Chain analysis \n",
      "of the spread of inﬂuenza, developed \n",
      "a large database analysis strategy \n",
      "involving the application of classiﬁcation \n",
      "algorithms to simulated genomic data, \n",
      "and implemented a Statistical Analysis \n",
      "Software (SAS) macro that automatically \n",
      "compares the relative potency of a given \n",
      "lot of vaccine using a matched set of dose \n",
      "response curves.  \n",
      "Our Impact\n",
      "New methods for post market surveillance of biologics are critical for FDA reviewers \n",
      "who must determine whether reported adverse events are actually a result of a \n",
      "biologic product. With more than 10 million vaccines administered each year to \n",
      "children less than one-year old, CBER reviewers are under pressure to quickly \n",
      "evaluate potential safety signals through manual evaluation of AE reports, review \n",
      "of scientiﬁc literature, and analysis of cumulative data using frequency calculations \n",
      "or statistical algorithms. Booz Allen’s support resulted in the development \n",
      "of innovative and data-driven approaches for the analysis of structured and \n",
      "unstructured AE reports. We increased the speed of existing text mining tools by \n",
      "two thousand times, allowing CBER reviewers to run a text mining algorithm to \n",
      "extract information contained in VAERS reports in seconds, instead of hours. We \n",
      "also increased the productivity of Medical Ofﬁcers through the implementation \n",
      "of text mining and network analysis tools. These new capabilities allow CBER to \n",
      "streamline the post market review process, extract knowledge from scientiﬁc data, \n",
      "and address public concerns regarding vaccine safety more quickly and efﬁciently.\n",
      "109 Putting it all Together\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Forecasting the Relative Risk \n",
      "for the Onset of Mass Killings to \n",
      "Help Prevent Future Atrocities\n",
      "Analytic Challenge\n",
      "Mass atrocities are rare yet devastating crimes. They are also preventable. Studies \n",
      "of past atrocities show that we can detect early warning signs of atrocities and that \n",
      "if policy makers act on those warnings and develop preventive strategies, we can \n",
      "save lives. Yet despite this awareness, all too often we see warning signs missed and \n",
      "action taken too late, if at all, in response to threats of mass atrocities. \n",
      "The Early Warning Project, an initiative of the United States Holocaust Memorial \n",
      "Museum (Holocaust Museum), aims to assess a country’s level of risk for the onset \n",
      "of future mass killings. Over time, the hope is to learn which models and which \n",
      "indicators are the best at helping anticipate future atrocities to aid in the design and \n",
      "implementation of more targeted and effective preventive strategies. By seeking to \n",
      "understand why and how each countries’ relative level of risk rises and falls over \n",
      "time, the system will deepen understanding of where new policies and resources can \n",
      "help make a difference in averting atrocities and what strategies are most effective. \n",
      "This will arm governments, advocacy groups, and at-risks societies with earlier and \n",
      "more reliable warning, and thus more opportunity to take action, well before mass \n",
      "killings occur.\n",
      "The project’s statistical risk assessment seeks to build statistical and machine \n",
      "learning algorithms to predict the onset of a mass killing in the succeeding 12 months \n",
      "for each country with a population larger than 500,000. The publically available system \n",
      "aggregates and provides access to open source datasets as well as democratizes the \n",
      "source code for analytic approaches developed by the Holocaust Museum staff and \n",
      "consultants, the research community, and the general public. The Holocaust Museum \n",
      "engaged Booz Allen to validate existing approaches as well as explore new and \n",
      "innovative approaches for the statistical risk assessment. \n",
      "Our Approach\n",
      "Taking into account the power of \n",
      "crowdsourcing, Booz Allen put out a call \n",
      "to employees to participate in a hack-a-\n",
      "thon—just the start of the team’s support \n",
      "as the Museum reﬁned and implemented \n",
      "the recommendations. More than 80 \n",
      "Booz Allen Hamilton software engineers, \n",
      "data analysts, and social scientists \n",
      "devoted a Saturday to participate. \n",
      "Interdisciplinary teams spent 12 hours identifying new datasets, building new \n",
      "machine learning models, and creating \n",
      "frameworks for ensemble modeling \n",
      "and interactive results visualization.  \n",
      "Following the hack-a-thon, Booz \n",
      "Allen Data Scientists worked with \n",
      "Holocaust Museum staff to create \n",
      "a data management framework to \n",
      "automate the download, aggregation, \n",
      "and transformation of the open ››\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "source datasets used by the statistical \n",
      "assessment. This extensible \n",
      "framework allows integration of new \n",
      "datasets with minimal effort, thereby supporting greater engagement by \n",
      "the Data Science community. \n",
      "  \n",
      "Our Impact\n",
      "Publically launched in the fall of 2015, the Early Warning Project can now leverage \n",
      "advanced quantitative and qualitative analyses to provide governments, advocacy \n",
      "groups and at-risk societies with assessments regarding the potential for mass \n",
      "atrocities around the world. Integration of the project’s statistical risk assessment \n",
      "models and expert opinion pool created a publicly available source of invaluable \n",
      "information and positioned Data Science at the center of global diplomacy.  \n",
      "The machine learning models developed during the hack-a-thon achieved \n",
      "performance on par with state of the art approaches as well as demonstrated the \n",
      "efﬁcacy of predictions 2-5 years into the future. Teams also identiﬁed approaches for \n",
      "constructing test/validation sets that support more robust model evaluation. These \n",
      "risk assessments are an important technological achievement in and of themselves, \n",
      "but what this initiative means for the Data Science community’s position in global \n",
      "diplomatic dialogue marks an entirely new era for those on the frontiers of Big Data.\n",
      "The data management framework developed from the lessons learned of the hack-\n",
      "a-thon represents a great leap forward for the Holocaust Museum. The periodicity \n",
      "of aggregating and transforming data was reduced from twice per year to once \n",
      "per week. In addition to providing the community with more up-to-date data, the \n",
      "reduced burden on researchers enables them to spend more time analyzing data and \n",
      "identifying new and emergent trends. The extensible framework will also allow the \n",
      "Holocaust Museum to seamlessly integrate new datasets as they become available or \n",
      "are identiﬁed by the community as holding analytic value for the problem at hand. \n",
      "Through this project, the Holocaust Museum was able to shift the dynamic from \n",
      "monitoring ongoing violence to determining where it is likely to occur 12 to 24 months \n",
      "into the future by integrating advanced quantitative and qualitative analyses to assess \n",
      "the potential for mass atrocities around the world. The Early Warning Project is an \n",
      "invaluable predictive resource supporting the global diplomatic dialogue. While the \n",
      "focus of this effort was on the machine learning and data management technologies \n",
      "behind the initiative, it demonstrates the growing role the Data Science community is \n",
      "playing at the center of global diplomatic discussions.\n",
      "111 Putting it all Together\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Predicting Customer Response\n",
      "Analytic Challenge\n",
      "It is very challenging to know how a customer will respond to a given promotional \n",
      "campaign.  Together with the InterContinental Hotels Group (IHG), Booz Allen \n",
      "Hamilton explored approaches to predict customer-by-customer response to a state-\n",
      "of-the-art promotional campaign in order to better understand and increase return on \n",
      "investment (ROI). \n",
      "In the past, conventional statistics have worked well for analyzing the impact of \n",
      "direct marketing promotions on purchase behavior . Today, modern multi-channel \n",
      "promotions often result in datasets that are highly dimensional and sometimes \n",
      "sparse, which strains the power of conventional statistical methods to accurately \n",
      "estimate the effect of a promotion on individual purchase decisions. Because of \n",
      "the growing frequency of multi-channel promotions, IHG was driven to investigate \n",
      "new approaches. In particular , IHG and Booz Allen studied one recent promotional \n",
      "campaign using hotel, stay, and guest data for a group of loyalty program customers.  \n",
      "Our Approach\n",
      "Working closely with IHG experts, Booz Allen investigated three key elements related \n",
      "to different stages of analytic maturity:\n",
      "Describe:  Using initial data mining, what \n",
      "insights or tendencies in guest behaviors \n",
      "can be identiﬁed after joining multiple, \n",
      "disparate datasets?\n",
      "Discover: Can we determine which \n",
      "control group members would be likely to \n",
      "register for a promotion if offered? If so, \n",
      "can we also quantify their registration?\n",
      "Predict: How would a hotel guest that \n",
      "received the promotion have responded \n",
      "if they were not offered the promotion? \n",
      "How would a hotel guest that did not \n",
      "receive the promotion have responded \n",
      "if they were offered the promotion?\n",
      "For the promotion that was the focus \n",
      "of this case study, not everything about \n",
      "customers could be controlled as required \n",
      "by traditional statistics. However , because a probabilistic Bayesian Belief Network \n",
      "(BBN) can learn the pairwise relationships \n",
      "between all individual customer attributes \n",
      "and their impact on promotional \n",
      "return, Booz Allen investigated how \n",
      "this technique could be used to model \n",
      "each treated customer without an exact \n",
      "controlled look-alike.  \n",
      "Speciﬁcally, Booz Allen developed a BBN \n",
      "to predict customer-by-customer impacts \n",
      "driven by promotional campaign offers, \n",
      "subsequently estimating the aggregated \n",
      "ROI of individual campaigns. We used six \n",
      "machine learning techniques (support \n",
      "vector machine, random forest, decision \n",
      "tree, neural network, linear model, and \n",
      "AdaBoost) in unison with the BBN to \n",
      "predict how each customer would be \n",
      "inﬂuenced by a promotional offer.››\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Our Impact\n",
      "The probabilistic model was capable of predicting customer response to the \n",
      "promotion, without relying on a costly control group. This ﬁnding represents millions \n",
      "of dollars of savings per promotional campaign. This analysis is an industry-\n",
      "ﬁrst for the travel and hospitality sector, where demand for more data-driven \n",
      "approaches to optimize marketing ROI at an individual level is rapidly growing.\n",
      "Because Booz Allen and IHG’s approach enabled estimation of ROI for each \n",
      "hypothetical customer, even when no exact look-alikes exist, there are a number \n",
      "of valuable future applications. One such application is optimal campaign design—\n",
      "the ability to estimate the promotional attributes for an individual customer \n",
      "that are likely to drive the greatest incremental spend. Another application is \n",
      "efﬁcient audience selection - which would reduce the risk of marketing “spam” \n",
      "that prompts costly unsubscriptions and can negatively impact a hotel’s brand. \n",
      "113 Putting it all Together\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "CLOSING    TIME\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "THE FUTURE   of   \n",
      "        DATA SCIENCE  \n",
      "Data Science is rapidly evolving as it touches every aspect of our \n",
      "lives on a daily basis. As Data Science changes the way we interact \n",
      "with, and explore our world, the algorithms and applications of \n",
      "Data Science continue to advance. We expect this trend to continue \n",
      "as Data Science has an increasingly profound effect on humanity. \n",
      "We describe here some of the trends and developments we \n",
      "anticipate emerging in the field of Data Science over the coming years. \n",
      "The advancements in some Data Science algorithms will deliberately \n",
      "track the evolution of data structures and data models that Data \n",
      "Scientists are using to represent their domains of study. One of the \n",
      "clearest examples of this linkage is in the development of massive-\n",
      "scale graph analytics algorithms, which are deployed on graph \n",
      "databases (including network data and semantically linked databases) . \n",
      "It is sometimes said “all the world is a graph,” and consequently the \n",
      "most natural data structure is not a table with rows and columns, but \n",
      "a network graph with nodes and edges. Graph analytics encompasses \n",
      "traditional methods of machine learning, but with a graph-data twist.\n",
      "Another growth area in Data Science algorithms is in the domain \n",
      "of geospatial temporal predictive analytics, which can be applied \n",
      "to any dataset that involves geospatial location and time – that \n",
      "describes just about everything in our lives! We expect increasingly \n",
      "sophisticated deployments of this methodology in the areas of law \n",
      "enforcement, climate change, disaster management, population \n",
      "health, sociopolitical change, and more. \n",
      "It is obvious that bigger, faster, and more complex datasets will \n",
      "require faster (hyperfast!) analytics. We anticipate advanced \n",
      "Data Science algorithms that take advantage of technological \n",
      "advancements in quantum machine-learning, in-memory data \n",
      "operations, and machine learning on specialized devices (e.g., \n",
      "the GPU, Raspberry Pi, or the next-generation mobile handheld \n",
      "“supercomputer”).  In such commodity devices, we expect to see \n",
      "development of more embedded machine learning (specifically, deep \n",
      "learning)  algorithms that perform time-critical data-to-insights \n",
      "transformations at the point of data collection. Such use cases will \n",
      "be in great abundance within the emerging Internet of Things  (IoT) , \n",
      "including the industrial IoT and the internet of everything.\n",
      "Advances in cognitive machine learning are on the horizon, \n",
      "including open source and configurable algorithms that exploit \n",
      "streaming real-time data’s full content, context, and semantic \n",
      "meaning. The ability to use the 360-degree view of a situation will \n",
      "enable the delivery of the right action, at the right time, at the right \n",
      "place, in the right context – this is the essence of cognitive analytics. \n",
      "Another way to view cognitive analytics is that, given all of the \n",
      "data and the context for a given object or population, the algorithm \n",
      "identifies the right question that you should be asking of your data \n",
      "(which might not be the question that you traditionally asked) .››\n",
      "Kirk Borne\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "Another area of Data Science evolution that tracks with the growth \n",
      "in a particular data type is that of unstructured data, specifically text. \n",
      "The growth of such unstructured data is phenomenal, and demands \n",
      "richer algorithms than those used on numerical data, since there are \n",
      "many more shades of meaning in natural language than in tables of \n",
      "numbers. The new Data Science algorithms for unstructured data \n",
      "will be applied in multiple directions. Natural Language Generation \n",
      "will be used to convert data points into text, which can be used \n",
      "to generate the data’s story automatically.  Structured Database \n",
      "Generation will transform text documents or other unstructured \n",
      "data into data points (i.e., converting qualitative data into machine-\n",
      "computable quantitative data).\n",
      "All of these technical advancements, plus others that we cannot \n",
      "yet imagine, will be brought to bear on new domains. Some of the \n",
      "hottest, most critical domains in which Data Science will be applied \n",
      "in the coming years include: \n",
      " ›Cybersecurity  including advanced detection, modeling, prediction, and  \n",
      "prescriptive analytics\n",
      " ›Healthcare  including genomics, precision medicine, population health, healthcare \n",
      "delivery, health data sharing and integration, health record mining, and wearable \n",
      "device analytics\n",
      " ›IoT  including sensor analytics, smart data, and emergent discovery alerting and response\n",
      " ›Customer Engagement and Experience  including 360-degree view, gamification, \n",
      "and just-in-time personalization\n",
      " ›Smart X , where X = cities, highways, cars, delivery systems, supply chain, and more\n",
      " ›Precision Y , where Y = medicine, farming, harvesting, manufacturing, pricing, and more\n",
      " ›Personalized Z , where Z = marketing, advertising, healthcare, learning, and more\n",
      " ›Human capital (talent) and organizational analytics\n",
      " ›Societal good\n",
      "THE FUTURE OF\n",
      "DATA SCIENCEAlgorithms Applications\n",
      "› Massive-scale Graph\n",
      "› Geospatial Temporal Predictive Analytics\n",
      "› Hyperfast Analytics\n",
      "› Embedded Deep Learning\n",
      "› Cognitive Machine Learning\n",
      "› Natural Language Generation\n",
      "› Structured Database Generation › Cybersecurity\n",
      "› Healthcare\n",
      "› Internet of Things\n",
      "› Customer Engagement & Experience\n",
      "› Smart Everything\n",
      "› Human Capital\n",
      "› Data for Societal Good \n",
      "117 Closing Time\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "PARTING   \n",
      "THOUGHTS  \n",
      "Data Science capabilities are creating data analytics that are \n",
      "touching every aspect of our lives on a daily basis. From visiting \n",
      "the doctor, to driving our cars, to shopping for services Data \n",
      "Science is quietly changing the way we interactive with and \n",
      "explore our world. We hope we have helped you truly understand \n",
      "the potential of your data and how to become extraordinary \n",
      "thinkers by asking the right questions. We hope we have helped \n",
      "continue to drive forward the science and art of Data Science. \n",
      "Most importantly, we hope you are leaving with a newfound \n",
      "passion and excitement for Data Science.  \n",
      "Thank you for taking this journey with us. Please join our \n",
      "conversation and let your voice be heard. Email us your ideas \n",
      "and perspectives at data_science@bah.com  or submit them \n",
      "via a pull request on the Github repository .  \n",
      " \n",
      "Tell us and the world what you know. Join us. Become an \n",
      "author of this story.››\n",
      "119 Closing Time\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "REFERENCES\n",
      "1. Commonly attributed to: Nye, Bill. Reddit Ask Me Anything  (AMA). \n",
      "July 2012. Web. Accessed 15 October 2013. SSRN: < http://www.reddit.\n",
      "com/r/IAmA/comments/x9pq0/iam_bill_nye_the_science_guy_ama >\n",
      "2. Fayyad, Usama, Gregory Piatetsky-Shapiro, and Padhraic Smyth. “From \n",
      "Data Mining to Knowledge Discovery in Databases.” AI Magazine 17.3 \n",
      "(1996): 37-54. Print.\n",
      "3. “Mining Data for Nuggets of Knowledge.” Knowledge@Wharton ,1999. \n",
      "Web. Accessed 16 October 2013. SSRN: < http://knowledge.wharton.\n",
      "upenn.edu/article/mining-data-for-nuggets-of-knowledge >\n",
      "4. Cleveland, William S. “Data Science: An Action Plan for Expanding \n",
      "the Technical Areas of the Field of Statistics.” International Statistical \n",
      "Review  69.1 (2001): 21-26. Print.\n",
      "5. Davenport, Thomas H., and D.J. Patil. “Data Scientist: The Sexiest Job \n",
      "of the 21st Century.” Harvard Business Review  90.10 (October 2012): \n",
      "70–76. Print.\n",
      "6. Smith, David. “Statistics vs Data Science vs BI.” Revolutions , 15 \n",
      "May 2013. Web. Accessed 15 October 2013. SSRN:< http://blog.\n",
      "revolutionanalytics.com/2013/05/statistics-vs-data-science-vs-bi.html >\n",
      "7. Brynjolfsson, Erik, Lorin M. Hitt, and Heekyung H. Kim. “Strength \n",
      "in Numbers: How Does Data-Driven Decision Making Affect Firm \n",
      "Performance?” Social Science Electronic Publishing , 22 April 2011. Web. \n",
      "Accessed 15 October 2013. SSRN: < http://ssrn.com/abstract=1819486 \n",
      "or http://dx.doi.org/10.2139/ssrn.1819486 >\n",
      "8. “The Stages of an Analytic Enterprise.” Nucleus Research . February 2012. \n",
      "Whitepaper.\n",
      "9. Barua, Anitesh, Deepa Mani, and Rajiv Mukherjee. “Measuring the \n",
      "Business Impacts of Effective Data.” University of Texas . Web. Accessed \n",
      "15 October 2013. SSRNL: < http://www.sybase.com/files/White_Papers/\n",
      "EffectiveDataStudyPt1-MeasuringtheBusinessImpactsofEffectiveDa\n",
      "ta-WP .pdf >\n",
      "10. Zikopoulos, Paul, Dirk deRoos, Kirshnan Parasuraman, Thomas Deutsch, \n",
      "David Corrigan and James Giles. Harness the Power of Big Data: The IBM \n",
      "Big Data Platform . New York: McGraw Hill, 2013. Print. 281pp.››\n",
      "THE FIELD  GUIDE to  DATA  SCIENCE\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "11. Booz Allen Hamilton. Cloud Analytics Playbook . 2013. Web. Accessed 15 \n",
      "October 2013. SSRN: < http://www.boozallen.com/media/file/Cloud-\n",
      "playbook-digital.pdf >\n",
      "12. Conway, Drew. “The Data Science Venn Diagram.” March 2013. \n",
      "Web. Accessed 15 October 2013. SSRN: < http://drewconway.com/\n",
      "zia/2013/3/26/the-data-science-venn-diagram >\n",
      "13. Booz Allen Hamilton. Tips for Building a Data Science Capability . 2015. \n",
      "Web Accessed 2 September 2015. SSRN: < https://www.boozallen.com/\n",
      "content/dam/boozallen/documents/2015/07/DS-Capability-Handbook.pdf >\n",
      "14. Mnih et al. 2015. Human-level control through deep reinforcement \n",
      "learning. Nature. 518: 529-533.\n",
      "15. Torán, Jacobo. “On the Hardness of Graph Isomorphism.” SIAM Journal \n",
      "on Computing . 33.5 (2004): 1093-1108. Print.\n",
      "16. Guyon, Isabelle and Andre Elisseeff. “An Introduction to Variable and \n",
      "Feature Selection.” Journal of Machine Learning Research 3 (March \n",
      "2003):1157-1182. Print.\n",
      "17. Golub T., D. Slonim, P. Tamayo, C. Huard, M. Gaasenbeek, J. Mesirov, \n",
      "H. Coller, M. Loh, J. Downing, M. Caligiuri, C. Bloomfield, and E. \n",
      "Lander. “Molecular Classification of Cancer: Class Discovery and Class \n",
      "Prediction by Gene Expression Monitoring.” Science.  286.5439 (1999): \n",
      "531-537. Print.\n",
      "18. Haykin, Simon O. Neural Networks and Learning Machines . New Jersey: \n",
      "Prentice Hall, 2008. Print.\n",
      "19. De Jong, Kenneth A. Evolutionary Computation - A Unified Approach . \n",
      "Massachusetts: MIT Press, 2002. Print.\n",
      "20. Yacci, Paul, Anne Haake, and Roger Gaborski. “Feature Selection of \n",
      "Microarray Data Using Genetic Algorithms and Artificial Neural \n",
      "Networks.” ANNIE 2009. St Louis, MO. 2-4 November 2009. \n",
      "Conference Presentation.\n",
      "121 Closing Time\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "About  \n",
      "  BOOZ ALLEN    \n",
      "  HAMILTON\n",
      "Booz Allen Hamilton  has been at the forefront of strategy and \n",
      "technology for more than 100 years. Today, the firm provides \n",
      "management and technology consulting and engineering services to \n",
      "leading Fortune 500 corporations, governments, and not-for-profits \n",
      "across the globe. Booz Allen partners with public and private sector \n",
      "clients to solve their most difficult challenges through a combination \n",
      "of consulting, analytics, mission operations, technology, systems \n",
      "delivery, cybersecurity, engineering, and innovation expertise.\n",
      "With international headquarters in McLean, Virginia, the firm \n",
      "employs more than 22,500 people globally, and had revenue of $5.27 \n",
      "billion for the 12 months ended March 31, 2015. To learn more, visit \n",
      "www.boozallen.com . (NYSE: BAH)››\n",
      "123 Closing Time\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Given the following extracted parts of a long document and a question, create a final answer. \n",
      "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
      "______________________\n",
      "Unfortunately, the provided text does not contain any information about the good characteristics for a data science team. The text appears to be the title page of a book or document, and does not provide any relevant information to answer the question.\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as desirable for a data science team:\n",
      "\n",
      "1. \"Curiosity and technical tradecraft\" - implying a strong desire to learn and apply technical skills to solve complex problems.\n",
      "2. \"Radical new ways of thinking about data and the world around us\" - suggesting a willingness to challenge assumptions and think outside the box.\n",
      "3. \"Leadership\" - implying that data scientists should be able to guide and navigate the team through complex challenges.\n",
      "4. \"Practitioners\" - suggesting that data scientists should be hands-on and able to apply their skills to real-world problems.\n",
      "5. \"Passion for Data Science\" - implying a genuine enthusiasm for the field and a desire to share that passion with others.\n",
      "\n",
      "These characteristics are mentioned as essential for navigating the \"new future\" of data science and for creating value through data science.\n",
      "\n",
      "The provided text does not mention data science teams or their characteristics. It appears to be a quote from a motivational or inspirational text, emphasizing the importance of learning from others.\n",
      "\n",
      "According to the provided text, the following characteristics are mentioned as being unique to Booz Allen Hamilton's Data Science team:\n",
      "\n",
      "* Focus on a broad range of problems, rather than a single class of problems\n",
      "* Support for a diverse set of government and commercial clients across various domains\n",
      "* Ability to understand the \"DNA of Data Science\" through their work as consultants\n",
      "\n",
      "These characteristics are presented as being different from other companies that may focus on a single class of problems or have a more limited scope.\n",
      "\n",
      "According to the provided text, the good characteristics for a data science team are:\n",
      "\n",
      "* Recognizing that Data Science is a team sport\n",
      "* Valuing the input of the community\n",
      "* Being open to new ideas and perspectives\n",
      "* Encouraging collaboration and contribution from outside the organization\n",
      "* Embracing a living document that can evolve with technology, expertise, and evolving techniques\n",
      "* Being willing to learn from others and share knowledge\n",
      "* Having a sense of ownership and authorship in the work being done\n",
      "\n",
      "These characteristics are highlighted in the text as essential for advancing the science and art of Data Science, and for creating a collaborative and dynamic environment within a data science team.\n",
      "\n",
      "Unfortunately, the provided text does not explicitly mention the good characteristics for a data science team. However, it does mention the success and popularity of \"The Field Guide to Data Science\" among various groups, including practitioners, educators, academics, and organizational leaders.\n",
      "\n",
      "From this, we can infer that some good characteristics for a data science team might include:\n",
      "\n",
      "* Collaboration: The guide has been used by various groups, indicating a willingness to share knowledge and work together.\n",
      "* Adaptability: The guide has been used in different industries, such as energy, life sciences, and retail, suggesting that the team is able to adapt to different contexts.\n",
      "* Openness to feedback: The guide has been shared and used by many organizations, implying that the team is open to feedback and willing to learn from others.\n",
      "* Continuous learning: The guide has been updated to a second edition, indicating a commitment to ongoing learning and improvement.\n",
      "* Community engagement: The team encourages feedback, encouragement, and success stories, suggesting a strong sense of community and engagement with stakeholders.\n",
      "\n",
      "These characteristics are not explicitly stated in the text, but can be inferred from the context and the tone of the acknowledgement.\n",
      "\n",
      "According to the provided document, the following text is relevant to answer the question:\n",
      "\n",
      "\"Guiding Principles\"\n",
      "\n",
      "This section appears to outline the good characteristics for a data science team. The text reads:\n",
      "\n",
      "\"Guiding Principles\n",
      "\n",
      "The Importance of Reason\n",
      "Component Parts of Data Science\n",
      "Fractal Analytic Model\n",
      "The Analytic Selection Process\n",
      "Guide to Analytic Selection\n",
      "Detailed Table of Analytics\"\n",
      "\n",
      "However, it seems that this section is not fully provided in the given text. The actual guiding principles may be discussed in the surrounding sections or in the full document.\n",
      "\n",
      "According to the provided text, the following characteristics are mentioned as good for a data science team:\n",
      "\n",
      "* Blending art and science to advance one's view of data analytics (Josh Sullivan)\n",
      "* Being part of the journey of evolving data science (Fred Blackburn)\n",
      "* Asking bigger questions, seeing future possibilities, and creating outcomes you desire (Angela Zutavern)\n",
      "* Having a powerful mixture of art and science (Josh Sullivan)\n",
      "* Investing time and energy in data that is difficult to assemble, and finding a way to make it exist if it doesn't (Steve Escaravage)\n",
      "* Having a blend of art, math, code, sweat, and tears (Peter Guerra)\n",
      "* Focusing on execution (Ezmeralda Khalil)\n",
      "\n",
      "These characteristics suggest that a good data science team should be:\n",
      "\n",
      "* Innovative and forward-thinking\n",
      "* Curious and willing to ask big questions\n",
      "* Able to balance creativity and technical skills\n",
      "* Persistent and willing to overcome challenges\n",
      "* Focused on delivering results through execution.\n",
      "\n",
      "According to the provided text, the good characteristics for a data science team are:\n",
      "\n",
      "* Deep curiosity (Stephanie Beben)\n",
      "* Healthy dose of skepticism (Stephanie Beben)\n",
      "* Truth-seekers, not fact-seekers (Alex Cosmas)\n",
      "* Focus on value, not volume (Kirk Borne)\n",
      "* Grit (Brian Keller)\n",
      "* Ability to play with tools, data, and algorithms (Drew Farris)\n",
      "\n",
      "These characteristics suggest that a successful data science team should be curious, skeptical, and focused on finding truth and value in their work, rather than just collecting data or facts. They should also be willing to put in the effort required to solve complex problems and have fun while doing it.\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as good for a data science team:\n",
      "\n",
      "* Dedication and persistence (Stephanie Rivera)\n",
      "* Collaboration and open communication (Aaron Sander)\n",
      "* Creativity and playing with data and algorithms (Charles Glover)\n",
      "* Artistic and scientific approach (Michael Kim)\n",
      "\n",
      "These characteristics suggest that a good data science team should be:\n",
      "\n",
      "* Committed to their work and willing to put in the effort required to achieve their goals\n",
      "* Collaborative and open to sharing ideas and working together\n",
      "* Creative and willing to experiment and try new approaches\n",
      "* Able to balance artistic and scientific aspects of data science\n",
      "\n",
      "Note that these characteristics are not exhaustive, and other important qualities may be necessary for a successful data science team.\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as good for a data science team:\n",
      "\n",
      "* Continuously seeking truth in spite of ambiguity (Armen Kherlopian)\n",
      "* Rigor and insight (Armen Kherlopian)\n",
      "* Being data-driven (Ed Kohlwey)\n",
      "\n",
      "Note that these characteristics are mentioned in the context of individual data scientists, but they can also be applied to a data science team.\n",
      "\n",
      "According to the provided text, the following are good characteristics for a data science team:\n",
      "\n",
      "* A broad view of the organization\n",
      "* Leaders who are key advocates who:\n",
      "\t+ Meet with stakeholders to ferret out the hardest challenges\n",
      "\t+ Locate the data\n",
      "\t+ Connect disparate parts of the business\n",
      "\t+ Gain widespread buy-in\n",
      "\n",
      "These characteristics suggest that a successful data science team should have leaders who are able to collaborate with stakeholders, understand the organization's needs, and facilitate communication and buy-in across different parts of the business.\n",
      "\n",
      "Unfortunately, the provided text does not mention the good characteristics for a data science team. It only provides a brief introduction to data science and a call to action to start learning the basics.\n",
      "\n",
      "Unfortunately, the provided text does not mention the good characteristics for a data science team. It only describes the difficulty of defining what data science is.\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as good characteristics for a data science team:\n",
      "\n",
      "1. Multidisciplinary team: The team should consist of individuals with diverse backgrounds, including computer scientists, mathematicians, and domain experts.\n",
      "2. Ability to produce new insights and analysis paths: A good data science team should be able to generate new and valuable insights from data.\n",
      "3. Breadth of experience: A team with experience working with clients across various domains can provide a unique perspective on data science.\n",
      "\n",
      "These characteristics are mentioned in the context of the author's experience establishing a data science team at Booz Allen in 2010.\n",
      "\n",
      "According to the provided text, the good characteristics for a data science team are:\n",
      "\n",
      "1. Ability to shift between deductive (hypothesis-based) and inductive (pattern-based) reasoning.\n",
      "2. Ability to combine the ability to reason deductively and inductively, creating an environment where models of reality are constantly tested, updated, and improved until better models are found.\n",
      "\n",
      "These characteristics are summarized in the figure, \"The Types of Reason and Their Role in Data Science Tradecraft\", which highlights the importance of both deductive and inductive reasoning in data science.\n",
      "\n",
      "Here is the relevant text:\n",
      "\n",
      "\"Data Science supports and encourages shifting between deductive (hypothesis-based) and inductive (pattern-based) reasoning. This is a fundamental change from traditional analytic approaches. Inductive reasoning and exploratory data analysis provide a means to form or refine hypotheses and discover new analytic paths. In fact, to do the discovery of significant insights that are the hallmark of Data Science, you must have the tradecraft and the interplay between inductive and deductive reasoning.\"\n",
      "\n",
      "According to the provided text, the good characteristics for a data science team are:\n",
      "\n",
      "››Power of Many vs. Ability of One: An entire team provides a common forum for pulling together computer science, mathematics and domain expertise.\n",
      "\n",
      "This suggests that a good data science team should have a diverse range of skills and expertise, including computer science, mathematics, and domain knowledge, and should work together collaboratively to achieve common goals.\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as desirable for organizations that want to succeed in the data economy:\n",
      "\n",
      "* Embracing Data Science to maintain competitiveness in the increasingly data-rich environment\n",
      "* Making informed decisions with real information through the application of Data Science\n",
      "* Being able to access and make use of data at scale\n",
      "* Being able to keep pace with market demands\n",
      "\n",
      "These characteristics suggest that a good data science team should:\n",
      "\n",
      "* Be proactive in adopting Data Science to stay ahead of the competition\n",
      "* Use data-driven insights to inform their decisions\n",
      "* Have the ability to collect, process, and analyze large amounts of data\n",
      "* Be agile and able to adapt quickly to changing market conditions\n",
      "\n",
      "The text also implies that organizations that do not adopt Data Science will struggle to keep pace with the competition, suggesting that a good data science team should be able to help their organization stay competitive in the market.\n",
      "\n",
      "Unfortunately, the provided text does not explicitly mention the good characteristics for a data science team. However, it does provide some statistics and insights on the importance of data science in organizations, which can be relevant to understanding the value of a data science team.\n",
      "\n",
      "If you're looking for characteristics of a successful data science team, I can provide some general guidelines:\n",
      "\n",
      "1. Collaboration: Data science teams should be able to work effectively with stakeholders from various departments, including business, product, and engineering.\n",
      "2. Communication: Clear communication is crucial for data science teams to effectively convey insights and recommendations to non-technical stakeholders.\n",
      "3. Domain expertise: Data science teams should have a deep understanding of the business domain and be able to apply data science techniques to solve real-world problems.\n",
      "4. Technical skills: Data science teams should have a strong foundation in programming languages, data modeling, machine learning, and statistical analysis.\n",
      "5. Creativity: Data science teams should be able to think creatively and come up with innovative solutions to complex problems.\n",
      "6. Iteration and experimentation: Data science teams should be able to iterate quickly and experiment with different approaches to find the best solution.\n",
      "7. Data quality: Data science teams should prioritize data quality and be able to handle messy or incomplete data.\n",
      "8. Business acumen: Data science teams should understand the business goals and be able to develop solutions that align with those goals.\n",
      "\n",
      "These are just some general guidelines, and the specific characteristics of a successful data science team may vary depending on the organization and its goals.\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as good for a data science team:\n",
      "\n",
      "1. **Consolidating data and distilling answers**: Instead of building data silos, a data science team should aim to consolidate data and provide actionable insights.\n",
      "2. **Making maximum use of all available data**: A data science team should strive to utilize all available data to help the organization succeed, rather than leaving opportunities untapped.\n",
      "3. **Transforming data into insights**: Data science teams should transform data into actionable insights that can improve existing processes and drive business value.\n",
      "4. **Incorporating complex interrelationships in data**: Effective data science teams should be able to identify and incorporate complex relationships in data to drive better decision-making.\n",
      "\n",
      "These characteristics suggest that a good data science team should be able to:\n",
      "\n",
      "* Integrate data from various sources\n",
      "* Analyze large amounts of data to identify patterns and trends\n",
      "* Provide actionable insights that drive business value\n",
      "* Improve existing processes and operations\n",
      "* Stay ahead of competitors by leveraging data science to gain insights and drive innovation.\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Given the following extracted parts of a long document and a question, create a final answer. \n",
      "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
      "______________________\n",
      "Unfortunately, the provided text does not mention the good characteristics for a data science team. The text is more focused on introducing the concept of Data Science and simplifying its complexity. If you're looking for information on the characteristics of a good data science team, I'd be happy to provide some general insights or point you in the direction of relevant resources.\n",
      "\n",
      "Based on the provided text, the good characteristics for a data science team are:\n",
      "\n",
      "* Effective: The team analyzes its data with a purpose, aiming to turn data into actions.\n",
      "* Analytical: The team is able to analyze data to gain insights and make informed decisions.\n",
      "* Collaborative: The team works together to achieve common goals, with a focus on converting insights into action.\n",
      "* Adaptable: The team is able to adapt to changing circumstances and challenges.\n",
      "* Innovative: The team is able to think creatively and come up with new solutions.\n",
      "* Data-driven: The team uses data to inform its decisions and actions.\n",
      "* Action-oriented: The team is able to take action based on its insights and analysis.\n",
      "\n",
      "These characteristics are implied by the text, which describes the four key activities of a data science endeavor: Acquire, Prepare, Analyze, and Act.\n",
      "\n",
      "According to the provided text, the good characteristics for a data science team are:\n",
      "\n",
      "* Embracing diversity: Trying to engage and connect to publicly available sources of data that may have relevance to your domain area.\n",
      "* Focusing on the right data: Not collecting all available data, but focusing on the data with the highest ROI for the organization. The data science team can help identify that data.\n",
      "* Striking a balance: Collecting the right amount of data, not too much or too little, and ensuring that it is the data that is needed.\n",
      "\n",
      "These characteristics suggest that a good data science team should be:\n",
      "\n",
      "* Open-minded and willing to explore different sources of data\n",
      "* Strategic and focused on collecting data that will have the greatest impact\n",
      "* Pragmatic and able to balance the need for data with the costs and limitations of collecting and storing it.\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as good for a data science team:\n",
      "\n",
      "* Ability to explore and analyze all the data\n",
      "* Ability to gain insights from new opportunities for analysis and data-driven decision making\n",
      "* Ability to prepare data for analysis using a Data Lake approach, which eliminates the need for expensive and cumbersome data-preparation processes.\n",
      "\n",
      "These characteristics suggest that a good data science team should be able to:\n",
      "\n",
      "* Work with large and complex datasets\n",
      "* Identify new opportunities for analysis and insights\n",
      "* Use innovative approaches to data preparation and analysis\n",
      "* Make data-driven decisions that drive business outcomes.\n",
      "\n",
      "Here is the relevant text:\n",
      "\n",
      "\"When Data Scientists are able to explore and analyze all the data, new opportunities arise for analysis and data-driven decision making. The insights gained from these new opportunities will significantly change the course of action and decisions within an organization. Gaining access to an organization’s complete repository of data, however, requires preparation.\"\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as good for a data science team:\n",
      "\n",
      "* Iterative application of specialized and scalable computational resources and tools to provide relevant insights from exponentially growing data.\n",
      "* Ability to find connections and patterns in data to identify promising opportunities.\n",
      "* Ability to dive into the data lake to discover new connections and patterns, rather than relying on older sampling methods.\n",
      "\n",
      "These characteristics suggest that a good data science team should be able to:\n",
      "\n",
      "* Work iteratively and apply advanced computational resources and tools to analyze large datasets.\n",
      "* Identify meaningful patterns and connections in data to inform business decisions.\n",
      "* Be able to access and analyze large datasets in real-time, rather than relying on sampling methods that may not provide a complete picture.\n",
      "\n",
      "Here is the relevant text:\n",
      "\n",
      "\"The Analyze activity requires the greatest effort of all the activities in a Data Science endeavor. The Data Scientist actually builds the analytics that create value from data. Analytics in this context is an iterative application of specialized and scalable computational resources and tools to provide relevant insights from exponentially growing data. This type of analysis enables real-time understanding of risks and opportunities by evaluating situational, operational and behavioral data.\n",
      "\n",
      "With the totality of data fully accessible in the Data Lake, organizations can use analytics to find the kinds of connections and patterns that point to promising opportunities. This high-speed analytic connection is done within the Data Lake, as opposed to older style sampling methods that could only make use of a narrow slice of the data. In order to understand what was in the lake, you had to bring the data out and study it. Now you can dive into the lake, bringing your analytics to the data.\"\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as good characteristics for a data science team:\n",
      "\n",
      "1. Ability to make sense of the analysis with relatively little up-front training or preparation on the part of the decision maker.\n",
      "2. Ability to make the most meaningful patterns, trends, and exceptions easy to see and interpret.\n",
      "3. Effort to encode quantitative data accurately so the decision maker can accurately interpret and compare the data.\n",
      "4. Clear and compelling logic used to arrive at the finding, with the ability to trace it back through the data.\n",
      "5. Ability to answer real business questions.\n",
      "\n",
      "These characteristics are mentioned in the context of presenting results to decision makers, suggesting that they are important for effective communication and impact.\n",
      "\n",
      "Based on the provided text, it seems that the text is discussing the maturity stages of a Data Science capability within an organization. However, it does not explicitly mention the good characteristics for a data science team.\n",
      "\n",
      "However, I can try to extract some relevant information that might be related to good characteristics for a data science team:\n",
      "\n",
      "* \"Repeat these activities with each new Data Science endeavor\" - This suggests that a good data science team is able to adapt and repeat their processes with each new project or endeavor.\n",
      "* \"Over time, however, the level of effort necessary for each activity will change\" - This implies that a good data science team is able to evolve and improve their processes over time, reducing the effort required for each activity.\n",
      "* \"Assessing the maturity of your Data Science capability calls for a slightly different view\" - This suggests that a good data science team is able to assess and evaluate their own capabilities and processes.\n",
      "\n",
      "It's worth noting that the provided text is more focused on the maturity stages of a Data Science capability within an organization, rather than specific characteristics of a data science team. If you're looking for more information on good characteristics for a data science team, I'd be happy to help you with that!\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as good characteristics for a data science team:\n",
      "\n",
      "1. **Collect**: Focuses on collecting internal or external datasets, gathering relevant data, and aggregating it.\n",
      "2. **Describe**: Enhances or refines raw data, leveraging basic analytic functions such as counts, and seeks to understand the data.\n",
      "3. **Discover**: Identifies hidden relationships or patterns, and seeks to uncover insights from the data.\n",
      "4. **Predict**: Utilizes past observations to predict future observations, and seeks to forecast outcomes.\n",
      "5. **Advise**: Defines possible decisions, optimizes over those decisions, and advises on the best course of action based on the data.\n",
      "\n",
      "These characteristics suggest that a good data science team should be able to:\n",
      "\n",
      "* Collect and aggregate relevant data\n",
      "* Understand and describe the data\n",
      "* Identify patterns and relationships\n",
      "* Make predictions and forecasts\n",
      "* Provide actionable insights and advice\n",
      "\n",
      "These characteristics are mentioned as part of the \"Stages of Data Science Maturity\" and are intended to help organizations advance in their data science capabilities.\n",
      "\n",
      "According to the provided text, the good characteristics for a data science team are:\n",
      "\n",
      "* Having a clear intent to produce an output (Advise)\n",
      "* Having the correct processes, people, culture, and operating model for a robust Data Science capability\n",
      "* Being able to focus on advanced Predict and Advise activities\n",
      "* Having a strong understanding of the questions their Data Science team is trying to answer\n",
      "* Evaluating the questions that will have the largest impact to the business\n",
      "* Having a data product for important factors driving the business\n",
      "* Having an understanding of future conditions\n",
      "* Knowing the best course of action to take for key decisions\n",
      "\n",
      "These characteristics are mentioned in the text as being important for a data science team to operate at the highest levels of maturity, specifically in the Predict and Advise stages.\n",
      "\n",
      "Based on the provided text, the relevant text that discusses good characteristics for a data science team is:\n",
      "\n",
      "\"...building teams and culture... A Data Science capability embeds and operationalizes Data Science across an enterprise such that it can deliver the next level of organizational performance and return on investment. A Data Science capability moves an organization beyond performing pockets of analytics to an enterprise approach that uses analytical insights as part of the normal course of business.\"\n",
      "\n",
      "This text suggests that a good data science team should have a strong culture and be able to embed and operationalize data science across the organization, leading to improved performance and return on investment.\n",
      "\n",
      "According to the provided text, a good data science team should have a diverse set of skills, which are represented by the three overlapping circles in the Data Science Venn Diagram:\n",
      "\n",
      "1. **Computer Science**: Provides the environment in which data-driven hypotheses are tested, and is necessary for data manipulation and processing.\n",
      "2. **Mathematics**: Provides the theoretical structure in which Data Science problems are examined, and a rich background in statistics, geometry, linear algebra, and calculus is important to understand the basis for many algorithms and tools.\n",
      "3. **Domain Expertise**: Contributes to an understanding of what problems actually need to be solved, what kind of data exists in the domain, and how the problem space may be instrumented and measured.\n",
      "\n",
      "The text also emphasizes the importance of building a blended team that covers all three elements of the Data Science Venn Diagram, as it is unlikely to find individuals with expertise across all three areas.\n",
      "\n",
      "According to the provided text, the \"elements\" or \"foundational technical skills\" that are important for a Data Science team are:\n",
      "\n",
      "1. Computer Science (CS)\n",
      "2. Mathematics (M)\n",
      "3. Domain Expertise (DE)\n",
      "\n",
      "These elements are compared to reactants and products in a chemical reaction, and the team's composition must be balanced to meet the skill requirements of the project.\n",
      "\n",
      "According to the provided text, the good characteristics for a data science team are:\n",
      "\n",
      "**Data Science Competency Framework**\n",
      "\n",
      "* **Technical**: Advanced Mathematics; Computer Science; Data Mining and Integration; Database Science; Research Design; Statistical Modeling; Machine Learning; Operations Research; Programming and Scripting\n",
      "* **Data Science Consulting**: Collaboration and Teamwork; Communications; Data Science Consulting; Ethics and Integrity\n",
      "* **Cognitive**: Critical Thinking; Inductive and Deductive Reasoning; Problem Solving\n",
      "* **Personality**: Adaptability/Flexibility; Ambiguity Tolerance; Detail Orientation; Innovation and Creativity; Inquisitiveness; Perseverance; Resilience and Hardiness; Self-Confidence; Work Ethic\n",
      "\n",
      "Additionally, the text mentions **Reach Back Competencies** that complement the foundational clusters, but do not define the core tradecraft or attributes of the Data Science team. These include:\n",
      "\n",
      "* Business Acumen\n",
      "* Data Visualization\n",
      "* Domain Expertise\n",
      "* Program Management\n",
      "\n",
      "According to the provided text, the good characteristics for a data science team are:\n",
      "\n",
      "* Curiosity: the ability to peel apart a problem and examine the interrelationships between data that may appear superficially unrelated.\n",
      "* Creativity: the ability to invent and try new approaches to solving a problem, which often times have never been applied in such a context before.\n",
      "* Focus: the ability to design and test a technique over days and weeks, find it doesn’t work, learn from the failure, and try again.\n",
      "* Attention to Detail: the ability to maintain rigor, and to detect and avoid over-reliance on intuition when examining data.\n",
      "* Flexibility: the willingness to abandon one idea and try a new approach, and the ability to be patient, persistent, and adaptable in the face of setbacks.\n",
      "\n",
      "Additionally, the text mentions that good candidates for a data science team should also have:\n",
      "\n",
      "* A formal background in one of the three foundational technical skills (not specified in the provided text)\n",
      "* Leadership traits and a sense of purpose for the organization\n",
      "\n",
      "It's also emphasized that amazing data scientists can be found in diverse and unexpected places, and that one should not judge a book by its cover or a data scientist by their degree.\n",
      "\n",
      "According to the provided text, the good characteristics for a data science team are:\n",
      "\n",
      "1. Curiosity: Data Scientists are fundamentally curious and imaginative.\n",
      "2. Imagination: Data Scientists should be able to imagine something new and different.\n",
      "3. Trust and transparent communication: Organizations must foster trust and transparent communication across all levels to establish a strong Data Science team.\n",
      "4. Empowerment: Data Scientists should be empowered to participate and contribute to the project.\n",
      "5. Baseline knowledge: All employees need a baseline of Data Science knowledge, starting with a common lexicon, to facilitate productive collaboration and instill confidence.\n",
      "6. Unrelenting curiosity: Data Scientists should have an unrelenting curiosity and imagination, which are fundamental to the success of every Data Science project.\n",
      "\n",
      "These characteristics are mentioned in the text as essential for building a strong Data Science team and for fostering a culture that supports Data Science.\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Given the following extracted parts of a long document and a question, create a final answer. \n",
      "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
      "______________________\n",
      "According to the provided text, the good characteristics for a data science team are:\n",
      "\n",
      "**Centralized Model:**\n",
      "\n",
      "* Greater efficiency with limited Data Science resources\n",
      "* Provides transparency on how organizations will identify and select Data Science projects\n",
      "* Emphasizes portfolio management\n",
      "\n",
      "**Deployed Model:**\n",
      "\n",
      "* Collectively develops knowledge across business units\n",
      "* Central leadership serves as a bridging mechanism for addressing organization-wide issues\n",
      "* Emphasizes conflict management to avoid competing priorities\n",
      "\n",
      "**Diffused Model:**\n",
      "\n",
      "* Can quickly react to high-priority business unit needs\n",
      "* Establishes cross-functional groups that promote organization-wide governance and peer collaboration\n",
      "\n",
      "Note that these characteristics are specific to each operating model, and the best approach may vary depending on the organization's size, complexity, and business drivers.\n",
      "\n",
      "According to the provided text, the four essential qualities for a Data Science prototype are:\n",
      "\n",
      "1. **Organizational Buy-in**: The individuals involved in the prototype must believe in it and be willing to make it successful.\n",
      "2. **Clear ROI**: The ROI of the analytic output must be clearly and convincingly demonstrated for both the project and the organization as a whole.\n",
      "3. **Necessary Data**: The data needed for the prototype must be determined, and its availability, cost, and feasibility must be considered.\n",
      "4. **Limited Complexity and Duration**: The problem addressed by the prototype should strike a balance between being too complex and too easy, aiming for a moderate level of complexity and a limited duration.\n",
      "\n",
      "These qualities are not specifically mentioned as characteristics for a Data Science team, but rather as requirements for a successful Data Science prototype. However, they can be seen as relevant to the team's approach and mindset, as they emphasize the importance of collaboration, clear goals, data availability, and practicality.\n",
      "\n",
      "Unfortunately, the provided text does not mention the good characteristics for a data science team. It appears to be an introduction to a guide on data science, but it does not provide any information on the characteristics of a successful data science team.\n",
      "\n",
      "According to the provided text, the good characteristics for a data science team are:\n",
      "\n",
      "1. **Be willing to fail**: Experimentation is at the core of data science, and failure is an acceptable byproduct of experimentation.\n",
      "2. **Fail often and learn quickly**: Be ready to fail repeatedly and strive to learn from each attempt quickly.\n",
      "3. **Keep the goal in mind**: Periodically step back, contemplate your goal, and evaluate whether your current approach can lead you where you want to go.\n",
      "4. **Dedication and focus lead to success**: Remain dedicated to your analytic goal and focus on the details and insights revealed by the data.\n",
      "5. **Complicated does not equal better**: A simpler approach can often provide the same insight, and it's easier and faster to prototype, implement, and verify.\n",
      "\n",
      "Additionally, the text also provides some tips from the pros:\n",
      "\n",
      "1. **Ruling out a solution is easier than confirming its correctness**: Focus on exploring obvious shortcomings that can quickly disqualify an approach.\n",
      "2. **Don't try to create the ultimate solution first**: Instead, start with a simpler approach and iterate towards a better solution.\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as important for a data science team:\n",
      "\n",
      "1. Ability to shift between deductive (hypothesis-based) and inductive (pattern-based) reasoning.\n",
      "2. Ability to form or refine hypotheses and discover new analytic paths through inductive reasoning and exploratory data analysis.\n",
      "3. Willingness to constantly test, update, and improve models until better models are found.\n",
      "4. Understanding of the difference between correlation and causation, and ability to avoid mistaking correlation for causation.\n",
      "\n",
      "These characteristics suggest that a good data science team should be:\n",
      "\n",
      "* Flexible and able to adapt to different approaches and methods\n",
      "* Curious and willing to explore new ideas and paths\n",
      "* Open to continuous learning and improvement\n",
      "* Critical thinkers who can distinguish between correlation and causation\n",
      "\n",
      "These characteristics are relevant to the question of what makes a good data science team.\n",
      "\n",
      "Based on the provided text, the following characteristics are relevant to a data science team:\n",
      "\n",
      "* **Attention to detail**: The text highlights the importance of controlling for Type I error, which requires a high level of attention to detail to ensure accurate results.\n",
      "* **Statistical knowledge**: The team should have a strong understanding of statistical concepts, such as hypothesis testing, p-values, and alpha values.\n",
      "* **Critical thinking**: The team should be able to critically evaluate results and identify potential issues, such as false indications of significance.\n",
      "* **Collaboration**: The text mentions the importance of working together to solidify understanding of the data and focus research efforts.\n",
      "* **Adaptability**: The team should be able to adapt to changing circumstances, such as the need to control for Type I error when running multiple hypothesis tests.\n",
      "* **Communication**: The team should be able to effectively communicate their findings and results to others, as mentioned in the text.\n",
      "* **Problem-solving**: The team should be able to identify and address problems, such as the need to correct for false indications of significance.\n",
      "* **Data-driven approach**: The team should be driven by data and focused on understanding the underlying relationships and patterns in the data.\n",
      "\n",
      "These characteristics are essential for a data science team to produce high-quality results, identify meaningful patterns, and make informed decisions.\n",
      "\n",
      "According to the provided text, the good characteristics for a data science team are:\n",
      "\n",
      "1. Reason and common sense: Data science teams should approach problems with a logical and rational mindset.\n",
      "2. Skepticism: Be cautious of surprise findings and verify the accuracy of conclusions.\n",
      "3. Clear communication: Articulate the problem being solved and the approach being taken, and ensure that the answer is clear and understandable.\n",
      "4. Discipline: Write out the analytic plan and document assumptions and biases to ensure transparency and accountability.\n",
      "5. Validation: Verify that the instructions provided to the computer are correct and intended, and that the analysis addresses the original intent.\n",
      "6. Storytelling: Present the findings in a clear and actionable story, and identify potential holes in the story to avoid surprises.\n",
      "7. Continuous improvement: Document what was learned and why changes were made, and be open to revising the plan based on new information.\n",
      "8. Collaboration: Test answers with a friendly audience to ensure that findings hold water.\n",
      "\n",
      "These characteristics can help a data science team to produce high-quality results, avoid errors, and effectively communicate their findings to stakeholders.\n",
      "\n",
      "Unfortunately, the provided text does not explicitly mention the good characteristics for a data science team. However, it does provide some relevant information about the components of data science and the importance of considering each aspect when engineering a data science solution.\n",
      "\n",
      "However, based on general knowledge and best practices, some good characteristics for a data science team might include:\n",
      "\n",
      "1. Collaboration: Data science teams should be able to work together effectively, sharing knowledge and expertise to achieve common goals.\n",
      "2. Communication: Clear and effective communication is essential for data science teams, as they need to be able to explain complex technical concepts to non-technical stakeholders.\n",
      "3. Problem-solving: Data science teams should be able to approach problems in a structured and methodical way, using data to inform their decisions.\n",
      "4. Creativity: Data science teams should be able to think creatively and come up with innovative solutions to complex problems.\n",
      "5. Adaptability: Data science teams should be able to adapt quickly to changing requirements and new technologies.\n",
      "6. Data literacy: Data science teams should have a strong understanding of data and its limitations, as well as the ability to work with large datasets.\n",
      "7. Business acumen: Data science teams should have a good understanding of the business and be able to communicate the value of their work to stakeholders.\n",
      "8. Continuous learning: Data science teams should be committed to ongoing learning and professional development, staying up-to-date with the latest tools and techniques.\n",
      "9. Transparency: Data science teams should be transparent in their methods and results, providing clear explanations of their work and its limitations.\n",
      "10. Accountability: Data science teams should be accountable for their work, taking ownership of their projects and results.\n",
      "\n",
      "These are just a few examples, and the specific characteristics that are most important will depend on the specific needs and goals of the organization.\n",
      "\n",
      "Based on the provided text, I couldn't find any specific characteristics mentioned for a data science team. However, I can suggest that the text might be related to data science concepts, such as data types, analytics, and learning models, which could be relevant to a data science team.\n",
      "\n",
      "If you're looking for characteristics of a good data science team, here are some general traits that are often considered important:\n",
      "\n",
      "* Collaboration: Data science teams often involve multiple stakeholders, including data scientists, analysts, engineers, and business stakeholders. A good data science team should be able to collaborate effectively across these groups.\n",
      "* Communication: Data science teams should be able to communicate complex technical concepts to non-technical stakeholders, as well as provide clear and concise results to business leaders.\n",
      "* Problem-solving: Data science teams should be able to identify and solve complex problems, often involving large datasets and complex algorithms.\n",
      "* Adaptability: Data science teams should be able to adapt to changing requirements, new technologies, and shifting priorities.\n",
      "* Creativity: Data science teams should be able to think creatively and come up with innovative solutions to complex problems.\n",
      "* Technical skills: Data science teams should have strong technical skills in areas such as programming, statistics, and machine learning.\n",
      "* Business acumen: Data science teams should have a good understanding of the business and be able to provide insights that drive business value.\n",
      "\n",
      "These are just a few examples, and the specific characteristics of a good data science team may vary depending on the organization and the specific goals of the team.\n",
      "\n",
      "Unfortunately, the provided text does not mention the good characteristics for a data science team. However, I can provide you with some common characteristics that are often considered important for a data science team:\n",
      "\n",
      "1. **Collaboration**: Data science teams should be able to work together effectively, sharing knowledge and expertise to achieve common goals.\n",
      "2. **Communication**: Clear and effective communication is crucial for data science teams, both within the team and with stakeholders.\n",
      "3. **Curiosity**: Data scientists should be curious and passionate about exploring data and uncovering insights.\n",
      "4. **Creativity**: Data science teams should be able to think creatively and come up with innovative solutions to complex problems.\n",
      "5. **Analytical skills**: Data scientists should have strong analytical skills, including statistical knowledge, programming skills, and data visualization expertise.\n",
      "6. **Domain expertise**: Data science teams should have a good understanding of the business domain and be able to apply data science techniques to solve real-world problems.\n",
      "7. **Adaptability**: Data science teams should be able to adapt quickly to changing requirements, new technologies, and shifting priorities.\n",
      "8. **Continuous learning**: Data science teams should be committed to ongoing learning and professional development, staying up-to-date with the latest tools, techniques, and methodologies.\n",
      "9. **Attention to detail**: Data scientists should be meticulous and detail-oriented, ensuring that their work is accurate and reliable.\n",
      "10. **Business acumen**: Data science teams should have a good understanding of the business goals and objectives, and be able to communicate insights and recommendations effectively to stakeholders.\n",
      "\n",
      "These characteristics can help a data science team to be successful and effective in their work.\n",
      "\n",
      "Unfortunately, the provided text does not mention good characteristics for a data science team. However, I can provide you with some general characteristics that are commonly considered important for a data science team:\n",
      "\n",
      "1. **Collaboration**: Data science teams should be able to work together effectively, sharing knowledge and expertise to achieve common goals.\n",
      "2. **Communication**: Clear and effective communication is crucial for data science teams, both within the team and with stakeholders.\n",
      "3. **Curiosity**: Data scientists should be curious and passionate about exploring data and uncovering insights.\n",
      "4. **Creativity**: Data science teams should be able to think creatively and come up with innovative solutions to complex problems.\n",
      "5. **Analytical skills**: Data scientists should have strong analytical skills, including statistical knowledge, programming skills, and data visualization expertise.\n",
      "6. **Domain expertise**: Data science teams should have a good understanding of the business domain and be able to apply data science techniques to solve real-world problems.\n",
      "7. **Adaptability**: Data science teams should be able to adapt quickly to changing requirements, new technologies, and shifting priorities.\n",
      "8. **Continuous learning**: Data science teams should be committed to ongoing learning and professional development, staying up-to-date with the latest tools, techniques, and methodologies.\n",
      "9. **Attention to detail**: Data science teams should be meticulous and detail-oriented, ensuring that data is accurate, reliable, and well-documented.\n",
      "10. **Business acumen**: Data science teams should have a good understanding of the business goals and objectives, and be able to communicate insights and recommendations effectively to stakeholders.\n",
      "\n",
      "These characteristics can help a data science team to be successful and effective in their work.\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Given the following extracted parts of a long document and a question, create a final answer. \n",
      "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
      "______________________\n",
      "Based on the provided text, there is no direct mention of good characteristics for a data science team. However, the text does discuss various aspects of learning models, including supervised, unsupervised, and semi-supervised learning, as well as online and offline models.\n",
      "\n",
      "If you're looking for characteristics of a good data science team, here are some relevant points that can be inferred from the text:\n",
      "\n",
      "1. Collaboration: Data science teams should be able to work together effectively, combining their skills and expertise to achieve common goals.\n",
      "2. Adaptability: Data science teams should be able to adapt to changing requirements, new data sources, and evolving business needs.\n",
      "3. Analytical skills: Data science teams should possess strong analytical skills, including the ability to design and implement effective learning models.\n",
      "4. Communication skills: Data science teams should be able to effectively communicate their findings and insights to stakeholders, both technical and non-technical.\n",
      "5. Problem-solving skills: Data science teams should be able to identify and solve complex problems, using a combination of data analysis, machine learning, and domain expertise.\n",
      "6. Continuous learning: Data science teams should be committed to continuous learning, staying up-to-date with the latest developments in machine learning, data science, and related fields.\n",
      "7. Flexibility: Data science teams should be able to work with different data sources, formats, and tools, and be flexible in their approach to problem-solving.\n",
      "8. Creativity: Data science teams should be able to think creatively, developing innovative solutions to complex problems.\n",
      "9. Attention to detail: Data science teams should be meticulous in their work, ensuring that their models are accurate, reliable, and well-documented.\n",
      "10. Business acumen: Data science teams should have a good understanding of the business context and be able to apply their skills to drive business value.\n",
      "\n",
      "These characteristics are not explicitly mentioned in the provided text, but they are generally considered important for a data science team to be successful.\n",
      "\n",
      "Based on the provided text, there is no direct mention of good characteristics for a data science team. However, the text does discuss some relevant concepts that can be applied to a data science team:\n",
      "\n",
      "1. Reinforcement Learning: This approach can be applied to complex, real-world tasks that involve optimization, such as navigation or trading. This can be relevant to a data science team that needs to optimize their workflow or improve their performance.\n",
      "2. Execution Models: The text discusses batch and streaming execution models, which can be relevant to a data science team that needs to process large datasets or handle real-time data.\n",
      "3. Feedback: The text mentions that online models can rapidly incorporate feedback to improve performance. This can be relevant to a data science team that needs to iterate on their models and improve their accuracy.\n",
      "\n",
      "Some good characteristics for a data science team that are not explicitly mentioned in the text but are generally considered important include:\n",
      "\n",
      "1. Collaboration: Data science teams often consist of individuals with different skill sets and expertise. Collaboration and communication are essential for successful project outcomes.\n",
      "2. Adaptability: Data science teams need to be able to adapt to changing requirements, new data sources, and evolving technologies.\n",
      "3. Creativity: Data science teams need to be able to think creatively and come up with innovative solutions to complex problems.\n",
      "4. Attention to detail: Data science teams need to be meticulous and detail-oriented to ensure the accuracy and quality of their work.\n",
      "5. Continuous learning: Data science teams need to stay up-to-date with the latest technologies, methodologies, and tools to remain competitive.\n",
      "6. Effective communication: Data science teams need to be able to communicate complex technical information to non-technical stakeholders and team members.\n",
      "7. Problem-solving skills: Data science teams need to be able to identify and solve complex problems, often with limited data and resources.\n",
      "8. Domain expertise: Data science teams need to have a deep understanding of the domain they are working in, including the business, industry, or market.\n",
      "\n",
      "These characteristics can help a data science team to be successful and achieve their goals.\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as good for a data science team:\n",
      "\n",
      "* Scalability: The ability to handle large amounts of data and scale computation over multiple computers.\n",
      "* Flexibility: The ability to choose between batch and streaming execution models depending on the analytic goals and requirements.\n",
      "* Parallelism: The ability to execute analytics in parallel to improve performance and scalability.\n",
      "* State management: The ability to manage state in memory and deliver results in real-time.\n",
      "* Timeliness: The ability to deliver results in a timely manner, with some analytics requiring up-to-the-second results.\n",
      "* Latency: The ability to analyze data quickly, with some analytics requiring latency of seconds or less.\n",
      "\n",
      "Additionally, the text mentions the importance of:\n",
      "\n",
      "* Understanding system capacity: Collecting metrics such as data consumed, data emitted, and latency to understand when scale limits are reached.\n",
      "* Choosing the right framework: Selecting frameworks that support parallel batch execution, such as Hadoop, or parallel streaming execution, such as Storm, S4, and Samza.\n",
      "\n",
      "It's worth noting that these characteristics are specific to the context of analytic execution models and may not be universally applicable to all data science teams.\n",
      "\n",
      "Unfortunately, the provided text does not explicitly mention the good characteristics for a data science team. However, it does provide an analogy between data science analytics and broccoli, highlighting the fractal nature of data science and the self-similar patterns that emerge at different scales.\n",
      "\n",
      "If you're looking for relevant text, you might consider searching for other sections of the document that discuss the characteristics of a successful data science team.\n",
      "\n",
      "According to the provided text, a good data science team is characterized by:\n",
      "\n",
      "* Being \"fractal in time\" - an iterative process\n",
      "* Getting an imperfect solution out the door quickly to gain interest from stakeholders\n",
      "* Incorporating domain expert knowledge\n",
      "* Trying different analytic techniques and models on subsets of the data\n",
      "* Evaluating and refining models, and selecting a model\n",
      "* Deploying models to inform, inspire action, and act\n",
      "* Evaluating business results to improve the overall product.\n",
      "\n",
      "Unfortunately, the provided text does not explicitly mention the good characteristics for a data science team. However, it does provide a high-level overview of a Data Science product and its components, which may be relevant to understanding the skills and competencies required for a data science team.\n",
      "\n",
      "The text mentions the following components of a Data Science product:\n",
      "\n",
      "1. GOAL: Describe, Discover, Predict, Advise\n",
      "2. ACTION: Productization, Data Monetization, Insights & Relationships\n",
      "3. DATA: Text, Imagery, Waveform, Geo, Time Series\n",
      "4. COMPUTATION: Aggregation, Enrichment, Clustering, Classification\n",
      "\n",
      "These components may imply that a data science team should have a range of skills, including:\n",
      "\n",
      "* Data analysis and interpretation (Describe, Discover)\n",
      "* Modeling and prediction (Predict)\n",
      "* Communication and storytelling (Advise)\n",
      "* Data engineering and productization (Productization)\n",
      "* Data monetization and business acumen (Data Monetization)\n",
      "* Data visualization and insights (Insights & Relationships)\n",
      "* Programming and computational skills (Aggregation, Enrichment, Clustering, Classification)\n",
      "* Familiarity with various data types (Text, Imagery, Waveform, Geo, Time Series)\n",
      "\n",
      "However, these are just inferences and not explicitly stated in the provided text. A comprehensive list of good characteristics for a data science team would likely include additional skills and competencies, such as:\n",
      "\n",
      "* Strong programming skills in languages like Python, R, or SQL\n",
      "* Experience with data visualization tools like Tableau, Power BI, or D3.js\n",
      "* Knowledge of machine learning algorithms and statistical modeling\n",
      "* Familiarity with data storage solutions like relational databases, NoSQL databases, or data warehouses\n",
      "* Strong communication and collaboration skills\n",
      "* Ability to work with stakeholders to understand business needs and develop data-driven solutions\n",
      "* Experience with data quality and data governance best practices\n",
      "* Stay up-to-date with industry trends and advancements in data science and analytics.\n",
      "\n",
      "According to the provided text, the good characteristics for a data science team are:\n",
      "\n",
      "1. **Clear goal definition**: The team should have a clear idea of their analytic goal and the end state of the analysis.\n",
      "2. **Business value understanding**: The team should define the business value of the data and plan to use the insights to drive decisions.\n",
      "3. **Data collection and cleaning**: The team should collect representative data and spend time upfront to clean the data, even if it's messy, to avoid generating garbage results.\n",
      "4. **Computation alignment**: The team should align the data to goals through the process of creating insights, using divide and conquer to decompose the problem into smaller analytic capabilities.\n",
      "5. **Action-oriented**: The team should ensure that the output of computation enables actions that align to the goals of the data product, and that results support or inspire action.\n",
      "\n",
      "Additionally, the text implies that a good data scientist should be:\n",
      "\n",
      "1. **Adept at handling messy data**: The team should be able to handle missing or erroneous values in the data.\n",
      "2. **Practical**: The team should not wait for perfect data to get started, but instead, start with the data they have and improve it over time.\n",
      "\n",
      "Overall, the text emphasizes the importance of having a clear understanding of the business value of the data, being practical and action-oriented, and having the skills to handle messy data.\n",
      "\n",
      "Unfortunately, the provided text does not mention specific characteristics for a data science team. However, it does mention the importance of being a \"data artist\" and the need to practice finding the right analytic technique, which could be interpreted as a characteristic of a good data science team.\n",
      "\n",
      "Here is the relevant text:\n",
      "\n",
      "\"If you focus only on the science aspect of Data Science you will never become a data artist.\n",
      "A critical step in Data Science is to identify an analytic technique that will produce the desired action. Sometimes it is clear; a characteristic of the problem (e.g., data type) points to the technique you should implement. Other times, however, it can be difficult to know where to begin. The universe of possible analytic techniques is large. Finding your way through this universe is an art that must be practiced. We are going to guide you on the next portion of your journey - becoming a data artist.\"\n",
      "\n",
      "Based on the provided text, I couldn't find any direct mention of good characteristics for a data science team. However, the text does discuss the concept of problem decomposition, which is a crucial aspect of data science. Here are some relevant points that can be inferred:\n",
      "\n",
      "* Breaking down complex problems into smaller, manageable pieces (problem decomposition) is essential for data science teams.\n",
      "* A holistic, end-to-end solution often requires combining multiple analytic techniques.\n",
      "* Data science teams should strive to engineer complete solutions by decomposing problems into progressively smaller sub-problems.\n",
      "* The Fractal Analytic Model embodies this approach, where the problem is decomposed into smaller computations that can be further broken down.\n",
      "\n",
      "While these points don't explicitly mention good characteristics for a data science team, they do highlight the importance of:\n",
      "\n",
      "* Analytical thinking\n",
      "* Problem-solving skills\n",
      "* Ability to combine multiple techniques\n",
      "* Holistic approach\n",
      "* Attention to detail\n",
      "* Ability to break down complex problems into smaller, manageable pieces\n",
      "\n",
      "In general, good characteristics for a data science team might include:\n",
      "\n",
      "* Strong analytical and problem-solving skills\n",
      "* Ability to work collaboratively and communicate effectively\n",
      "* Strong programming and technical skills\n",
      "* Familiarity with data visualization and storytelling techniques\n",
      "* Ability to think critically and creatively\n",
      "* Strong understanding of data science concepts and methodologies\n",
      "* Ability to work with diverse data types and sources\n",
      "* Strong attention to detail and ability to identify and address errors\n",
      "* Ability to adapt to changing requirements and priorities\n",
      "* Strong understanding of business goals and objectives\n",
      "\n",
      "Please note that these are general characteristics and may vary depending on the specific needs and goals of the organization.\n",
      "\n",
      "According to the provided text, the good characteristics for a data science team are:\n",
      "\n",
      "* Compound analytic goals that create natural segmentation\n",
      "* Natural orderings of analytic goals\n",
      "* Data types that dictate processing activities\n",
      "* Requirements for human-in-the-loop feedback\n",
      "* The need to combine multiple data sources\n",
      "\n",
      "These characteristics are mentioned as helpful hints to guide problem decomposition, which is an important aspect of data science.\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Given the following extracted parts of a long document and a question, create a final answer. \n",
      "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
      "______________________\n",
      "Based on the provided text, it seems that the data science team was able to successfully identify spoofed domains by:\n",
      "\n",
      "1. \"Deriving a list of domains similar to those registered by the company\" - This suggests that the team was able to effectively identify patterns and relationships in the data.\n",
      "2. \"Comparing that list against a list of recently registered domains\" - This implies that the team was able to efficiently and accurately match the similar domains with the recently registered domains.\n",
      "3. \"Discovering a spoofed domain within 48 hours\" - This indicates that the team was able to quickly and accurately identify the spoofed domain, which is a critical aspect of the problem.\n",
      "\n",
      "Some good characteristics for a data science team that can be inferred from this example include:\n",
      "\n",
      "1. **Pattern recognition**: The team was able to identify patterns and relationships in the data, which is a key skill for data scientists.\n",
      "2. **Efficient data processing**: The team was able to quickly and accurately compare the lists of domains, which suggests that they were able to efficiently process large amounts of data.\n",
      "3. **Attention to detail**: The team was able to identify a spoofed domain within 48 hours, which implies that they were able to carefully examine the data and identify subtle differences.\n",
      "4. **Collaboration**: The team was able to work together to decompose the problem and develop a solution, which is an important aspect of data science.\n",
      "5. **Adaptability**: The team was able to re-evaluate their approach and derive a new solution when the initial approach proved to be too complex, which suggests that they were able to adapt to changing circumstances.\n",
      "6. **Domain expertise**: The team had a good understanding of the problem domain and was able to develop a solution that was tailored to the specific needs of the company.\n",
      "7. **Communication**: The team was able to effectively communicate their approach and results to stakeholders, as evidenced by the inclusion of a figure in the report.\n",
      "\n",
      "Overall, the data science team demonstrated a range of skills and characteristics that are important for success in data science, including pattern recognition, efficient data processing, attention to detail, collaboration, adaptability, domain expertise, and communication.\n",
      "\n",
      "According to the provided text, the five dimensions that compete for a data scientist's attention and are relevant to balancing implementation constraints are:\n",
      "\n",
      "1. **SPEED**: The speed at which an analytic outcome must be produced (e.g., near real-time, hourly, daily) or the time it takes to develop and implement the analytic solution.\n",
      "2. **ANALYTIC COMPLEXITY**: Algorithmic complexity (e.g., complexity class and execution resources).\n",
      "3. **ACCURACY & PRECISION**: The ability to produce exact versus approximate solutions as well as the ability to provide a measure of confidence.\n",
      "4. **DATA SIZE**: The size of the dataset (e.g., number of rows).\n",
      "5. **DATA COMPLEXITY**: The data type, formal complexity measures including measures of overlap and linear separability, number of dimensions/columns, and linkages between datasets.\n",
      "\n",
      "These dimensions are competing, and a data science team must balance them to achieve the right outcome.\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as good for a data science team:\n",
      "\n",
      "* Ability to work with previously computed results to avoid re-computing values across the full time horizon of data.\n",
      "* Ability to produce results quickly and then incrementally improve the solution.\n",
      "* Ability to work with streaming approaches to overcome storage limitations.\n",
      "\n",
      "These characteristics suggest that a good data science team should be able to:\n",
      "\n",
      "* Leverage existing results to speed up their work\n",
      "* Be agile and able to quickly produce and iterate on solutions\n",
      "* Be able to work with large and complex data sets by using efficient and scalable approaches.\n",
      "\n",
      "Here is the relevant text:\n",
      "\n",
      "» Tips From the Pros\n",
      "When possible, consider approaches \n",
      "that make use of previously computed \n",
      "results. Your algorithm will run  \n",
      "much faster if you can avoid  \n",
      "re-computing values across  \n",
      "the full time horizon of data.\n",
      " » Tips From the Pros\n",
      "Our Data Science Product Lifecycle  \n",
      "has evolved to produce results quickly \n",
      "and then incrementally improve  \n",
      "the solution.\n",
      " » Tips From the Pros\n",
      "Streaming approaches may be useful \n",
      "for overcoming storage limitations.\n",
      "\n",
      "Unfortunately, the provided text does not mention good characteristics for a data science team. The text appears to be a guide for selecting analytic techniques and provides tips and information on data science, but it does not discuss team characteristics.\n",
      "\n",
      "Unfortunately, the provided text does not mention good characteristics for a data science team. However, I can provide you with some common characteristics that are often considered important for a data science team:\n",
      "\n",
      "1. **Collaboration**: Data science teams should be able to work together effectively, sharing knowledge and expertise to achieve common goals.\n",
      "2. **Communication**: Clear and effective communication is crucial for data science teams, as they need to explain complex technical concepts to non-technical stakeholders.\n",
      "3. **Curiosity**: Data science teams should be curious and passionate about exploring data to uncover insights and solve problems.\n",
      "4. **Creativity**: Data science teams should be able to think creatively and come up with innovative solutions to complex problems.\n",
      "5. **Analytical skills**: Data science teams should have strong analytical skills, including statistical knowledge, programming skills, and data visualization expertise.\n",
      "6. **Domain expertise**: Data science teams should have a deep understanding of the domain or industry they are working in, allowing them to ask informed questions and develop relevant solutions.\n",
      "7. **Adaptability**: Data science teams should be able to adapt quickly to changing requirements, new technologies, and shifting priorities.\n",
      "8. **Attention to detail**: Data science teams should be meticulous and detail-oriented, ensuring that their work is accurate and reliable.\n",
      "9. **Business acumen**: Data science teams should have a good understanding of the business goals and objectives, allowing them to develop solutions that drive value.\n",
      "10. **Continuous learning**: Data science teams should be committed to ongoing learning and professional development, staying up-to-date with the latest tools, techniques, and methodologies.\n",
      "\n",
      "These characteristics can help a data science team be successful in their work and deliver valuable insights and solutions to their organization.\n",
      "\n",
      "Unfortunately, the provided text does not mention the characteristics of a good data science team. The text appears to be a table of contents or a list of topics related to data science, including clustering, regression, hypothesis testing, and more.\n",
      "\n",
      "If you're looking for characteristics of a good data science team, I can provide some general guidelines:\n",
      "\n",
      "1. **Collaboration**: Data science teams should be able to work together effectively, sharing knowledge and expertise to achieve common goals.\n",
      "2. **Communication**: Clear and effective communication is crucial for data science teams, both within the team and with stakeholders.\n",
      "3. **Domain expertise**: Team members should have a deep understanding of the business domain and the problems they're trying to solve.\n",
      "4. **Technical skills**: Data science teams should have a strong foundation in programming languages, data analysis, machine learning, and other relevant technical skills.\n",
      "5. **Curiosity and creativity**: Data science teams should be curious and creative, always looking for new ways to solve problems and improve processes.\n",
      "6. **Adaptability**: Data science teams should be able to adapt quickly to changing requirements, new technologies, and shifting priorities.\n",
      "7. **Data literacy**: Team members should have a strong understanding of data and its limitations, as well as the ability to communicate complex data insights to non-technical stakeholders.\n",
      "8. **Testing and validation**: Data science teams should prioritize testing and validation to ensure the accuracy and reliability of their models and insights.\n",
      "9. **Continuous learning**: Data science teams should prioritize continuous learning, staying up-to-date with the latest technologies, methods, and best practices.\n",
      "10. **Transparency and accountability**: Data science teams should be transparent in their methods and results, and accountable for the insights and recommendations they provide.\n",
      "\n",
      "These are just some general guidelines, and the specific characteristics of a good data science team may vary depending on the organization, industry, and goals.\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as good starting points for a data science team:\n",
      "\n",
      "* Bayesian network: for known dependent relationships between variables\n",
      "* Decision trees: for highly transparent models\n",
      "* K-nearest neighbors: for datasets with <20 data dimensions\n",
      "* Naive bayes: for large datasets with an unknown classification signal\n",
      "* Hidden markov model: for estimating an unobservable state based on observable variables\n",
      "* Support vector machines (SVM): for unknown or complex data structures\n",
      "* Random forests: for feature importance and unknown data structures\n",
      "* Tree-based methods: for unknown data structures\n",
      "* Generalized linear models: for highly transparent models\n",
      "\n",
      "Additionally, the text provides some general tips for data science teams:\n",
      "\n",
      "* Try multiple classifiers and pick the one or two that work best\n",
      "* Be careful of the \"recommendation bubble\" and ensure diversity in recommendations\n",
      "* Use tools like SVD and PCA to create better features for recommenders\n",
      "\n",
      "It's worth noting that these are just some of the many possible characteristics and approaches that a data science team might use, and the specific needs and goals of the team will depend on the specific problem they are trying to solve.\n",
      "\n",
      "Unfortunately, the provided text does not mention good characteristics for a data science team. The text appears to be a list of different approaches and techniques for various data science tasks, such as modeling, simulation, and optimization.\n",
      "\n",
      "If you're looking for characteristics of a good data science team, here are some general traits that are often considered important:\n",
      "\n",
      "1. Collaboration: Data science teams should be able to work together effectively, sharing knowledge and expertise to achieve common goals.\n",
      "2. Communication: Good data science teams should be able to clearly communicate complex technical concepts to both technical and non-technical stakeholders.\n",
      "3. Problem-solving: Data science teams should be able to identify and tackle complex problems, using a combination of technical skills and creative thinking.\n",
      "4. Adaptability: Data science teams should be able to adapt to changing requirements, new data sources, and evolving technologies.\n",
      "5. Domain expertise: Data science teams should have a deep understanding of the domain or industry they are working in, as well as the business goals and objectives.\n",
      "6. Technical skills: Data science teams should have a strong foundation in programming languages, data analysis, machine learning, and other relevant technical skills.\n",
      "7. Continuous learning: Data science teams should be committed to ongoing learning and professional development, staying up-to-date with the latest tools, techniques, and methodologies.\n",
      "8. Data-driven decision-making: Data science teams should be able to use data to inform business decisions, rather than relying on intuition or anecdotal evidence.\n",
      "9. Transparency: Data science teams should be transparent in their methods, results, and assumptions, and be willing to explain complex technical concepts to non-technical stakeholders.\n",
      "10. Accountability: Data science teams should be accountable for their work, taking ownership of their projects and results, and being willing to iterate and improve based on feedback.\n",
      "\n",
      "These are just a few examples of the characteristics that can make a data science team effective. The specific characteristics that are most important will depend on the team's goals, objectives, and context.\n",
      "\n",
      "Unfortunately, the provided text does not mention the good characteristics for a data science team. However, I can provide you with some general characteristics that are commonly considered important for a data science team:\n",
      "\n",
      "1. Collaboration: Data science teams should be able to work together effectively, sharing knowledge and expertise to achieve common goals.\n",
      "2. Communication: Clear and effective communication is crucial for data science teams, both within the team and with stakeholders.\n",
      "3. Curiosity: Data science teams should be curious and passionate about exploring and understanding data.\n",
      "4. Creativity: Data science teams should be able to think creatively and come up with innovative solutions to complex problems.\n",
      "5. Analytical skills: Data science teams should have strong analytical skills, including statistical knowledge, programming skills, and data visualization expertise.\n",
      "6. Business acumen: Data science teams should have a good understanding of the business and be able to communicate insights and recommendations to stakeholders.\n",
      "7. Adaptability: Data science teams should be able to adapt quickly to changing requirements and new technologies.\n",
      "8. Continuous learning: Data science teams should be committed to continuous learning and professional development, staying up-to-date with the latest tools, techniques, and methodologies.\n",
      "9. Domain expertise: Data science teams should have a good understanding of the domain or industry they are working in, including the business processes, regulations, and stakeholders.\n",
      "10. Transparency: Data science teams should be transparent in their work, including data collection, processing, and analysis, as well as their findings and recommendations.\n",
      "\n",
      "These characteristics can help a data science team to be effective, efficient, and successful in their work.\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Given the following extracted parts of a long document and a question, create a final answer. \n",
      "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
      "______________________\n",
      "Based on the provided text, the following characteristics are mentioned as good for a data science team:\n",
      "\n",
      "* Collaborative: The text mentions \"Collaborative Filtering\" as a technique, suggesting that collaboration is an important aspect of a data science team.\n",
      "* Use of Singular Value Decomposition (SVD) based Recommendation: This suggests that the team should be familiar with advanced mathematical techniques and be able to apply them to real-world problems.\n",
      "* Use of Deep Learning: The text mentions \"Deep Learning\" as a method that learns features that lead to higher concept learning, suggesting that the team should be familiar with this technique and be able to apply it to complex problems.\n",
      "* Design of Experiments: The text mentions \"Design of Experiments\" as a technique that applies controlled experiments to quantify effects on system output caused by changes to inputs, suggesting that the team should be able to design and conduct experiments to test hypotheses.\n",
      "* Use of Discrete Event Simulation: The text mentions \"Discrete Event Simulation\" as a technique that simulates a discrete sequence of events, suggesting that the team should be able to use this technique to analyze event-based processes.\n",
      "* Use of Ensemble Learning: The text mentions \"Ensemble Learning\" as a technique that learns multiple models and combines output to achieve better performance, suggesting that the team should be able to use this technique to improve the accuracy of their models.\n",
      "* Use of Expert Systems: The text mentions \"Expert Systems\" as a technique that uses symbolic logic to reason about facts, suggesting that the team should be able to use this technique to build systems that can reason about complex data.\n",
      "* Use of Exponential Smoothing: The text mentions \"Exponential Smoothing\" as a technique that removes artifacts expected from collection error or outliers, suggesting that the team should be able to use this technique to clean and preprocess data.\n",
      "\n",
      "It's worth noting that these characteristics are not necessarily unique to data science teams, and may be relevant to other types of teams as well.\n",
      "\n",
      "Unfortunately, the provided text does not mention good characteristics for a data science team. However, I can provide you with some general characteristics that are commonly considered important for a data science team:\n",
      "\n",
      "1. **Collaboration**: Data science teams should be able to work together effectively, sharing knowledge and expertise to achieve common goals.\n",
      "2. **Communication**: Clear and effective communication is crucial for data science teams, as they need to explain complex technical concepts to non-technical stakeholders.\n",
      "3. **Curiosity**: Data science teams should be curious and passionate about exploring data to uncover insights and solve problems.\n",
      "4. **Creativity**: Data science teams should be able to think creatively and come up with innovative solutions to complex problems.\n",
      "5. **Analytical skills**: Data science teams should have strong analytical skills, including statistical knowledge, programming skills, and data visualization expertise.\n",
      "6. **Domain expertise**: Data science teams should have a deep understanding of the business domain they are working in, including the industry, market, and customer needs.\n",
      "7. **Adaptability**: Data science teams should be able to adapt quickly to changing requirements, new technologies, and shifting priorities.\n",
      "8. **Continuous learning**: Data science teams should be committed to continuous learning, staying up-to-date with the latest tools, techniques, and methodologies.\n",
      "9. **Attention to detail**: Data science teams should be meticulous and detail-oriented, ensuring that their work is accurate and reliable.\n",
      "10. **Business acumen**: Data science teams should have a good understanding of the business side of the organization, including financials, operations, and strategy.\n",
      "\n",
      "These characteristics can help a data science team to be effective, efficient, and successful in their work.\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as good characteristics for a data science team:\n",
      "\n",
      "1. **Collaboration**: The text does not explicitly mention collaboration, but it does highlight the importance of working together in the context of machine learning and data analysis.\n",
      "2. **Domain expertise**: The text does not explicitly mention domain expertise, but it does emphasize the importance of understanding the underlying distributions of interest in the context of Markov Chain Monte Carlo (MCMC) methods.\n",
      "3. **Statistical knowledge**: The text highlights the importance of statistical knowledge in the context of regression with shrinkage (Lasso) and sensitivity analysis.\n",
      "4. **Programming skills**: The text mentions the importance of programming skills in the context of Monte Carlo methods and neural networks.\n",
      "5. **Data analysis skills**: The text highlights the importance of data analysis skills in the context of data mining and knowledge discovery.\n",
      "6. **Problem-solving skills**: The text mentions the importance of problem-solving skills in the context of outlier removal and sensitivity analysis.\n",
      "7. **Communication skills**: The text does not explicitly mention communication skills, but it does highlight the importance of presenting results in the context of data visualization.\n",
      "8. **Domain-specific knowledge**: The text mentions the importance of domain-specific knowledge in the context of operations research and machine learning.\n",
      "\n",
      "Some additional characteristics that are not explicitly mentioned in the text but are commonly considered important for a data science team include:\n",
      "\n",
      "1. **Business acumen**: Understanding the business goals and objectives of the organization and being able to communicate the value of data science insights to stakeholders.\n",
      "2. **Creativity**: Being able to think creatively and come up with innovative solutions to complex problems.\n",
      "3. **Adaptability**: Being able to adapt to changing requirements and priorities, and being able to pivot when necessary.\n",
      "4. **Attention to detail**: Being meticulous and detail-oriented in data analysis and modeling.\n",
      "5. **Teamwork**: Being able to work collaboratively with other team members and stakeholders to achieve common goals.\n",
      "6. **Continuous learning**: Being committed to ongoing learning and professional development, and staying up-to-date with the latest methods and technologies in data science.\n",
      "\n",
      "It's worth noting that these characteristics may vary depending on the specific context and goals of the data science team.\n",
      "\n",
      "Unfortunately, the provided text does not mention data science teams or their characteristics. The text only mentions \"Take off the Training Wheels\", which seems to be a phrase unrelated to data science teams.\n",
      "\n",
      "Based on the provided text, there is no direct mention of good characteristics for a data science team. However, some relevant information can be extracted from the text that may be applicable to a data science team:\n",
      "\n",
      "1. Collaboration: The text mentions \"Tips From the Pros\" and \"References we love to read\", suggesting a collaborative approach to learning and sharing knowledge.\n",
      "2. Adaptability: The concept of simulated annealing, which involves adjusting the temperature or annealing schedule to vary algorithmic convergence, may be applicable to a data science team's approach to problem-solving.\n",
      "3. Critical thinking: The text cautions against overfitting in stepwise regression and the importance of meeting assumptions in t-tests, highlighting the need for critical thinking and careful consideration of results.\n",
      "4. Continuous learning: The text references various academic papers and books, indicating a commitment to ongoing learning and staying up-to-date with the latest developments in the field.\n",
      "5. Diverse skills: The text mentions a range of techniques and methods, including simulated annealing, stepwise regression, stochastic gradient descent, support vector machines, and topic modeling, suggesting that a data science team should have a diverse range of skills and expertise.\n",
      "\n",
      "Some additional characteristics that are commonly considered important for a data science team include:\n",
      "\n",
      "* Strong communication skills: Data scientists should be able to effectively communicate complex technical information to both technical and non-technical stakeholders.\n",
      "* Business acumen: Data scientists should have a good understanding of the business and be able to identify opportunities for data-driven decision-making.\n",
      "* Creativity: Data scientists should be able to think creatively and come up with innovative solutions to complex problems.\n",
      "* Attention to detail: Data scientists should be meticulous and detail-oriented, ensuring that their work is accurate and reliable.\n",
      "* Flexibility: Data scientists should be able to adapt to changing priorities and deadlines, and be willing to pivot when necessary.\n",
      "* Strong problem-solving skills: Data scientists should be able to identify and solve complex problems, and be able to debug and troubleshoot issues.\n",
      "\n",
      "These characteristics may not be explicitly mentioned in the provided text, but they are commonly considered important for a data science team.\n",
      "\n",
      "Unfortunately, the provided text does not mention the good characteristics for a data science team. The text only mentions the expertise of the data science team in navigating and reframing analytic questions, but does not provide specific characteristics.\n",
      "\n",
      "Based on the provided text, there is no direct mention of good characteristics for a data science team. However, the text does highlight the importance of deep learning and its applications in various fields, including data science.\n",
      "\n",
      "If we were to infer some good characteristics for a data science team based on the text, we could consider the following:\n",
      "\n",
      "1. Collaboration: The text mentions the combination of GPUs, advances in algorithms, and collections of big data, which suggests the importance of collaboration between different teams and stakeholders.\n",
      "2. Adaptability: The text highlights the rapid progress in deep learning and its applications, which implies that data science teams should be adaptable and able to quickly respond to new developments and challenges.\n",
      "3. Creativity: The text mentions the exploration of new neural network architectures, which suggests that data science teams should be creative and able to think outside the box to develop innovative solutions.\n",
      "4. Problem-solving skills: The text mentions the ability to train larger networks with more data, which implies that data science teams should have strong problem-solving skills and be able to analyze complex data sets.\n",
      "5. Communication skills: The text mentions the application of deep learning in various fields, including language translation services, which suggests that data science teams should have strong communication skills to effectively convey their findings and insights to non-technical stakeholders.\n",
      "\n",
      "Again, these are inferred characteristics and not explicitly mentioned in the text.\n",
      "\n",
      "Based on the provided text, the following characteristics of a data science team can be inferred:\n",
      "\n",
      "1. **Collaboration**: The text mentions that competitors \"collectively sharing knowledge and collaborating to advance the state-of-the-art in computer vision\" and \"contributed to the development of open source software for creating CNN models\".\n",
      "2. **Innovative thinking**: The teams implemented new techniques for developing CNNs, which suggests that they were willing to think outside the box and try new approaches.\n",
      "3. **Domain expertise**: The teams had a good understanding of the marine research domain, which allowed them to develop solutions that were relevant and effective.\n",
      "4. **Technical expertise**: The teams had a strong foundation in deep learning and computer vision, which enabled them to develop accurate and efficient algorithms.\n",
      "5. **Communication skills**: The teams were able to effectively communicate their results and share their knowledge with others, as evident from the competition forum.\n",
      "6. **Adaptability**: The teams were able to adapt to new techniques and approaches, as they tested new methods for developing CNNs.\n",
      "7. **Open-source mindset**: The teams contributed to the development of open-source software, which suggests that they were willing to share their knowledge and collaborate with others.\n",
      "\n",
      "These characteristics are likely to be beneficial for a data science team, as they enable the team to work effectively, innovate, and make a meaningful impact in their domain.\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as important for a data science team:\n",
      "\n",
      "1. Domain knowledge: The text states that \"better features can be developed with more knowledge of the domain.\" This suggests that a data science team should have a strong understanding of the domain they are working in.\n",
      "2. Creativity: Feature engineering is described as a \"challenging art\" that requires creativity. This implies that a data science team should be able to think outside the box and come up with innovative solutions.\n",
      "3. Experience: The text mentions that feature engineering is influenced by the scientist's \"experiences, tastes and understanding of the field.\" This suggests that a data science team should have a diverse range of experiences and expertise.\n",
      "4. Collaboration: The text does not explicitly mention collaboration, but the concept of \"subject-matter expertise\" implies that a data science team should be able to work with experts from other fields.\n",
      "5. Adaptability: The text mentions that feature engineering is a \"complex, but crucial aspect of Data Science\" and that \"the Learning Optimal Features sidebar goes into detail about feature learning – an automated approach to feature engineering that applies machine learning techniques.\" This suggests that a data science team should be able to adapt to new techniques and technologies.\n",
      "\n",
      "Relevant text:\n",
      "\n",
      "* \"Feature engineering is a challenging art. Like other arts, it is a creative process that manifests uniquely in each Data Scientist.\"\n",
      "* \"Better features can be developed with more knowledge of the domain.\"\n",
      "* \"The ultimate judge in this process is the performance of the machine learning algorithm which makes decisions based on this feature vector.\"\n",
      "* \"The Learning Optimal Features sidebar goes into detail about feature learning – an automated approach to feature engineering that applies machine learning techniques.\"\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Given the following extracted parts of a long document and a question, create a final answer. \n",
      "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
      "______________________\n",
      "Based on the provided text, the following characteristics of a data science team are highlighted:\n",
      "\n",
      "1. Creativity: The team was able to \"creatively combine and build 'features on features'\" to create new representations of data that were richer and more descriptive.\n",
      "2. Complexity: The approach was \"multi-staged and complex\" involving multiple stages such as generating sub-graphs, creating bloom filters, calculating distance metrics, and fitting a linear-regression model.\n",
      "3. Sophistication: The team was able to produce a sophisticated feature representation by combining and building features.\n",
      "4. Ability to work with complex data: The team was able to work with complex 3D structures, which are typically represented as a list of atoms joined by chemical bonds of differing lengths with varying electron domain and molecular geometries.\n",
      "5. Ability to develop innovative solutions: The team developed a solution based on previous work in molecular fingerprinting, which is a dimensionality reduction technique that dramatically reduces the problem space by summarizing many features.\n",
      "6. Ability to use heuristic approaches: The team used heuristic approaches such as fingerprinting when an exact solution is likely to be infeasible.\n",
      "7. Ability to work with large datasets: The team worked with a large dataset of molecules and their properties.\n",
      "8. Ability to develop models: The team developed a model of how molecular structural similarities might affect their properties.\n",
      "9. Ability to use non-linear regression: The team used non-linear regression to approximate the shape of the hidden manifold and predict the properties of new molecules.\n",
      "10. Ability to collaborate: The team worked together to develop the solution, with each member contributing their expertise and skills.\n",
      "\n",
      "These characteristics are relevant to a data science team working on a chemoinformatic search project, where they need to develop innovative solutions to complex problems, work with large datasets, and develop models to predict the properties of molecules.\n",
      "\n",
      "Based on the provided text, it seems that the relevant text is not directly related to the characteristics of a data science team. However, I can try to extract some relevant information from the text.\n",
      "\n",
      "The text mentions the importance of \"feeding\" a model with the \"good parts\" (features), which implies that a good data science team should be able to identify and select the most relevant and informative features for their model.\n",
      "\n",
      "Additionally, the text highlights the tradeoffs between filtering and wrapper methods for feature selection. This suggests that a good data science team should be able to balance the need for speed and efficiency with the need for accuracy and performance.\n",
      "\n",
      "Some potential characteristics of a good data science team that can be inferred from this text are:\n",
      "\n",
      "* Ability to identify and select the most relevant and informative features for their model\n",
      "* Ability to balance the need for speed and efficiency with the need for accuracy and performance\n",
      "* Familiarity with different feature selection methods and their tradeoffs\n",
      "* Ability to evaluate the performance of different feature sets and models\n",
      "\n",
      "Here is the relevant text:\n",
      "\n",
      "\"Models are like honored guests; you should only feed them the good parts.\n",
      "Feature selection is the process of determining the set of features with the highest information value to the model. Two main approaches are filtering and wrapper methods. Filtering methods analyze features using a test statistic and eliminate redundant or non-informative features. As an example, a filtering method could eliminate features that have little correlation to the class labels. Wrapper methods utilize a classification model as part of feature selection. A model is trained on a set of features and the classification accuracy is used to measure the information value of the feature set. One example is that of training a neural network with a set of features and evaluating the accuracy of the model. If the model scores highly on the test set, then the features have high information value. All possible combinations of features are tested to find the best feature set. There are tradeoffs between these techniques. Filtering methods are faster to compute since each feature only needs to be compared against its class label. Wrapper methods, on the other hand, evaluate feature sets by constructing models and measuring performance. This requires a large number of models to be trained and evaluated (a quantity that grows exponentially in the number of features).\"\n",
      "\n",
      "Based on the provided text, the following characteristics of a data science team are highlighted:\n",
      "\n",
      "1. **Collaboration**: The team worked together to classify cancer cell profiles, indicating a collaborative approach.\n",
      "2. **Hybrid approach**: The team used a combination of Artificial Neural Network (ANN) and Genetic Algorithm to identify the best features, demonstrating the value of combining different techniques.\n",
      "3. **Iterative process**: The team used cross-fold validation and feedback from the performance measure to refine their approach, showing an iterative and adaptive mindset.\n",
      "4. **Exploration**: The team was willing to explore different feature sets and adjust their approach when necessary, indicating a willingness to experiment and learn.\n",
      "5. **Focus on insights**: The team's goal was to gain better insight into the factors governing the system, highlighting the importance of understanding the underlying mechanisms.\n",
      "6. **Pragmatism**: The team's ultimate goal was to design a diagnostic test with reduced complexity and cost, demonstrating a practical and problem-solving approach.\n",
      "\n",
      "These characteristics suggest that a good data science team should be:\n",
      "\n",
      "* Collaborative and open to different perspectives\n",
      "* Willing to experiment and adapt to new information\n",
      "* Focused on gaining insights and understanding the underlying mechanisms\n",
      "* Pragmatic and solution-oriented\n",
      "* Able to combine different techniques and approaches\n",
      "* Iterative and willing to refine their approach based on feedback and performance measures.\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as good characteristics for a data science team:\n",
      "\n",
      "1. Diversity: The text mentions that ensemble models benefit from the diversity of their members, implying that a diverse team with different perspectives and strengths can lead to better results.\n",
      "2. Collaboration: The quote \"None of us is as smart as all of us, but some are smarter than others\" suggests that collaboration and sharing knowledge can lead to better outcomes.\n",
      "3. Ability to balance individual strengths and weaknesses: The text notes that ensemble models can overcome individual weaknesses by combining the predictions of multiple models, implying that a data science team should be able to recognize and balance the strengths and weaknesses of its individual members.\n",
      "4. Ability to manage complexity: The text mentions that ensembling can improve accuracy but also increases complexity, suggesting that a data science team should be able to manage and balance the complexity of their models and methods.\n",
      "5. Ability to balance interpretability and black-box complexity: The text notes that high-stakes problems require higher standards for auditing model functionality, implying that a data science team should be able to balance the need for interpretability with the need for complex models.\n",
      "\n",
      "Relevant text:\n",
      "\n",
      "\"None of us is as smart as all of us, but some are smarter than others.\n",
      "...Data Science models have unique strengths and weaknesses (i.e., determined by their design), and are influenced by varied perspectives based on past experience (i.e., the data they have observed).\n",
      "Ensembles overcome individual weaknesses to make predictions with more accuracy than their constituent models.\n",
      "...The ensembling methodology may be as simple as averaging two outputs, or as complex as using a “meta model” to learn an optimal combination.\n",
      "...The Data Scientist must manage a balance between ensemble interpretability and black-box complexity.\"\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as good for a data science team:\n",
      "\n",
      "1. Diversity of models: The text highlights the importance of including diverse models in an ensemble to cancel out errors and achieve a lower score.\n",
      "2. Thoughtfulness in selecting individual models: The text emphasizes the need to be thoughtful when selecting individual models for an ensemble, as introducing less accurate models can lead to an increase in the ensemble score.\n",
      "\n",
      "These characteristics can be applied to a data science team in the following ways:\n",
      "\n",
      "1. Diversity of skills and expertise: A data science team should have a diverse range of skills and expertise, including different programming languages, data analysis techniques, and domain knowledge. This diversity can help to identify and mitigate potential biases and errors in the data and models.\n",
      "2. Collaboration and communication: A data science team should work collaboratively and communicate effectively to ensure that each member's strengths and weaknesses are leveraged and that the team's overall performance is improved.\n",
      "3. Continuous learning and improvement: A data science team should prioritize continuous learning and improvement, staying up-to-date with the latest techniques and technologies, and regularly evaluating and refining their models and processes.\n",
      "\n",
      "Here is the relevant text:\n",
      "\n",
      "\"The diversity of models included within the ensemble causes the respective errors to cancel out, resulting in an overall lower score. This holds true for all points across the top 50 teams. However, after we increase the number of models in the ensemble beyond 15, we begin to see the ensembled score increase. This occurs because we are introducing less accurate (i.e., potentially overfit) models into the ensemble.\n",
      "\n",
      "The results of this simple experiment quantify the value of creating an ensemble model, while reinforcing the idea that we must be thoughtful when selecting the individual models contained within the ensemble.\"\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as important for a data science team:\n",
      "\n",
      "1. Domain expertise: The text emphasizes the importance of understanding the data origins and context, which suggests that domain expertise is crucial for a data science team.\n",
      "2. Experience: The text mentions relying on experience when assessing data truthfulness, which implies that experience is valuable for a data science team.\n",
      "3. Flexibility: The text suggests that a data science team should be willing to try different approaches and not get stuck on a single method, as seen in the quote \"Find an approach that works, implement it, and move on. You can worry about optimization and tuning your approaches later during incremental improvement.\"\n",
      "\n",
      "These characteristics are not explicitly stated as \"good characteristics\" for a data science team, but they are implied as important qualities for a team to possess.\n",
      "\n",
      "Based on the provided text, some good characteristics for a data science team are:\n",
      "\n",
      "1. **Collaboration**: The team worked together to identify and address data veracity issues, and a team member with experience in signal processing suggested a median filter approach.\n",
      "2. **Problem-solving**: The team was able to quickly identify the issue with the data and experiment with different approaches to find a solution.\n",
      "3. **Adaptability**: The team was willing to abandon a simplistic approach (moving average) and try a different approach (median filter) when it didn't work.\n",
      "4. **Communication**: The team was able to effectively communicate their findings and results, as evident from the inclusion of figures and statistics in the text.\n",
      "5. **Creativity**: The team was able to think outside the box and come up with a creative solution (median filter) to address the data issues.\n",
      "6. **Attention to detail**: The team was able to identify and address data veracity issues, which is crucial in data science.\n",
      "7. **Flexibility**: The team was able to adjust their approach based on the results and constraints (implementation speed).\n",
      "\n",
      "These characteristics are essential for a data science team to be successful in addressing complex data issues and achieving their goals.\n",
      "\n",
      "According to the provided text, the good characteristics for a data science team include:\n",
      "\n",
      "* Domain knowledge: having an in-depth understanding of the data and factors influencing the analytic goal\n",
      "* Teamwork: relying on team members, other analysts, and domain experts to build an understanding of the domain\n",
      "* Collaboration: working together to engineer and select features, impute data, choose an algorithm, and determine success\n",
      "\n",
      "Based on the provided text, the following characteristics of a data science team are highlighted:\n",
      "\n",
      "1. **Domain expertise**: The team had a domain expert who was able to provide insights and validate the findings, which is essential for effective data science projects.\n",
      "2. **Collaboration**: The team worked together to parse and verify crime data, conduct data experiments, and develop a Monte Carlo model.\n",
      "3. **Data enrichment**: The team enriched stolen car reporting with general city data to gain a deeper understanding of the problem.\n",
      "4. **Experimentation**: The team conducted several data experiments across both space and time to identify geospatial and temporal hotspots.\n",
      "5. **Insight generation**: The team was able to generate actionable insights from the data, which could be used to make the streets safer.\n",
      "6. **Problem-solving**: The team was able to identify a problem (motor vehicle theft) and develop a solution (predicting likelihood of theft at particular city intersections) using data science techniques.\n",
      "7. **Communication**: The team was able to effectively communicate their findings and insights to stakeholders, as evidenced by the development of a Monte Carlo model to predict motor vehicle theft.\n",
      "\n",
      "These characteristics suggest that a good data science team should have a combination of technical skills, domain expertise, and collaboration and communication abilities.\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Given the following extracted parts of a long document and a question, create a final answer. \n",
      "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
      "______________________\n",
      "Based on the provided text, the following characteristics are mentioned as good for a data science team:\n",
      "\n",
      "1. Focus on solving immediate problems with basic methods: Instead of trying to create super-scalable algorithm implementations, focus on solving the current problem at hand with simple and effective methods.\n",
      "2. Wait for problems to arise: Only when you encounter a problem where an algorithm fails to converge or provides poor cross-validated results, should you seek new approaches.\n",
      "3. Keep it simple: The phrase \"Keep it simple, stupid\" suggests that simplicity and straightforwardness are valuable characteristics for a data science team.\n",
      "\n",
      "These characteristics can be summarized as:\n",
      "\n",
      "* Practicality: Focus on solving real-world problems with practical solutions.\n",
      "* Flexibility: Be willing to adapt and change approaches as needed.\n",
      "* Simplicity: Prioritize simplicity and ease of implementation over complexity and scalability.\n",
      "\n",
      "These characteristics can help a data science team to be effective, efficient, and productive in their work.\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as good for a data science team:\n",
      "\n",
      "1. Ability to handle complexity: The text mentions that the client was challenged to handle the complexity associated with the large number of variables, and the data scientist was able to help by using various techniques to reduce the number of variables.\n",
      "2. Creativity: The text mentions that the data scientist used a variety of techniques, including projection and correlation, to make heads or tails of the predictors, showing creativity in approaching the problem.\n",
      "3. Problem-solving skills: The text mentions that the data scientist was able to successfully reduce the number of variables, accomplishing the client's goal of making the problem space tractable, showing problem-solving skills.\n",
      "4. Flexibility: The text mentions that the data scientist chose to use neural networks for evaluating the weekly variable contributions, showing flexibility in choosing the right approach for the problem.\n",
      "5. Ability to work with diverse data: The text mentions that the predictor variables were quite diverse, including daily, weekly, quarterly, and monthly data, and the data scientist was able to work with this diverse data.\n",
      "\n",
      "These characteristics are relevant to a data science team because they enable the team to effectively handle complex problems, think creatively, and work with diverse data to achieve their goals.\n",
      "\n",
      "Based on the provided text, there is no direct mention of good characteristics for a data science team. However, the text does discuss the importance of model validation and provides some techniques for combating model overfitting.\n",
      "\n",
      "If you're looking for characteristics of a good data science team, here are some general traits that are often considered important:\n",
      "\n",
      "1. Collaboration: Data science teams often consist of individuals with diverse skill sets, and collaboration is key to successful project outcomes.\n",
      "2. Communication: Effective communication is crucial for data science teams to ensure that stakeholders understand the results and insights generated by the team.\n",
      "3. Problem-solving: Data science teams should be able to identify and solve complex problems, often involving large datasets and complex algorithms.\n",
      "4. Creativity: Data science teams should be able to think creatively and come up with innovative solutions to complex problems.\n",
      "5. Attention to detail: Data science teams should be meticulous and detail-oriented, ensuring that data is accurate and reliable.\n",
      "6. Adaptability: Data science teams should be able to adapt to changing project requirements and new technologies.\n",
      "7. Continuous learning: Data science teams should be committed to ongoing learning and professional development, staying up-to-date with the latest tools, techniques, and methodologies.\n",
      "8. Transparency: Data science teams should be transparent in their methods and results, ensuring that stakeholders understand the data and insights generated by the team.\n",
      "9. Business acumen: Data science teams should have a good understanding of the business and be able to communicate insights and recommendations in a way that is relevant and actionable for stakeholders.\n",
      "10. Technical skills: Data science teams should have strong technical skills in areas such as programming, statistics, and machine learning.\n",
      "\n",
      "These are just some of the characteristics that are often considered important for a data science team. The specific characteristics that are most important will depend on the specific needs and goals of the team and organization.\n",
      "\n",
      "Unfortunately, the provided text does not contain any relevant information about the good characteristics for a data science team. The text only contains the title \"PUTTING IT ALL TOGETHER\" and does not provide any content related to data science teams.\n",
      "\n",
      "Based on the provided text, the following characteristics of a data science team are mentioned:\n",
      "\n",
      "* Ability to leverage data-driven approaches and analytics methods to extract information, detect signals, and uncover trends to enhance regulatory decision-making and protect public health.\n",
      "* Ability to conduct cross-study, cross-product, retrospective, and meta-analysis during product reviews.\n",
      "* Ability to fully utilize the agency's expansive data resources for efficient and effective drug review.\n",
      "* Ability to design and develop informatics capabilities based on Natural Language Processing (NLP), data integration, and data visualization methodologies.\n",
      "* Ability to co-locate complex, heterogeneous data to identify patterns and foster development of strategies to protect public health.\n",
      "* Ability to implement NLP algorithms to compare adverse events across datasets, and geographic visualization capabilities to support the inspection of pharmaceutical manufacturing facilities.\n",
      "\n",
      "These characteristics suggest that a good data science team should have the following skills and abilities:\n",
      "\n",
      "* Strong analytical skills to extract insights from large datasets\n",
      "* Ability to work with complex, heterogeneous data\n",
      "* Experience with data integration and visualization\n",
      "* Familiarity with NLP and machine learning algorithms\n",
      "* Ability to conduct cross-study and meta-analysis\n",
      "* Strong communication skills to present findings and recommendations to stakeholders\n",
      "* Ability to work in a fast-paced environment with rapidly changing data and requirements\n",
      "* Strong problem-solving skills to identify and address complex issues\n",
      "\n",
      "It's worth noting that these characteristics may not be exhaustive, and a good data science team may have additional skills and abilities depending on the specific context and requirements.\n",
      "\n",
      "Based on the provided text, the following characteristics of a data science team are mentioned:\n",
      "\n",
      "1. Ability to integrate disparate data sources: The text highlights the importance of integrating various data sources to build a comprehensive profile of manufacturers, facilities, and products.\n",
      "2. Novel methodologies and tools: The team developed novel methodologies and tools to improve the efficiency and efficacy of the product quality-review process.\n",
      "3. Geospatial analysis: The Facility Inventory Report uses geospatial analysis to visualize facility data and provide reviewers with the ability to establish connections between facility data and product quality.\n",
      "4. Data visualization: The text mentions the importance of data visualization in presenting complex data in a user-friendly format, enhancing surveillance capabilities, and providing reviewers with the ability to gain insights from disparate data sources.\n",
      "5. Natural Language Processing (NLP): The team used NLP to extract adverse events from product labels and create a structured table of label data out of unstructured text.\n",
      "6. Collaboration: The text implies that the data science team collaborated with other stakeholders, such as safety evaluators and reviewers, to develop the dashboard and Facility Inventory Report.\n",
      "7. Domain expertise: The team demonstrated domain expertise in the FDA's mission and regulatory processes, as well as in the development of novel methodologies and tools.\n",
      "8. Data-driven decision-making: The text suggests that the data science team's work enables data-driven decision-making, allowing the FDA to enhance regulatory decision-making, drive advances in personalized medicine, and enable earlier detection of safety signals.\n",
      "\n",
      "These characteristics are relevant to a data science team working in a regulatory environment, such as the FDA.\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as important for a data science team:\n",
      "\n",
      "1. Ability to gather and process large amounts of data: The team gathered over 4 TB of data detailing various aspects of flight operations.\n",
      "2. Data quality control and accuracy: The team ensured data quality control and accuracy between disparate datasets.\n",
      "3. Application of supervised learning algorithms: The team applied supervised learning algorithms to develop Bayesian Belief Network (BBN) models to predict flight departure deviation.\n",
      "4. Selection of optimal algorithms: The team selected optimal algorithms to discretize model variables and machine learning techniques to learn the model from the data.\n",
      "5. Information theory principles: The team followed information theory principles to discretize model variables to maximize the model's predictive power and represent the data as closely as possible with the least amount of network complexity.\n",
      "6. Segmentation of model variables: The team segmented the model variables into three different categories based on the time to flight departure: 24 hours, 11 hours, and one hour.\n",
      "\n",
      "These characteristics suggest that a good data science team should have:\n",
      "\n",
      "* Strong data gathering and processing capabilities\n",
      "* Attention to data quality and accuracy\n",
      "* Familiarity with machine learning algorithms and techniques\n",
      "* Ability to apply information theory principles to optimize model performance\n",
      "* Ability to segment and categorize data based on relevant variables\n",
      "\n",
      "These characteristics are relevant to the specific problem of predicting flight departure delays, but may not be exhaustive for all data science projects.\n",
      "\n",
      "Based on the provided text, I couldn't find any direct mention of good characteristics for a data science team. However, I can extract some relevant information that might be indirectly related to the characteristics of a data science team:\n",
      "\n",
      "* \"Improved reliability of departure prediction\" and \"improved real-time traffic flow management\" suggest that the team's work has a significant impact on the efficiency and effectiveness of the air transportation network.\n",
      "* The text mentions the importance of \"proactive schedule adjustments\" and \"better understanding and prediction of network flight delays\", which implies that the team's work requires strong analytical skills, attention to detail, and the ability to make informed decisions.\n",
      "* The phrase \"range of aviation stakeholders\" suggests that the team's work is collaborative and requires effective communication and collaboration with various stakeholders.\n",
      "\n",
      "Some potential characteristics of a data science team that can be inferred from this text include:\n",
      "\n",
      "* Strong analytical skills and attention to detail\n",
      "* Ability to work collaboratively with various stakeholders\n",
      "* Effective communication and collaboration skills\n",
      "* Ability to make informed decisions based on data analysis\n",
      "* Strong problem-solving skills\n",
      "* Ability to adapt to changing circumstances and make proactive adjustments\n",
      "\n",
      "Please note that these characteristics are inferred and may not be directly mentioned in the provided text.\n",
      "\n",
      "Based on the provided text, the following characteristics of a data science team are highlighted:\n",
      "\n",
      "1. **Collaboration**: The team worked with the FDA Center for Biologics Evaluation and Research (CBER) to develop advanced analytics approaches for the triage and analysis of Adverse Event (AE) reports.\n",
      "2. **Domain expertise**: The team had expertise in biologics, including vaccines, blood and blood products, and worked closely with Medical Officers to develop solutions.\n",
      "3. **Technical skills**: The team leveraged advanced analytics approaches, including Natural Language Processing (NLP), network analysis, and text mining, to develop prototypes for the analysis and visualization of complex structured and unstructured AE datasets.\n",
      "4. **Problem-solving**: The team designed and developed tools to address the challenges of manual review of AE reports, including the development of a text-mining tool and an AE network analysis tool.\n",
      "5. **Communication**: The team provided decision-makers with important information concerning product risks and possible mitigations that can reduce risk, indicating effective communication of findings and insights.\n",
      "6. **Adaptability**: The team was able to adapt to the changing needs of the FDA, developing solutions that could scale to short-term workload variation and long-term improvements in review cycle-time.\n",
      "7. **Innovative thinking**: The team developed novel approaches to address the challenges of AE report analysis, including the use of NLP and network analysis to identify patterns and trends in the data.\n",
      "\n",
      "These characteristics are relevant to a data science team working on a project that involves:\n",
      "\n",
      "* Collaboration with stakeholders to understand their needs and develop solutions\n",
      "* Domain expertise in the field of biologics and vaccines\n",
      "* Technical skills in advanced analytics approaches, including NLP and network analysis\n",
      "* Problem-solving skills to address complex challenges in data analysis and visualization\n",
      "* Effective communication of findings and insights to stakeholders\n",
      "* Adaptability to changing project requirements and timelines\n",
      "* Innovative thinking to develop novel solutions to complex problems.\n",
      "\n",
      "Based on the provided text, the following characteristics of a data science team are highlighted:\n",
      "\n",
      "1. **Innovative approaches**: The team developed \"innovative and data-driven approaches for the analysis of structured and unstructured AE reports.\"\n",
      "2. **Data-driven**: The team's work is characterized as \"data-driven,\" suggesting a focus on using data to inform decisions and drive insights.\n",
      "3. **Collaboration**: The team worked with CBER reviewers and Medical Officers to develop solutions, indicating a collaborative approach.\n",
      "4. **Speed and efficiency**: The team increased the speed of text mining tools by 2000 times, allowing for faster analysis and decision-making.\n",
      "5. **Productivity**: The team's work increased the productivity of Medical Officers through the implementation of text mining and network analysis tools.\n",
      "6. **Streamlined processes**: The team's solutions allowed CBER to streamline the post-market review process, suggesting a focus on efficiency and effectiveness.\n",
      "7. **Domain expertise**: The team demonstrated domain expertise in the field of biologics and vaccine safety, as evidenced by their work on the BSE agent simulation model and the development of a database analysis strategy involving genomic data.\n",
      "\n",
      "These characteristics suggest that a good data science team should be:\n",
      "\n",
      "* Innovative and adaptable\n",
      "* Data-driven and analytical\n",
      "* Collaborative and communicative\n",
      "* Focused on speed and efficiency\n",
      "* Productive and effective\n",
      "* Able to streamline processes and improve workflows\n",
      "* Domain experts with a deep understanding of the problem domain\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Given the following extracted parts of a long document and a question, create a final answer. \n",
      "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
      "______________________\n",
      "Based on the provided text, the following characteristics of a data science team are highlighted:\n",
      "\n",
      "1. Interdisciplinary teams: The team consisted of software engineers, data analysts, and social scientists, indicating a diverse range of skills and expertise.\n",
      "2. Collaboration: The team worked together for 12 hours, identifying new datasets, building machine learning models, and creating frameworks for ensemble modeling and interactive results visualization.\n",
      "3. Innovation: The team was encouraged to explore new and innovative approaches for the statistical risk assessment, indicating a culture of experimentation and creativity.\n",
      "4. Crowdsourcing: The team was part of a hack-a-thon, which involved a large number of employees (over 80) participating in the project, demonstrating the power of crowdsourcing and collective effort.\n",
      "5. Flexibility: The team was able to adapt and refine their recommendations over time, indicating a willingness to iterate and improve their work.\n",
      "6. Data management: The team created a data management framework to automate the download, aggregation, and transformation of open-source datasets, demonstrating attention to data quality and management.\n",
      "\n",
      "These characteristics suggest that a good data science team should:\n",
      "\n",
      "* Be interdisciplinary and collaborative\n",
      "* Encourage innovation and experimentation\n",
      "* Leverage crowdsourcing and collective effort\n",
      "* Be flexible and willing to iterate\n",
      "* Prioritize data quality and management\n",
      "\n",
      "These characteristics can help a data science team to be effective, efficient, and innovative in their work.\n",
      "\n",
      "Based on the provided text, the following characteristics of a data science team are highlighted:\n",
      "\n",
      "1. **Extensibility**: The ability to integrate new datasets with minimal effort, supporting greater engagement by the Data Science community.\n",
      "2. **Collaboration**: The project's success is attributed to the integration of statistical risk assessment models and expert opinion pool, demonstrating the importance of collaboration between different disciplines.\n",
      "3. **Innovative thinking**: The hack-a-thon's machine learning models achieved performance on par with state-of-the-art approaches, and teams identified new approaches for constructing test/validation sets.\n",
      "4. **Adaptability**: The data management framework developed from the hack-a-thon represents a great leap forward for the Holocaust Museum, allowing for more up-to-date data and reduced burden on researchers.\n",
      "5. **Community engagement**: The project's extensible framework will allow the Holocaust Museum to seamlessly integrate new datasets as they become available or are identified by the community as holding analytic value for the problem at hand.\n",
      "6. **Predictive capabilities**: The Early Warning Project is able to predict the potential for mass atrocities around the world, demonstrating the team's ability to develop predictive models.\n",
      "7. **Interdisciplinary approach**: The project integrates advanced quantitative and qualitative analyses, highlighting the importance of an interdisciplinary approach in data science.\n",
      "\n",
      "These characteristics suggest that a good data science team should be:\n",
      "\n",
      "* Able to adapt to new datasets and technologies\n",
      "* Collaborative and open to different perspectives\n",
      "* Innovative and willing to try new approaches\n",
      "* Engaged with the community and willing to integrate new ideas and datasets\n",
      "* Able to develop predictive models and provide valuable insights\n",
      "* Interdisciplinary, with a willingness to combine different methods and expertise.\n",
      "\n",
      "Based on the provided text, the following characteristics are relevant to a data science team:\n",
      "\n",
      "* Collaboration: The text mentions \"Working closely with IHG experts\" and \"Booz Allen investigated three key elements related to different stages of analytic maturity\", indicating the importance of collaboration between data scientists and stakeholders.\n",
      "* Problem-solving: The text describes the challenge of predicting customer response to a promotional campaign and the team's approach to addressing this challenge, highlighting the problem-solving skills required of a data science team.\n",
      "* Analytical thinking: The text mentions \"initial data mining\", \"data mining\", and \"predicting customer-by-customer impacts\", indicating the importance of analytical thinking and data analysis skills.\n",
      "* Creativity: The text mentions the use of \"probabilistic Bayesian Belief Network (BBN)\" and \"six machine learning techniques\" to model and predict customer behavior, indicating the need for creative thinking and experimentation.\n",
      "* Communication: The text assumes that the data science team will be able to communicate their findings and insights to stakeholders, highlighting the importance of effective communication.\n",
      "\n",
      "Here is the relevant text:\n",
      "\n",
      "\"It is very challenging to know how a customer will respond to a given promotional campaign. Together with the InterContinental Hotels Group (IHG), Booz Allen Hamilton explored approaches to predict customer-by-customer response to a state-of-the-art promotional campaign in order to better understand and increase return on investment (ROI).\n",
      "\n",
      "Working closely with IHG experts, Booz Allen investigated three key elements related to different stages of analytic maturity:\n",
      "\n",
      "* Describe: Using initial data mining, what insights or tendencies in guest behaviors can be identified after joining multiple, disparate datasets?\n",
      "* Discover: Can we determine which control group members would be likely to register for a promotion if offered? If so, can we also quantify their registration?\n",
      "* Predict: How would a hotel guest that received the promotion have responded if they were not offered the promotion? How would a hotel guest that did not receive the promotion have responded if they were offered the promotion?\n",
      "\n",
      "For the promotion that was the focus of this case study, not everything about customers could be controlled as required by traditional statistics. However, because a probabilistic Bayesian Belief Network (BBN) can learn the pairwise relationships between all individual customer attributes and their impact on promotional return, Booz Allen investigated how this technique could be used to model each treated customer without an exact controlled look-alike.\n",
      "\n",
      "Specifically, Booz Allen developed a BBN to predict customer-by-customer impacts driven by promotional campaign offers, subsequently estimating the aggregated ROI of individual campaigns. We used six machine learning techniques (support vector machine, random forest, decision tree, neural network, linear model, and AdaBoost) in unison with the BBN to predict how each customer would be influenced by a promotional offer.\"\n",
      "\n",
      "Based on the provided text, the following characteristics are relevant to a data science team:\n",
      "\n",
      "* Data-driven approaches: The text highlights the importance of data-driven approaches to optimize marketing ROI at an individual level.\n",
      "* Ability to estimate ROI: The team's approach enabled estimation of ROI for each hypothetical customer, even when no exact look-alikes exist.\n",
      "* Optimal campaign design: The team's approach allows for the estimation of promotional attributes for an individual customer that are likely to drive the greatest incremental spend.\n",
      "* Efficient audience selection: The team's approach can reduce the risk of marketing \"spam\" that prompts costly unsubscriptions and can negatively impact a hotel's brand.\n",
      "\n",
      "These characteristics suggest that a good data science team should have the following skills and abilities:\n",
      "\n",
      "* Strong analytical skills to develop data-driven approaches\n",
      "* Ability to estimate ROI and make data-informed decisions\n",
      "* Knowledge of marketing and customer behavior to design effective campaigns\n",
      "* Ability to select the right audience for marketing campaigns to maximize ROI\n",
      "* Strong communication skills to present findings and recommendations to stakeholders\n",
      "\n",
      "Here is the relevant text:\n",
      "\n",
      "* \"This analysis is an industry-first for the travel and hospitality sector, where demand for more data-driven approaches to optimize marketing ROI at an individual level is rapidly growing.\"\n",
      "* \"Because Booz Allen and IHG’s approach enabled estimation of ROI for each hypothetical customer, even when no exact look-alikes exist, there are a number of valuable future applications.\"\n",
      "* \"One such application is optimal campaign design—the ability to estimate the promotional attributes for an individual customer that are likely to drive the greatest incremental spend.\"\n",
      "* \"Another application is efficient audience selection - which would reduce the risk of marketing “spam” that prompts costly unsubscriptions and can negatively impact a hotel’s brand.\"\n",
      "\n",
      "Unfortunately, the provided text does not contain any relevant information about the good characteristics for a data science team. The text only mentions \"CLOSING TIME\", which appears to be a heading or a label, but does not provide any information about data science teams.\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as desirable for a data science team:\n",
      "\n",
      "1. Ability to work with massive-scale graph analytics algorithms and graph databases.\n",
      "2. Familiarity with geospatial temporal predictive analytics and its applications in various domains.\n",
      "3. Knowledge of advanced Data Science algorithms that take advantage of technological advancements in:\n",
      "\t* Quantum machine-learning\n",
      "\t* In-memory data operations\n",
      "\t* Machine learning on specialized devices (e.g., GPU, Raspberry Pi, or next-generation mobile handheld \"supercomputer\")\n",
      "4. Experience with embedded machine learning (specifically, deep learning) algorithms that perform time-critical data-to-insights transformations at the point of data collection.\n",
      "5. Understanding of cognitive machine learning, including open source and configurable algorithms that exploit streaming real-time data's full content, context, and semantic meaning.\n",
      "6. Ability to work with 360-degree views of situations and deliver the right action, at the right time, at the right place, in the right context.\n",
      "7. Familiarity with identifying the right question to ask of the data, rather than relying on traditional questions.\n",
      "\n",
      "These characteristics suggest that a good data science team should be:\n",
      "\n",
      "* Versatile and able to work with different types of data and algorithms\n",
      "* Familiar with cutting-edge technologies and advancements\n",
      "* Able to work with complex and large-scale datasets\n",
      "* Experienced in applying machine learning and deep learning techniques\n",
      "* Able to think critically and identify the right questions to ask of the data\n",
      "* Able to work with real-time data and deliver insights quickly\n",
      "\n",
      "Note that these characteristics are based on the specific text provided and may not be exhaustive or universally applicable.\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as important for a data science team:\n",
      "\n",
      "* Ability to work with unstructured data, specifically text\n",
      "* Richer algorithms for processing unstructured data\n",
      "* Ability to convert qualitative data into machine-computable quantitative data\n",
      "* Application of new Data Science algorithms in multiple directions, such as:\n",
      "\t+ Natural Language Generation\n",
      "\t+ Structured Database Generation\n",
      "\t+ Cybersecurity\n",
      "\t+ Healthcare\n",
      "\t+ IoT\n",
      "\t+ Customer Engagement and Experience\n",
      "\t+ Smart X (cities, highways, cars, delivery systems, supply chain, etc.)\n",
      "\t+ Precision Y (medicine, farming, harvesting, manufacturing, pricing, etc.)\n",
      "\t+ Personalized Z (marketing, advertising, healthcare, learning, etc.)\n",
      "\t+ Human capital (talent) and organizational analytics\n",
      "\t+ Societal good\n",
      "\n",
      "These characteristics suggest that a good data science team should be able to:\n",
      "\n",
      "* Work with diverse types of data, including unstructured text data\n",
      "* Develop and apply advanced algorithms to process and analyze data\n",
      "* Convert qualitative data into quantitative data for machine learning and analysis\n",
      "* Apply data science techniques to various domains and industries\n",
      "* Stay up-to-date with the latest advancements and trends in data science\n",
      "\n",
      "Note that these characteristics are not exhaustive, and other important skills and qualities may be necessary for a data science team to be successful.\n",
      "\n",
      "Unfortunately, the provided text does not mention specific characteristics for a data science team. However, I can provide some general characteristics that are commonly considered important for a data science team:\n",
      "\n",
      "* Curiosity: A data science team should be curious and passionate about exploring and understanding data.\n",
      "* Collaboration: Data science is a team effort, and a successful team should be able to work collaboratively and communicate effectively.\n",
      "* Creativity: Data science requires creative thinking and problem-solving skills to extract insights from data.\n",
      "* Analytical skills: A data science team should have strong analytical skills, including statistical knowledge and programming skills.\n",
      "* Business acumen: Data science teams should have a good understanding of the business and be able to communicate insights to stakeholders.\n",
      "* Adaptability: Data science is a rapidly evolving field, and a successful team should be able to adapt to new tools, technologies, and methodologies.\n",
      "* Passion for learning: A data science team should be committed to ongoing learning and professional development.\n",
      "* Strong communication skills: Data science teams should be able to effectively communicate complex technical information to non-technical stakeholders.\n",
      "* Attention to detail: Data science requires attention to detail and a focus on accuracy and precision.\n",
      "* Ability to work with ambiguity: Data science often involves working with incomplete or uncertain data, and a successful team should be able to work with ambiguity and uncertainty.\n",
      "\n",
      "These are just some of the characteristics that are commonly considered important for a data science team.\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Given the following extracted parts of a long document and a question, create a final answer. \n",
      "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
      "______________________\n",
      "Unfortunately, the provided text does not mention the good characteristics for a data science team. However, I can provide you with some general characteristics that are commonly considered important for a data science team:\n",
      "\n",
      "1. Collaboration: Data science teams should be able to work together effectively, combining their skills and expertise to achieve common goals.\n",
      "2. Communication: Clear and effective communication is crucial for data science teams, as they need to be able to explain complex technical concepts to non-technical stakeholders.\n",
      "3. Curiosity: Data science teams should be curious and passionate about exploring and understanding data, and be willing to ask questions and challenge assumptions.\n",
      "4. Creativity: Data science teams should be able to think creatively and come up with innovative solutions to complex problems.\n",
      "5. Analytical skills: Data science teams should have strong analytical skills, including statistical knowledge, programming skills, and data visualization expertise.\n",
      "6. Business acumen: Data science teams should have a good understanding of the business and be able to communicate the value of their work to stakeholders.\n",
      "7. Flexibility: Data science teams should be flexible and able to adapt to changing requirements and priorities.\n",
      "8. Continuous learning: Data science teams should be committed to continuous learning and professional development, staying up-to-date with the latest tools, techniques, and methodologies.\n",
      "9. Attention to detail: Data science teams should be meticulous and detail-oriented, ensuring that their work is accurate and reliable.\n",
      "10. Strong project management: Data science teams should have strong project management skills, including the ability to prioritize tasks, manage timelines, and coordinate with other teams.\n",
      "\n",
      "These characteristics are not exhaustive, and the specific needs of a data science team may vary depending on the organization, industry, and project requirements.\n",
      "\n",
      "Unfortunately, the provided text does not contain any information about the good characteristics for a data science team. The text appears to be a list of references to academic papers, books, and online resources related to data science and machine learning.\n",
      "\n",
      "However, I can provide you with some general characteristics that are commonly considered important for a data science team:\n",
      "\n",
      "1. Collaboration: Data science teams should be able to work collaboratively, sharing knowledge and expertise to achieve common goals.\n",
      "2. Communication: Effective communication is crucial for data science teams, as they need to be able to explain complex technical concepts to non-technical stakeholders.\n",
      "3. Problem-solving: Data science teams should be able to approach problems in a systematic and analytical way, using data to inform their decisions.\n",
      "4. Creativity: Data science teams should be able to think creatively and come up with innovative solutions to complex problems.\n",
      "5. Adaptability: Data science teams should be able to adapt quickly to changing requirements and new technologies.\n",
      "6. Domain expertise: Data science teams should have a deep understanding of the domain they are working in, including the business, industry, or field.\n",
      "7. Technical skills: Data science teams should have strong technical skills in areas such as programming, statistics, and machine learning.\n",
      "8. Data literacy: Data science teams should be able to work with large datasets and understand the importance of data quality and integrity.\n",
      "9. Business acumen: Data science teams should have a good understanding of the business and be able to communicate the value of their work to stakeholders.\n",
      "10. Continuous learning: Data science teams should be committed to continuous learning and professional development, staying up-to-date with the latest technologies and methodologies.\n",
      "\n",
      "These are just some of the characteristics that are commonly considered important for a data science team. The specific characteristics that are most important will depend on the specific needs and goals of the team.\n",
      "\n",
      "Unfortunately, the provided text does not mention good characteristics for a data science team. The text appears to be an introduction to Booz Allen Hamilton, a management and technology consulting firm, and does not discuss data science teams specifically.\n",
      "\n",
      "If you're looking for information on good characteristics for a data science team, I can provide some general insights:\n",
      "\n",
      "1. Collaboration: Data science teams should be able to work effectively together, combining their diverse skills and expertise to achieve common goals.\n",
      "2. Communication: Clear and effective communication is crucial for data science teams, as they need to convey complex technical information to both technical and non-technical stakeholders.\n",
      "3. Problem-solving: Data science teams should be able to approach problems in a structured and methodical way, using data-driven insights to inform their decisions.\n",
      "4. Adaptability: Data science teams should be able to adapt quickly to changing requirements, new technologies, and shifting priorities.\n",
      "5. Continuous learning: Data science teams should prioritize ongoing learning and professional development, staying up-to-date with the latest tools, techniques, and methodologies.\n",
      "6. Data-driven decision-making: Data science teams should be able to use data to inform their decisions, rather than relying on intuition or anecdotal evidence.\n",
      "7. Transparency: Data science teams should be transparent in their methods, results, and assumptions, ensuring that stakeholders understand the basis for their recommendations.\n",
      "8. Creativity: Data science teams should be able to think creatively, developing innovative solutions to complex problems.\n",
      "9. Attention to detail: Data science teams should be meticulous in their work, ensuring that their results are accurate, reliable, and actionable.\n",
      "10. Business acumen: Data science teams should have a good understanding of the business context and be able to communicate their findings in a way that resonates with stakeholders.\n",
      "\n",
      "These are just a few examples of the good characteristics for a data science team. If you're looking for more information, I'd be happy to help!\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Given the following extracted parts of a long document and a question, create a final answer. \n",
      "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
      "______________________\n",
      "Based on the provided text, the good characteristics for a data science team are:\n",
      "\n",
      "1. **Collaboration**: The team should consist of individuals with diverse backgrounds, including computer scientists, mathematicians, and domain experts.\n",
      "2. **Ability to produce new insights and analysis paths**: A good data science team should be able to generate new and valuable insights from data.\n",
      "3. **Breadth of experience**: A team with experience working with clients across various domains can provide a unique perspective on data science.\n",
      "4. **Multidisciplinary team**: The team should consist of individuals with diverse backgrounds, including computer scientists, mathematicians, and domain experts.\n",
      "5. **Ability to shift between deductive (hypothesis-based) and inductive (pattern-based) reasoning**: A good data science team should be able to combine the ability to reason deductively and inductively, creating an environment where models of reality are constantly tested, updated, and improved until better models are found.\n",
      "6. **Power of Many vs. Ability of One**: An entire team provides a common forum for pulling together computer science, mathematics, and domain expertise.\n",
      "7. **Embracing Data Science to maintain competitiveness in the increasingly data-rich environment**: A good data science team should be proactive in adopting Data Science to stay ahead of the competition.\n",
      "8. **Making informed decisions with real information through the application of Data Science**: A good data science team should use data-driven insights to inform their decisions.\n",
      "9. **Being able to access and make use of data at scale**: A good data science team should have the ability to collect, process, and analyze large amounts of data.\n",
      "10. **Being able to keep pace with market demands**: A good data science team should be agile and able to adapt quickly to changing market conditions.\n",
      "11. **Consolidating data and distilling answers**: Instead of building data silos, a data science team should aim to consolidate data and provide actionable insights.\n",
      "12. **Making maximum use of all available data**: A data science team should strive to utilize all available data to help the organization succeed, rather than leaving opportunities untapped.\n",
      "13. **Transforming data into insights**: Data science teams should transform data into actionable insights that can improve existing processes and drive business value.\n",
      "14. **Incorporating complex interrelationships in data**: Effective data science teams should be able to identify and incorporate complex relationships in data to drive better decision-making.\n",
      "\n",
      "These characteristics suggest that a good data science team should be able to:\n",
      "\n",
      "* Work collaboratively and effectively with stakeholders\n",
      "* Generate new and valuable insights from data\n",
      "* Stay ahead of the competition by adopting Data Science\n",
      "* Use data-driven insights to inform their decisions\n",
      "* Collect, process, and analyze large amounts of data\n",
      "* Adapt quickly to changing market conditions\n",
      "* Provide actionable insights that drive business value\n",
      "* Identify and incorporate complex relationships in data\n",
      "* Stay ahead of competitors by leveraging data science to gain insights and drive innovation.\n",
      "\n",
      "Based on the provided text, the good characteristics for a data science team are:\n",
      "\n",
      "1. Effective: The team analyzes its data with a purpose, aiming to turn data into actions.\n",
      "2. Analytical: The team is able to analyze data to gain insights and make informed decisions.\n",
      "3. Collaborative: The team works together to achieve common goals, with a focus on converting insights into action.\n",
      "4. Adaptable: The team is able to adapt to changing circumstances and challenges.\n",
      "5. Innovative: The team is able to think creatively and come up with new solutions.\n",
      "6. Data-driven: The team uses data to inform its decisions and actions.\n",
      "7. Action-oriented: The team is able to take action based on its insights and analysis.\n",
      "\n",
      "Additionally, the text mentions the following characteristics as good for a data science team:\n",
      "\n",
      "* Embracing diversity: Trying to engage and connect to publicly available sources of data that may have relevance to your domain area.\n",
      "* Focusing on the right data: Not collecting all available data, but focusing on the data with the highest ROI for the organization.\n",
      "* Striking a balance: Collecting the right amount of data, not too much or too little, and ensuring that it is the data that is needed.\n",
      "\n",
      "Other characteristics mentioned as good for a data science team include:\n",
      "\n",
      "* Ability to explore and analyze all the data\n",
      "* Ability to gain insights from new opportunities for analysis and data-driven decision making\n",
      "* Ability to prepare data for analysis using a Data Lake approach, which eliminates the need for expensive and cumbersome data-preparation processes.\n",
      "* Iterative application of specialized and scalable computational resources and tools to provide relevant insights from exponentially growing data.\n",
      "* Ability to find connections and patterns in data to identify promising opportunities.\n",
      "* Ability to dive into the data lake to discover new connections and patterns, rather than relying on older sampling methods.\n",
      "* Ability to make sense of the analysis with relatively little up-front training or preparation on the part of the decision maker.\n",
      "* Ability to make the most meaningful patterns, trends, and exceptions easy to see and interpret.\n",
      "* Effort to encode quantitative data accurately so the decision maker can accurately interpret and compare the data.\n",
      "* Clear and compelling logic used to arrive at the finding, with the ability to trace it back through the data.\n",
      "* Ability to answer real business questions.\n",
      "* Repeatable processes: The ability to adapt and repeat their processes with each new project or endeavor.\n",
      "* Evolutionary processes: The ability to evolve and improve their processes over time, reducing the effort required for each activity.\n",
      "* Assessing maturity: The ability to assess and evaluate their own capabilities and processes.\n",
      "\n",
      "It's worth noting that the provided text is more focused on the maturity stages of a Data Science capability within an organization, rather than specific characteristics of a data science team.\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as important for a data science team:\n",
      "\n",
      "1. **Collaboration**: Data science teams should be able to work together effectively, sharing knowledge and expertise to achieve common goals.\n",
      "2. **Communication**: Clear and effective communication is crucial for data science teams, both within the team and with stakeholders.\n",
      "3. **Curiosity**: Data scientists should be curious and passionate about exploring data and uncovering insights.\n",
      "4. **Creativity**: Data science teams should be able to think creatively and come up with innovative solutions to complex problems.\n",
      "5. **Analytical skills**: Data scientists should have strong analytical skills, including statistical knowledge, programming skills, and data visualization expertise.\n",
      "6. **Domain expertise**: Data science teams should have a good understanding of the business domain and be able to apply data science techniques to solve real-world problems.\n",
      "7. **Adaptability**: Data science teams should be able to adapt quickly to changing requirements, new technologies, and shifting priorities.\n",
      "8. **Continuous learning**: Data science teams should be committed to ongoing learning and professional development, staying up-to-date with the latest tools, techniques, and methodologies.\n",
      "9. **Attention to detail**: Data science teams should be meticulous and detail-oriented, ensuring that data is accurate, reliable, and well-documented.\n",
      "10. **Business acumen**: Data science teams should have a good understanding of the business goals and objectives, and be able to communicate insights and recommendations effectively to stakeholders.\n",
      "\n",
      "Additionally, the text also mentions the following characteristics:\n",
      "\n",
      "1. **Reason and common sense**: Data science teams should approach problems with a logical and rational mindset.\n",
      "2. **Skepticism**: Be cautious of surprise findings and verify the accuracy of conclusions.\n",
      "3. **Clear communication**: Articulate the problem being solved and the approach being taken, and ensure that the answer is clear and understandable.\n",
      "4. **Discipline**: Write out the analytic plan and document assumptions and biases to ensure transparency and accountability.\n",
      "5. **Validation**: Verify that the instructions provided to the computer are correct and intended, and that the analysis addresses the original intent.\n",
      "6. **Storytelling**: Present the findings in a clear and actionable story, and identify potential holes in the story to avoid surprises.\n",
      "7. **Continuous improvement**: Document what was learned and why changes were made, and be open to revising the plan based on new information.\n",
      "8. **Collaboration**: Test answers with a friendly audience to ensure that findings hold water.\n",
      "\n",
      "These characteristics can help a data science team to be successful and effective in their work.\n",
      "\n",
      "Based on the provided text, the good characteristics for a data science team are not explicitly mentioned. However, some relevant points that can be inferred from the text include:\n",
      "\n",
      "1. Collaboration: Data science teams should be able to work together effectively, combining their skills and expertise to achieve common goals.\n",
      "2. Adaptability: Data science teams should be able to adapt to changing requirements, new data sources, and evolving business needs.\n",
      "3. Analytical skills: Data science teams should possess strong analytical skills, including the ability to design and implement effective learning models.\n",
      "4. Communication skills: Data science teams should be able to effectively communicate their findings and insights to stakeholders, both technical and non-technical.\n",
      "5. Problem-solving skills: Data science teams should be able to identify and solve complex problems, using a combination of data analysis, machine learning, and domain expertise.\n",
      "6. Continuous learning: Data science teams should be committed to continuous learning, staying up-to-date with the latest developments in machine learning, data science, and related fields.\n",
      "7. Flexibility: Data science teams should be able to work with different data sources, formats, and tools, and be flexible in their approach to problem-solving.\n",
      "8. Creativity: Data science teams should be able to think creatively, developing innovative solutions to complex problems.\n",
      "9. Attention to detail: Data science teams should be meticulous in their work, ensuring that their models are accurate, reliable, and well-documented.\n",
      "10. Business acumen: Data science teams should have a good understanding of the business context and be able to apply their skills to drive business value.\n",
      "\n",
      "Additionally, some other characteristics that are generally considered important for a data science team include:\n",
      "\n",
      "* Strong programming skills in languages like Python, R, or SQL\n",
      "* Experience with data visualization tools like Tableau, Power BI, or D3.js\n",
      "* Knowledge of machine learning algorithms and statistical modeling\n",
      "* Familiarity with data storage solutions like relational databases, NoSQL databases, or data warehouses\n",
      "* Strong communication and collaboration skills\n",
      "* Ability to work with stakeholders to understand business needs and develop data-driven solutions\n",
      "* Experience with data quality and data governance best practices\n",
      "* Stay up-to-date with industry trends and advancements in data science and analytics.\n",
      "\n",
      "Please note that these are general characteristics and may vary depending on the specific needs and goals of the organization.\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Given the following extracted parts of a long document and a question, create a final answer. \n",
      "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
      "______________________\n",
      "Based on the provided text, the following characteristics are mentioned as good for a data science team:\n",
      "\n",
      "1. **Pattern recognition**: The team was able to identify patterns and relationships in the data, which is a key skill for data scientists.\n",
      "2. **Efficient data processing**: The team was able to quickly and accurately compare the lists of domains, which suggests that they were able to efficiently process large amounts of data.\n",
      "3. **Attention to detail**: The team was able to identify a spoofed domain within 48 hours, which implies that they were able to carefully examine the data and identify subtle differences.\n",
      "4. **Collaboration**: The team was able to work together to decompose the problem and develop a solution, which is an important aspect of data science.\n",
      "5. **Adaptability**: The team was able to re-evaluate their approach and derive a new solution when the initial approach proved to be too complex, which suggests that they were able to adapt to changing circumstances.\n",
      "6. **Domain expertise**: The team had a good understanding of the problem domain and was able to develop a solution that was tailored to the specific needs of the company.\n",
      "7. **Communication**: The team was able to effectively communicate their approach and results to stakeholders, as evidenced by the inclusion of a figure in the report.\n",
      "\n",
      "Additionally, some common characteristics that are often considered important for a data science team include:\n",
      "\n",
      "1. **Collaboration**: Data science teams should be able to work together effectively, sharing knowledge and expertise to achieve common goals.\n",
      "2. **Communication**: Clear and effective communication is crucial for data science teams, both within the team and with stakeholders.\n",
      "3. **Curiosity**: Data science teams should be curious and passionate about exploring and understanding data.\n",
      "4. **Creativity**: Data science teams should be able to think creatively and come up with innovative solutions to complex problems.\n",
      "5. **Analytical skills**: Data science teams should have strong analytical skills, including statistical knowledge, programming skills, and data visualization expertise.\n",
      "6. **Business acumen**: Data science teams should have a good understanding of the business and be able to communicate insights and recommendations to stakeholders.\n",
      "7. **Adaptability**: Data science teams should be able to adapt quickly to changing requirements and new technologies.\n",
      "8. **Continuous learning**: Data science teams should be committed to continuous learning and professional development, staying up-to-date with the latest tools, techniques, and methodologies.\n",
      "9. **Domain expertise**: Data science teams should have a good understanding of the domain or industry they are working in, including the business processes, regulations, and stakeholders.\n",
      "10. **Transparency**: Data science teams should be transparent in their work, including data collection, processing, and analysis, as well as their findings and recommendations.\n",
      "\n",
      "These characteristics can help a data science team to be effective, efficient, and successful in their work.\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as good for a data science team:\n",
      "\n",
      "1. **Collaboration**: The text mentions \"Collaborative Filtering\" as a technique, suggesting that collaboration is an important aspect of a data science team.\n",
      "2. **Domain expertise**: The text mentions the importance of understanding the underlying distributions of interest in the context of Markov Chain Monte Carlo (MCMC) methods, suggesting that a data science team should have a deep understanding of the domain they are working in.\n",
      "3. **Statistical knowledge**: The text highlights the importance of statistical knowledge in the context of regression with shrinkage (Lasso) and sensitivity analysis, suggesting that a data science team should have strong statistical knowledge.\n",
      "4. **Programming skills**: The text mentions the importance of programming skills in the context of Monte Carlo methods and neural networks, suggesting that a data science team should have strong programming skills.\n",
      "5. **Data analysis skills**: The text highlights the importance of data analysis skills in the context of data mining and knowledge discovery, suggesting that a data science team should have strong data analysis skills.\n",
      "6. **Problem-solving skills**: The text mentions the importance of problem-solving skills in the context of outlier removal and sensitivity analysis, suggesting that a data science team should be able to identify and solve complex problems.\n",
      "7. **Communication skills**: The text does not explicitly mention communication skills, but it does highlight the importance of presenting results in the context of data visualization, suggesting that a data science team should be able to effectively communicate complex technical information to both technical and non-technical stakeholders.\n",
      "\n",
      "Some additional characteristics that are commonly considered important for a data science team include:\n",
      "\n",
      "1. **Business acumen**: Understanding the business goals and objectives of the organization and being able to communicate the value of data science insights to stakeholders.\n",
      "2. **Creativity**: Being able to think creatively and come up with innovative solutions to complex problems.\n",
      "3. **Adaptability**: Being able to adapt to changing requirements and priorities, and being able to pivot when necessary.\n",
      "4. **Attention to detail**: Being meticulous and detail-oriented in data analysis and modeling.\n",
      "5. **Teamwork**: Being able to work collaboratively with other team members and stakeholders to achieve common goals.\n",
      "6. **Continuous learning**: Being committed to ongoing learning and professional development, and staying up-to-date with the latest methods and technologies in data science.\n",
      "\n",
      "These characteristics may vary depending on the specific context and goals of the data science team.\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as good for a data science team:\n",
      "\n",
      "1. Creativity: The team was able to \"creatively combine and build 'features on features'\" to create new representations of data that were richer and more descriptive.\n",
      "2. Complexity: The approach was \"multi-staged and complex\" involving multiple stages such as generating sub-graphs, creating bloom filters, calculating distance metrics, and fitting a linear-regression model.\n",
      "3. Sophistication: The team was able to produce a sophisticated feature representation by combining and building features.\n",
      "4. Ability to work with complex data: The team was able to work with complex 3D structures, which are typically represented as a list of atoms joined by chemical bonds of differing lengths with varying electron domain and molecular geometries.\n",
      "5. Ability to develop innovative solutions: The team developed a solution based on previous work in molecular fingerprinting, which is a dimensionality reduction technique that dramatically reduces the problem space by summarizing many features.\n",
      "6. Ability to use heuristic approaches: The team used heuristic approaches such as fingerprinting when an exact solution is likely to be infeasible.\n",
      "7. Ability to work with large datasets: The team worked with a large dataset of molecules and their properties.\n",
      "8. Ability to develop models: The team developed a model of how molecular structural similarities might affect their properties.\n",
      "9. Ability to use non-linear regression: The team used non-linear regression to approximate the shape of the hidden manifold and predict the properties of new molecules.\n",
      "10. Ability to collaborate: The team worked together to develop the solution, with each member contributing their expertise and skills.\n",
      "\n",
      "Additionally, the following characteristics are mentioned as good for a data science team:\n",
      "\n",
      "1. Diversity: The text mentions that ensemble models benefit from the diversity of their members, implying that a diverse team with different perspectives and strengths can lead to better results.\n",
      "2. Collaboration: The quote \"None of us is as smart as all of us, but some are smarter than others\" suggests that collaboration and sharing knowledge can lead to better outcomes.\n",
      "3. Ability to balance individual strengths and weaknesses: The text notes that ensemble models can overcome individual weaknesses by combining the predictions of multiple models, implying that a data science team should be able to recognize and balance the strengths and weaknesses of its individual members.\n",
      "4. Ability to manage complexity: The text mentions that ensembling can improve accuracy but also increases complexity, suggesting that a data science team should be able to manage and balance the complexity of their models and methods.\n",
      "5. Ability to balance interpretability and black-box complexity: The text notes that high-stakes problems require higher standards for auditing model functionality, implying that a data science team should be able to balance the need for interpretability with the need for complex models.\n",
      "6. Diversity of models: The text highlights the importance of including diverse models in an ensemble to cancel out errors and achieve a lower score.\n",
      "7. Thoughtfulness in selecting individual models: The text emphasizes the need to be thoughtful when selecting individual models for an ensemble, as introducing less accurate models can lead to an increase in the ensemble score.\n",
      "8. Domain expertise: The text emphasizes the importance of understanding the data origins and context, which suggests that domain expertise is crucial for a data science team.\n",
      "9. Experience: The text mentions relying on experience when assessing data truthfulness, which implies that experience is valuable for a data science team.\n",
      "10. Flexibility: The text suggests that a data science team should be willing to try different approaches and not get stuck on a single method, as seen in the quote \"Find an approach that works, implement it, and move on. You can worry about optimization and tuning your approaches later during incremental improvement.\"\n",
      "\n",
      "These characteristics suggest that a good data science team should have a combination of technical skills, domain expertise, collaboration and communication abilities, and a willingness to adapt and learn.\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as good for a data science team:\n",
      "\n",
      "1. Practicality: Focus on solving real-world problems with practical solutions.\n",
      "2. Flexibility: Be willing to adapt and change approaches as needed.\n",
      "3. Simplicity: Prioritize simplicity and ease of implementation over complexity and scalability.\n",
      "4. Ability to handle complexity: The ability to handle complex problems and data.\n",
      "5. Creativity: The ability to think creatively and come up with innovative solutions.\n",
      "6. Problem-solving skills: The ability to identify and solve complex problems.\n",
      "7. Flexibility: The ability to choose the right approach for the problem.\n",
      "8. Ability to work with diverse data: The ability to work with diverse data types and formats.\n",
      "9. Collaboration: The ability to work collaboratively with other stakeholders.\n",
      "10. Communication: The ability to effectively communicate insights and results to stakeholders.\n",
      "11. Attention to detail: The ability to be meticulous and detail-oriented.\n",
      "12. Adaptability: The ability to adapt to changing project requirements and timelines.\n",
      "13. Innovative thinking: The ability to develop novel approaches to solve complex problems.\n",
      "14. Domain expertise: The ability to have domain expertise in the field of biologics and vaccines.\n",
      "15. Technical skills: The ability to have strong technical skills in areas such as programming, statistics, and machine learning.\n",
      "\n",
      "Additionally, some general traits that are often considered important for a data science team include:\n",
      "\n",
      "1. Collaboration: Data science teams often consist of individuals with diverse skill sets, and collaboration is key to successful project outcomes.\n",
      "2. Communication: Effective communication is crucial for data science teams to ensure that stakeholders understand the results and insights generated by the team.\n",
      "3. Problem-solving: Data science teams should be able to identify and solve complex problems, often involving large datasets and complex algorithms.\n",
      "4. Creativity: Data science teams should be able to think creatively and come up with innovative solutions to complex problems.\n",
      "5. Attention to detail: Data science teams should be meticulous and detail-oriented, ensuring that data is accurate and reliable.\n",
      "6. Adaptability: Data science teams should be able to adapt to changing project requirements and new technologies.\n",
      "7. Continuous learning: Data science teams should be committed to ongoing learning and professional development, staying up-to-date with the latest tools, techniques, and methodologies.\n",
      "8. Transparency: Data science teams should be transparent in their methods and results, ensuring that stakeholders understand the data and insights generated by the team.\n",
      "9. Business acumen: Data science teams should have a good understanding of the business and be able to communicate insights and recommendations in a way that is relevant and actionable for stakeholders.\n",
      "10. Technical skills: Data science teams should have strong technical skills in areas such as programming, statistics, and machine learning.\n",
      "\n",
      "Please note that these characteristics may not be exhaustive, and the specific characteristics that are most important will depend on the specific needs and goals of the team and organization.\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Given the following extracted parts of a long document and a question, create a final answer. \n",
      "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
      "______________________\n",
      "Based on the provided text, the following characteristics are highlighted as important for a data science team:\n",
      "\n",
      "1. Interdisciplinary teams: The team consisted of software engineers, data analysts, and social scientists, indicating a diverse range of skills and expertise.\n",
      "2. Collaboration: The team worked together for 12 hours, identifying new datasets, building machine learning models, and creating frameworks for ensemble modeling and interactive results visualization.\n",
      "3. Innovation: The team was encouraged to explore new and innovative approaches for the statistical risk assessment, indicating a culture of experimentation and creativity.\n",
      "4. Crowdsourcing: The team was part of a hack-a-thon, which involved a large number of employees (over 80) participating in the project, demonstrating the power of crowdsourcing and collective effort.\n",
      "5. Flexibility: The team was able to adapt and refine their recommendations over time, indicating a willingness to iterate and improve their work.\n",
      "6. Data management: The team created a data management framework to automate the download, aggregation, and transformation of open-source datasets, demonstrating attention to data quality and management.\n",
      "\n",
      "These characteristics suggest that a good data science team should:\n",
      "\n",
      "* Be interdisciplinary and collaborative\n",
      "* Encourage innovation and experimentation\n",
      "* Leverage crowdsourcing and collective effort\n",
      "* Be flexible and willing to iterate\n",
      "* Prioritize data quality and management\n",
      "\n",
      "Additionally, other characteristics that are commonly considered important for a data science team include:\n",
      "\n",
      "* Curiosity: A data science team should be curious and passionate about exploring and understanding data.\n",
      "* Collaboration: Data science is a team effort, and a successful team should be able to work collaboratively and communicate effectively.\n",
      "* Creativity: Data science requires creative thinking and problem-solving skills to extract insights from data.\n",
      "* Analytical skills: A data science team should have strong analytical skills, including statistical knowledge and programming skills.\n",
      "* Business acumen: Data science teams should have a good understanding of the business and be able to communicate insights to stakeholders.\n",
      "* Adaptability: Data science is a rapidly evolving field, and a successful team should be able to adapt to new tools, technologies, and methodologies.\n",
      "* Passion for learning: A data science team should be committed to ongoing learning and professional development.\n",
      "* Strong communication skills: Data science teams should be able to effectively communicate complex technical information to non-technical stakeholders.\n",
      "* Attention to detail: Data science requires attention to detail and a focus on accuracy and precision.\n",
      "* Ability to work with ambiguity: Data science often involves working with incomplete or uncertain data, and a successful team should be able to work with ambiguity and uncertainty.\n",
      "\n",
      "These are just some of the characteristics that are commonly considered important for a data science team.\n",
      "\n",
      "According to the provided text, some general characteristics that are commonly considered important for a data science team are:\n",
      "\n",
      "1. Collaboration: Data science teams should be able to work together effectively, combining their skills and expertise to achieve common goals.\n",
      "2. Communication: Clear and effective communication is crucial for data science teams, as they need to be able to explain complex technical concepts to non-technical stakeholders.\n",
      "3. Problem-solving: Data science teams should be able to approach problems in a systematic and analytical way, using data to inform their decisions.\n",
      "4. Creativity: Data science teams should be able to think creatively and come up with innovative solutions to complex problems.\n",
      "5. Adaptability: Data science teams should be able to adapt quickly to changing requirements and new technologies.\n",
      "6. Domain expertise: Data science teams should have a deep understanding of the domain they are working in, including the business, industry, or field.\n",
      "7. Technical skills: Data science teams should have strong technical skills in areas such as programming, statistics, and machine learning.\n",
      "8. Data literacy: Data science teams should be able to work with large datasets and understand the importance of data quality and integrity.\n",
      "9. Business acumen: Data science teams should have a good understanding of the business and be able to communicate the value of their work to stakeholders.\n",
      "10. Continuous learning: Data science teams should be committed to continuous learning and professional development, staying up-to-date with the latest technologies and methodologies.\n",
      "\n",
      "Additionally, other characteristics that are often considered important for a data science team include:\n",
      "\n",
      "* Flexibility\n",
      "* Attention to detail\n",
      "* Strong project management\n",
      "* Data-driven decision-making\n",
      "* Transparency\n",
      "* Business acumen\n",
      "\n",
      "Please note that the specific characteristics that are most important will depend on the specific needs and goals of the team.\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Given the following extracted parts of a long document and a question, create a final answer. \n",
      "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
      "______________________\n",
      "Based on the provided text, the good characteristics for a data science team are:\n",
      "\n",
      "1. **Collaboration**: The team should consist of individuals with diverse backgrounds, including computer scientists, mathematicians, and domain experts.\n",
      "2. **Ability to produce new insights and analysis paths**: A good data science team should be able to generate new and valuable insights from data.\n",
      "3. **Breadth of experience**: A team with experience working with clients across various domains can provide a unique perspective on data science.\n",
      "4. **Multidisciplinary team**: The team should consist of individuals with diverse backgrounds, including computer scientists, mathematicians, and domain experts.\n",
      "5. **Ability to shift between deductive (hypothesis-based) and inductive (pattern-based) reasoning**: A good data science team should be able to combine the ability to reason deductively and inductively, creating an environment where models of reality are constantly tested, updated, and improved until better models are found.\n",
      "6. **Power of Many vs. Ability of One**: An entire team provides a common forum for pulling together computer science, mathematics, and domain expertise.\n",
      "7. **Embracing Data Science to maintain competitiveness in the increasingly data-rich environment**: A good data science team should be proactive in adopting Data Science to stay ahead of the competition.\n",
      "8. **Making informed decisions with real information through the application of Data Science**: A good data science team should use data-driven insights to inform their decisions.\n",
      "9. **Being able to access and make use of data at scale**: A good data science team should have the ability to collect, process, and analyze large amounts of data.\n",
      "10. **Being able to keep pace with market demands**: A good data science team should be agile and able to adapt quickly to changing market conditions.\n",
      "11. **Consolidating data and distilling answers**: Instead of building data silos, a data science team should aim to consolidate data and provide actionable insights.\n",
      "12. **Making maximum use of all available data**: A data science team should strive to utilize all available data to help the organization succeed, rather than leaving opportunities untapped.\n",
      "13. **Transforming data into insights**: Data science teams should transform data into actionable insights that can improve existing processes and drive business value.\n",
      "14. **Incorporating complex interrelationships in data**: Effective data science teams should be able to identify and incorporate complex relationships in data to drive better decision-making.\n",
      "\n",
      "Additionally, some other characteristics that are generally considered important for a data science team include:\n",
      "\n",
      "* Strong programming skills in languages like Python, R, or SQL\n",
      "* Experience with data visualization tools like Tableau, Power BI, or D3.js\n",
      "* Knowledge of machine learning algorithms and statistical modeling\n",
      "* Familiarity with data storage solutions like relational databases, NoSQL databases, or data warehouses\n",
      "* Strong communication and collaboration skills\n",
      "* Ability to work with stakeholders to understand business needs and develop data-driven solutions\n",
      "* Experience with data quality and data governance best practices\n",
      "* Stay up-to-date with industry trends and advancements in data science and analytics.\n",
      "\n",
      "Please note that these are general characteristics and may vary depending on the specific needs and goals of the organization.\n",
      "\n",
      "Based on the provided text, the following characteristics are mentioned as good for a data science team:\n",
      "\n",
      "1. Pattern recognition: The ability to identify patterns and relationships in data.\n",
      "2. Efficient data processing: The ability to quickly and accurately process large amounts of data.\n",
      "3. Attention to detail: The ability to carefully examine data and identify subtle differences.\n",
      "4. Collaboration: The ability to work together effectively, sharing knowledge and expertise.\n",
      "5. Adaptability: The ability to adapt to changing circumstances and re-evaluate approaches as needed.\n",
      "6. Domain expertise: A deep understanding of the domain or industry being worked in.\n",
      "7. Communication: The ability to effectively communicate insights and results to stakeholders.\n",
      "8. Creativity: The ability to think creatively and come up with innovative solutions.\n",
      "9. Analytical skills: Strong analytical skills, including statistical knowledge, programming skills, and data visualization expertise.\n",
      "10. Business acumen: A good understanding of the business and the ability to communicate insights and recommendations in a way that is relevant and actionable for stakeholders.\n",
      "11. Continuous learning: A commitment to ongoing learning and professional development, staying up-to-date with the latest tools, techniques, and methodologies.\n",
      "12. Transparency: The ability to be transparent in data collection, processing, and analysis, as well as findings and recommendations.\n",
      "13. Problem-solving skills: The ability to identify and solve complex problems.\n",
      "14. Flexibility: The ability to choose the right approach for the problem and adapt to changing project requirements and timelines.\n",
      "15. Innovative thinking: The ability to develop novel approaches to solve complex problems.\n",
      "16. Technical skills: Strong technical skills in areas such as programming, statistics, and machine learning.\n",
      "17. Diversity: A diverse team with different perspectives and strengths can lead to better results.\n",
      "18. Collaboration: The ability to work collaboratively with other stakeholders.\n",
      "19. Ability to balance individual strengths and weaknesses: Recognizing and balancing the strengths and weaknesses of individual team members.\n",
      "20. Ability to manage complexity: The ability to manage and balance the complexity of models and methods.\n",
      "\n",
      "Additionally, some general traits that are often considered important for a data science team include:\n",
      "\n",
      "1. Collaboration: Data science teams often consist of individuals with diverse skill sets, and collaboration is key to successful project outcomes.\n",
      "2. Communication: Effective communication is crucial for data science teams to ensure that stakeholders understand the results and insights generated by the team.\n",
      "3. Problem-solving: Data science teams should be able to identify and solve complex problems, often involving large datasets and complex algorithms.\n",
      "4. Creativity: Data science teams should be able to think creatively and come up with innovative solutions to complex problems.\n",
      "5. Attention to detail: Data science teams should be meticulous and detail-oriented, ensuring that data is accurate and reliable.\n",
      "6. Adaptability: Data science teams should be able to adapt to changing project requirements and new technologies.\n",
      "7. Continuous learning: Data science teams should be committed to ongoing learning and professional development, staying up-to-date with the latest tools, techniques, and methodologies.\n",
      "8. Transparency: Data science teams should be transparent in their methods and results, ensuring that stakeholders understand the data and insights generated by the team.\n",
      "9. Business acumen: Data science teams should have a good understanding of the business and be able to communicate insights and recommendations in a way that is relevant and actionable for stakeholders.\n",
      "10. Technical skills: Data science teams should have strong technical skills in areas such as programming, statistics, and machine learning.\n",
      "\n",
      "Please note that these characteristics may not be exhaustive, and the specific characteristics that are most important will depend on the specific needs and goals of the team and organization.\n",
      "\n",
      "Based on the provided text, the good characteristics for a data science team are:\n",
      "\n",
      "1. Interdisciplinary and collaborative\n",
      "2. Encourages innovation and experimentation\n",
      "3. Leverages crowdsourcing and collective effort\n",
      "4. Flexible and willing to iterate\n",
      "5. Prioritizes data quality and management\n",
      "6. Curious and passionate about exploring and understanding data\n",
      "7. Collaborative and able to work effectively with others\n",
      "8. Creative and able to think outside the box\n",
      "9. Strong analytical skills, including statistical knowledge and programming skills\n",
      "10. Business acumen and able to communicate insights to stakeholders\n",
      "11. Adaptable and able to work with new tools, technologies, and methodologies\n",
      "12. Passionate about ongoing learning and professional development\n",
      "13. Strong communication skills and able to effectively communicate complex technical information\n",
      "14. Attention to detail and focus on accuracy and precision\n",
      "15. Able to work with ambiguity and uncertainty\n",
      "\n",
      "Additionally, other characteristics that are often considered important for a data science team include:\n",
      "\n",
      "* Flexibility\n",
      "* Attention to detail\n",
      "* Strong project management\n",
      "* Data-driven decision-making\n",
      "* Transparency\n",
      "* Business acumen\n",
      "\n",
      "Note that the specific characteristics that are most important will depend on the specific needs and goals of the team.\n",
      "Human: What are the good characteristics for a data science teams\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Based on the provided text, the good characteristics for a data science team are:\\n\\n1. **Collaboration**: The team should consist of individuals with diverse backgrounds, including computer scientists, mathematicians, and domain experts.\\n2. **Ability to produce new insights and analysis paths**: A good data science team should be able to generate new and valuable insights from data.\\n3. **Breadth of experience**: A team with experience working with clients across various domains can provide a unique perspective on data science.\\n4. **Multidisciplinary team**: The team should consist of individuals with diverse backgrounds, including computer scientists, mathematicians, and domain experts.\\n5. **Ability to shift between deductive (hypothesis-based) and inductive (pattern-based) reasoning**: A good data science team should be able to combine the ability to reason deductively and inductively, creating an environment where models of reality are constantly tested, updated, and improved until better models are found.\\n6. **Power of Many vs. Ability of One**: An entire team provides a common forum for pulling together computer science, mathematics, and domain expertise.\\n7. **Embracing Data Science to maintain competitiveness in the increasingly data-rich environment**: A good data science team should be proactive in adopting Data Science to stay ahead of the competition.\\n8. **Making informed decisions with real information through the application of Data Science**: A good data science team should use data-driven insights to inform their decisions.\\n9. **Being able to access and make use of data at scale**: A good data science team should have the ability to collect, process, and analyze large amounts of data.\\n10. **Being able to keep pace with market demands**: A good data science team should be agile and able to adapt quickly to changing market conditions.\\n11. **Consolidating data and distilling answers**: Instead of building data silos, a data science team should aim to consolidate data and provide actionable insights.\\n12. **Making maximum use of all available data**: A data science team should strive to utilize all available data to help the organization succeed, rather than leaving opportunities untapped.\\n13. **Transforming data into insights**: Data science teams should transform data into actionable insights that can improve existing processes and drive business value.\\n14. **Incorporating complex interrelationships in data**: Effective data science teams should be able to identify and incorporate complex relationships in data to drive better decision-making.\\n\\nAdditionally, some other characteristics that are generally considered important for a data science team include:\\n\\n* Strong programming skills in languages like Python, R, or SQL\\n* Experience with data visualization tools like Tableau, Power BI, or D3.js\\n* Knowledge of machine learning algorithms and statistical modeling\\n* Familiarity with data storage solutions like relational databases, NoSQL databases, or data warehouses\\n* Strong communication and collaboration skills\\n* Ability to work with stakeholders to understand business needs and develop data-driven solutions\\n* Experience with data quality and data governance best practices\\n* Stay up-to-date with industry trends and advancements in data science and analytics.'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queschain.run(input_documents = splitdocs,question = query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the provided query, it gave good answering. That's good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the huge book of 126 pages is given to the llm model. We loaded the data and next transformed them into chunks for smoother processing and perfomed vector embeddings, later stored that vector embeddings to the pincone vector database, which is running in AWS cloud. And at last performing summarization and question answering based on the user query. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
